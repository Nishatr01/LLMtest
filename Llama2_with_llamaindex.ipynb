{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnUOq3dZeDK1"
      },
      "source": [
        "## RAG System Using Llama2 With Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHP9Gfafdq57",
        "outputId": "710589c5-a3c9-47fb-cff4-70963cd535b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.0.0-py3-none-any.whl (292 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/292.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m286.7/292.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YYeHrwmHfbgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c40ee7-5be4-4adc-8053-6468ad31e070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Tu1g-xwnfv9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754f50e9-2198-4d27-fa9a-25b16cbe8c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-3.1.1\n"
          ]
        }
      ],
      "source": [
        "## Embedding\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urL9wZkqf-Zu",
        "outputId": "3024b2a5-f264-462b-e053-a1b50986060d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index\n",
            "  Downloading llama_index-0.11.11-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama_index)\n",
            "  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama_index)\n",
            "  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.10 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.11.11)\n",
            "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama_index)\n",
            "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.3.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama_index)\n",
            "  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.3.0,>=0.2.9 (from llama_index)\n",
            "  Downloading llama_index_llms_openai-0.2.9-py3-none-any.whl.metadata (648 bytes)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.2.1-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.9.1)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.4.0,>=0.3.4->llama_index)\n",
            "  Downloading openai-1.47.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.10->llama_index) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (3.3)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.10->llama_index) (1.16.0)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama_index)\n",
            "  Downloading llama_cloud-0.0.17-py3-none-any.whl.metadata (751 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.1.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama_index)\n",
            "  Downloading llama_parse-0.5.6-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama_index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama_index) (2024.9.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.10->llama_index) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.10->llama_index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.10->llama_index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.10->llama_index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.10->llama_index) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.10->llama_index) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.10->llama_index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama_index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama_index) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama_index) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama_index) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama_index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.10->llama_index) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama_index) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama_index)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.10->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.10->llama_index) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.10->llama_index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.10->llama_index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.10->llama_index) (3.1.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.10->llama_index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.10->llama_index) (3.22.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.10->llama_index) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.10->llama_index) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.16.0)\n",
            "Downloading llama_index-0.11.11-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.2.9-py3-none-any.whl (12 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.2.1-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading llama_cloud-0.0.17-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.4/187.4 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.5.6-py3-none-any.whl (10 kB)\n",
            "Downloading openai-1.47.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: striprtf, pypdf, jiter, openai, llama-cloud, llama-index-legacy, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama_index\n",
            "  Attempting uninstall: pypdf\n",
            "    Found existing installation: pypdf 5.0.0\n",
            "    Uninstalling pypdf-5.0.0:\n",
            "      Successfully uninstalled pypdf-5.0.0\n",
            "Successfully installed jiter-0.5.0 llama-cloud-0.0.17 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.3.1 llama-index-legacy-0.9.48.post3 llama-index-llms-openai-0.2.9 llama-index-multi-modal-llms-openai-0.2.1 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.2 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.6 llama_index-0.11.11 openai-1.47.0 pypdf-4.3.1 striprtf-0.0.26\n"
          ]
        }
      ],
      "source": [
        "!pip install llama_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBVEwGHb94VJ",
        "outputId": "35126981-5b6d-4e35-e94a-32d81055d5eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index-llms-huggingface in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.23.5)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.11.11)\n",
            "Requirement already satisfied: text-generation<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.7.0)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (2.4.1+cu121)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.12.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.0.8)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.3)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.7.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.19.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.34.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.4.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.1.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.2.2)\n",
            "Requirement already satisfied: llama-index-llms-huggingface-api in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface-api) (0.23.5)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface-api) (0.11.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (4.12.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.0.8)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (3.3)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (0.7.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (3.1.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (3.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index-llms-huggingface\n",
        "!pip install llama-index-llms-huggingface-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HutpiHgpgLBE"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader,ServiceContext\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core.prompts.prompts import SimpleInputPrompt\n",
        "#from llama_index.core import VectorStoreIndex,SimpleDirectoryReader,ServiceContext,PromptTemplate\n",
        "#from llama_index.llms.huggingface import HuggingFaceLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcU-nQ_XgxWD",
        "outputId": "479f7c46-9475-4a39-84f8-0ef1205adb17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(id_='323a297a-ae0c-482b-a740-51e4d79bcb89', embedding=None, metadata={'page_label': 'I', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='IntechOpen Series  \\nArtificial Intelligence, Volume 7\\nMachine Learning  \\nAlgorithms, Models and Applications\\nEdited by Jaydip SenEdited by Jaydip Sen\\nRecent times are witnessing rapid development in machine learning algorithm systems, \\nespecially in reinforcement learning, natural language processing, computer and \\nrobot vision, image processing, speech, and emotional processing and understanding. \\nIn tune with the increasing importance and relevance of machine learning models, \\nalgorithms, and their applications, and with the emergence of more innovative \\nuses–cases of deep learning and artificial intelligence, the current volume presents \\na few innovative research works and their applications in real-world, such as stock \\ntrading, medical and healthcare systems, and software automation. The chapters in \\nthe book illustrate how machine learning and deep learning algorithms and models are \\ndesigned, optimized, and deployed. The volume will be useful for advanced graduate \\nand doctoral students, researchers, faculty members of universities, practicing data \\nscientists and data engineers, professionals, and consultants working on the broad \\nareas of machine learning, deep learning, and artificial intelligence.\\nPublished in London, UK  \\n© 2021 IntechOpen \\n© your_photo / iStockISBN 978-1-83969-484-4Andries Engelbrecht, Artificial Intelligence Series Editor\\nISSN  2633-1403Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='e50bd1b6-3a67-4cdb-afab-06af3ffb8e60', embedding=None, metadata={'page_label': 'II', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='0b2ed391-14ec-4224-a0b4-748f95454812', embedding=None, metadata={'page_label': 'III', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - \\nAlgorithms, Models and \\nApplications\\nEdited by Jaydip Sen\\nPublished in London, United Kingdom', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='f6b5e357-3a16-4d33-b855-a125b5c9ee7b', embedding=None, metadata={'page_label': 'IV', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c22b0489-324f-40ba-9de6-124106b6fa0c', embedding=None, metadata={'page_label': 'V', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Supporting open minds since 2005\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='917ce793-1040-4fcf-a7de-bc363062a8ba', embedding=None, metadata={'page_label': 'VI', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\nhttp:/ /dx.doi.org/10.5772/intechopen.94615Edited by Jaydip Sen\\nAssistant to the Editor: Sidra MehtabContributors\\nPooja Kherwa, Saheel Ahmed, Pranay Berry, Sahil Khurana, Sonali Singh, Jaydip Sen, Sidra Mehtab, David W. W Cadotte, David W. Anderson, Kalum J. Ost, Racheal S. Akinbo, Oladunni A. Daramola, Bongs Lainjo, Rajdeep Sen, Abhishek Dutta\\n© The Editor(s) and the Author(s) 2021\\nThe rights of the editor(s) and the author(s) have been asserted in accordance with the Copyright, Designs and Patents Act 1988. All rights to the book as a whole are reserved by INTECHOPEN LIMITED. The book as a whole (compilation) cannot be reproduced, distributed or used for commercial or non-commercial purposes without INTECHOPEN LIMITED’s written permission. Enquiries concerning the use of the book should be directed to INTECHOPEN LIMITED rights and permissions department (permissions@intechopen.com).Violations are liable to prosecution under the governing Copyright Law.\\nIndividual chapters of this publication are distributed under the terms of the Creative Commons Attribution 3.0 Unported License which permits commercial use, distribution and reproduction of the individual chapters, provided the original author(s) and source publication are appropriately acknowledged. If so indicated, certain images may not be included under the Creative Commons license. In such cases users will need to obtain permission from the license holder to reproduce the material. More details and guidelines concerning content reuse and adaptation can be found at http:/ /www.intechopen.com/copyright-policy.html.\\nNotice\\nStatements and opinions expressed in the chapters are these of the individual contributors and not necessarily those of the editors or publisher. No responsibility is accepted for the accuracy of information contained in the published chapters. The publisher assumes no responsibility for any damage or injury to persons or property arising out of the use of any materials, instructions, methods or ideas contained in the book.\\nFirst published in London, United Kingdom, 2021 by IntechOpen\\nIntechOpen is the global imprint of INTECHOPEN LIMITED, registered in England and Wales, registration number: 11086078, 5 Princes Gate Court, London, SW7 2QJ, United KingdomPrinted in Croatia\\nBritish Library Cataloguing-in-Publication Data\\nA catalogue record for this book is available from the British Library\\nAdditional hard and PDF copies can be obtained from orders@intechopen.comMachine Learning - Algorithms, Models and Applications\\nEdited by Jaydip Senp. cm.\\nThis title is part of the Artificial Intelligence Book Series, Volume 7\\nTopic: Machine Learning and Data MiningSeries Editor: Andries Engelbrecht Topic Editor: Marco Antonio Aceves Fernandez \\nPrint ISBN 978-1-83969-484-4\\nOnline ISBN 978-1-83969-485-1eBook (PDF) ISBN 978-1-83969-486-8ISSN 2633-1403', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='bf70d011-151a-4489-beb7-e0a399a92cd3', embedding=None, metadata={'page_label': 'VII', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Interested in publishing with us? \\nContact book.department@intechopen.com\\nNumbers displayed above are based on latest data collected. \\nFor more information visit www.intechopen.com5,600+ \\nOpen access books available\\n156\\nCountries delivered to12.2%\\nContributors from top 500 universitiesOur authors are among the\\nTop 1%\\nmost cited scientists138,000+\\nInternational authors and editors170M+ \\nDownloadsWe are IntechOpen,\\nthe world’ s leading publisher of \\nOpen Access books\\nBuilt by scientists, for scientists\\nBOOK\\nCITATION\\nINDEX \\nCLARIVATE ANALYTICS\\nINDEXED\\nSelection of our books indexed in the Book Citation Index (BKCI)  \\nin Web of Science Core Collection™', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='b307f1a6-a89c-41d4-a183-5400581a44de', embedding=None, metadata={'page_label': 'VIII', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='e615a357-bbe5-4dff-aea4-a2601b512900', embedding=None, metadata={'page_label': 'IX', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='IntechOpen Book Series  \\nArtificial Intelligence\\nV olume 7\\nAims and Scope of the Series\\nArtificial Intelligence (AI) is a rapidly developing multidisciplinary research area \\nthat aims to solve increasingly complex problems. In today’ s highly integrated world, AI promises to become a robust and powerful means for obtaining solutions to previously unsolvable problems. This Series is intended for researchers and stu-dents alike interested in this fascinating field and its many applications.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c529881a-06c7-4c66-ba15-178614843604', embedding=None, metadata={'page_label': 'X', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='572757fc-6862-4767-8198-a634da87c9c2', embedding=None, metadata={'page_label': 'XI', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Meet the Series Editor\\nAndries Engelbrecht received the Masters and Ph.D. degrees in \\nComputer Science from the University of Stellenbosch, South Africa, in 1994 and 1999 respectively. He is currently appointed as the V oigt Chair in Data Science in the Department of Indus-trial Engineering, with a joint appointment as Professor in the Computer Science Division, Stellenbosch University. Prior to his appointment at Stellenbosch University, he has been at the \\nUniversity of Pretoria, Department of Computer Science (1998-2018), where he was appointed as South Africa Research Chair in Artifical Intelligence (2007-2018), the head of the Department of Computer Science (2008-2017), and Director of the Institute for Big Data and Data Science (2017-2018). In addition to a number of research articles, he has written two books, Computational Intelligence: An Intro-duction and Fundamentals of Computational Swarm Intelligence.\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='0feeb545-dfeb-4e05-a90c-15dcd5ec3209', embedding=None, metadata={'page_label': 'XII', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='8ab8ba67-2136-43ad-97ba-4a4232396a1d', embedding=None, metadata={'page_label': 'XIII', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jaydip Sen is associated with Praxis Business School, Kolkata, \\nIndia, as a professor in the Department of Data Science. His re-search areas include security and privacy issues in computing and communication, intrusion detection systems, machine learning, deep learning, and artificial intelligence in the financial domain. He has more than 200 publications in reputed international journals, refereed conference proceedings, and 18 book chapters \\nin books published by internationally renowned publishing houses, such as Spring -\\ner, CRC press, IGI Global, etc. Currently, he is serving on the editorial board of the prestigious journal Frontiers in Communications and Networks and in the technical program committees of a number of high-ranked international conferences orga -\\nnized by the IEEE, USA, and the ACM, USA. He has been listed among the top 2% of scientists in the world for both the years 2020 and 2021 as of August 2021.\\nMeet the V olume Editor', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='0eda44d6-0cac-4045-8a0a-cf6fa7ef4b54', embedding=None, metadata={'page_label': 'XIV', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Contents\\nPreface XV\\nChapter 1 1\\nIntroductory Chapter: Machine Learning in Finance-Emerging \\nTrends and Challengesby Jaydip Sen, Rajdeep Sen and Abhishek Dutta\\nChapter 2 15\\nDesign and Analysis of Robust Deep Learning Models for Stock Price Predictionby Jaydip Sen and Sidra Mehtab\\nChapter 3 47\\nArticulated Human Pose Estimation Using Greedy Approachby Pooja Kherwa, Sonali Singh, Saheel Ahmed, Pranay Berry  \\nand Sahil Khurana\\nChapter 4 59\\nEnsemble Machine Learning Algorithms for Prediction \\nand Classification of Medical Images\\nby Racheal S. Akinbo and Oladunni A. Daramola\\nChapter 5 79\\nDelivering Precision Medicine to Patients with Spinal Cord Disorders; Insights into Applications of Bioinformatics and Machine Learning  from Studies of Degenerative Cervical Myelopathyby Kalum J. Ost, David W . Anderson and David W . Cadotte\\nChapter 6 103\\nEnhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nby Bongs Lainjo', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='51b69d52-15c7-4ba8-9b3c-cb361e9236c3', embedding=None, metadata={'page_label': 'XV', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Contents\\nPreface XVII\\nChapter 1 1\\nIntroductory Chapter: Machine Learning in Finance-Emerging \\nTrends and Challengesby Jaydip Sen, Rajdeep Sen and Abhishek Dutta\\nChapter 2 15\\nDesign and Analysis of Robust Deep Learning Models for Stock Price Predictionby Jaydip Sen and Sidra Mehtab\\nChapter 3 47\\nArticulated Human Pose Estimation Using Greedy Approachby Pooja Kherwa, Sonali Singh, Saheel Ahmed, Pranay Berry  \\nand Sahil Khurana\\nChapter 4 59\\nEnsemble Machine Learning Algorithms for Prediction \\nand Classification of Medical Imagesby Racheal S. Akinbo and Oladunni A. Daramola\\nChapter 5 79\\nDelivering Precision Medicine to Patients with Spinal Cord Disorders; Insights into Applications of Bioinformatics and Machine Learning  from Studies of Degenerative Cervical Myelopathyby Kalum J. Ost, David W . Anderson and David W . Cadotte\\nChapter 6 103\\nEnhancing Program Management with Predictive Analytics Algorithms (PAAs)by Bongs Lainjo', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='8be7af8b-6003-492e-aded-381237d05058', embedding=None, metadata={'page_label': 'XVI', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Preface\\nMachine learning (ML) is the ability of a system to automatically acquire, integrate, \\nand then develop knowledge from large-scale data, and then expand the acquired knowledge autonomously by discovering new information, without being specifically programmed to do so. In short, the ML algorithms can find applicationin the following: (1) a deeper understanding of the cyber event that generated the data under study, (2) capturing the understating of the event in the form of amodel, (3) predicting the future values that will be generated by the event based on the constructed model, and (4) proactively detect any anomalous behavior ofthe phenomenon so that appropriate corrective actions can be taken beforehand. ML is an evolutionary area, and with recent innovations in technology, especiallywith the development of smarter algorithms and advances in hardware and storagesystems, it has become possible to perform a large number of tasks more efficientlyand precisely, which were not even imaginable a couple of decades before. Over thepast few years, deep learning (DL), a specialized subset of machine learning thatinvolves more complex architectures, algorithms, and models for solving complexproblems and predicting future outcomes of complex events, has also evolved.\\nRecent times are witnessing rapid development in machine learning algorithm\\nsystems, especially in reinforcement learning, natural language processing, computer and robot vision, image processing, speech, and emotional processing and understanding. There are numerous applications of machine learning that haveemerged or are evolving at present in several business domains, such as medicinesand healthcare, finance and investment, sales and marketing, operations and supply chain, human resources, media and entertainment, and so on.\\nOf late, the applied ML systems in the industry are exhibiting some prominent\\ntrends. These trends will utilize the power of ML and artificial intelligence (AI)systems even further to reap benefits in business and society, in general. Some ofthese trends are as follows: (1) less volume of code and faster implementation ofML systems; (2) increasing use of light-weight systems suitable for working on theresource-constrained internet of things (IoT) devices; (3) automatic generation ofcodes for building ML models; (4) designing novel processes for robust managementof the development of ML systems for increased reliability and efficiency; (5) morewide-spread adoption of deep-learning solutions into products of all domains andapplications; (6) increased use of generative adversarial networks (GAN)-basedmodels for various image processing applications including image searching,image enhancement, etc.; (7) more prominence of unsupervised learning-basedsystems that require less or no human intervention for their operations; (8) use ofreinforcement learning-based systems; and finally, (9) evolution of few-shots,if not zero-shot learning-based systems.\\nIn tune with the increasing importance and relevance of ML models, algorithms, \\nand their applications and with the emergence of more innovative uses-cased ofDL- and AI-based systems, the current volume presents a few innovative researchworks and their applications in real-world, such as stock trading, medical and healthcare systems, and software automation. The chapters in the book illustrate', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='41b2fc50-1b7d-4fce-bfae-851c13923cc3', embedding=None, metadata={'page_label': 'XVII', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Preface\\nMachine learning (ML) is the ability of a system to automatically acquire, integrate, \\nand then develop knowledge from large-scale data, and then expand the acquired knowledge autonomously by discovering new information, without being specifically programmed to do so. In short, the ML algorithms can find application in the following: (1) a deeper understanding of the cyber event that generated the data under study, (2) capturing the understating of the event in the form of a model, (3) predicting the future values that will be generated by the event based on the constructed model, and (4) proactively detect any anomalous behavior of the phenomenon so that appropriate corrective actions can be taken beforehand. ML is an evolutionary area, and with recent innovations in technology, especially with the development of smarter algorithms and advances in hardware and storage systems, it has become possible to perform a large number of tasks more efficiently and precisely, which were not even imaginable a couple of decades before. Over the past few years, deep learning (DL), a specialized subset of machine learning that involves more complex architectures, algorithms, and models for solving complex problems and predicting future outcomes of complex events, has also evolved.\\nRecent times are witnessing rapid development in machine learning algorithm \\nsystems, especially in reinforcement learning, natural language processing, computer and robot vision, image processing, speech, and emotional processing and understanding. There are numerous applications of machine learning that have emerged or are evolving at present in several business domains, such as medicines and healthcare, finance and investment, sales and marketing, operations and supply chain, human resources, media and entertainment, and so on.\\nOf late, the applied ML systems in the industry are exhibiting some prominent \\ntrends. These trends will utilize the power of ML and artificial intelligence (AI) systems even further to reap benefits in business and society, in general. Some of these trends are as follows: (1) less volume of code and faster implementation of ML systems; (2) increasing use of light-weight systems suitable for working on the resource-constrained internet of things (IoT) devices; (3) automatic generation of codes for building ML models; (4) designing novel processes for robust management of the development of ML systems for increased reliability and efficiency; (5) more wide-spread adoption of deep-learning solutions into products of all domains and applications; (6) increased use of generative adversarial networks (GAN)-based models for various image processing applications including image searching, image enhancement, etc.; (7) more prominence of unsupervised learning-based systems that require less or no human intervention for their operations; (8) use of reinforcement learning-based systems; and finally, (9) evolution of few-shots,  \\nif not zero-shot learning-based systems.\\nIn tune with the increasing importance and relevance of ML models, algorithms, \\nand their applications and with the emergence of more innovative uses-cased of DL- and AI-based systems, the current volume presents a few innovative research works and their applications in real-world, such as stock trading, medical and healthcare systems, and software automation. The chapters in the book illustrate ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='7d7836cc-dd51-40ee-a36b-4f7aa3f4c21d', embedding=None, metadata={'page_label': 'XVIII', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='IVhow ML and DL algorithms and models are designed, optimized, and applied \\nfor\\xa0achieving higher precision and efficiency in business and other processes in real-world scenarios.\\nThe book presents six chapters that highlight different architectures, models, \\nalgorithms, and applications of machine learning, deep learning, and artificial intelligence. The subject matter discussed in the chapters of the book illustrates the complexities involved in the design, training, validation, testing, and deployment of machine learning and deep learning models in real-world applications.\\nIn the introductory chapter entitled Introductory Chapter: Machine Learning in \\nFinance-Emerging Trends and Challenges, Jaydip Sen, Rajdeep Sen, and Abhishek Dutta present a landscape of the emerging trends and challenges in banks and other financial institutions that machine learning-based models will face in the near future and how the organizations should transform those challenges into opportunities for their business.\\nIn Chapter 2, Design and Analysis of Robust Deep Learning Models for Stock Price \\nPrediction , Jaydip Sen and Sidra Mehtab present a set of deep learning-based \\nregression models for precise and robust prediction of future prices of a stock listed in the diversified sector in the National Stock Exchange (NSE) of India. The models are built on convolutional neural network (CNN) and long short-term memory (LSTM) network architectures, and they are designed to handle high-frequency stock price data. The performances of the models are compared based on their execution time and prediction accuracies.\\nIn Chapter 3, Articulated Human Pose Estimation Using Greedy Approach, Pooja Kherwa, \\nSonali Singh, Saheel Ahmed, Pranay Berry, and Sahil Khurana propose a method of\\xa0bottom-up parsing for human pose estimation that localizes anatomical key points of humans. The authors have also presented results on the performance of their proposed mechanism.\\nIn Chapter 4, Ensemble Machine Learning Algorithms for Prediction and Classification \\nof Medical Images, Racheal S. Akinbo and Oladunni A. Daramola discuss how ensemble machine learning models can be applied for classifying medical images, such as ultrasound reports, X-rays, mammography, fluoroscopy, computer-aided tomography, magnetic resonance image, magnetic resonance angiography, nuclear medicine, and positron emission tomography.\\nIn Chapter 5, Delivering Precision Medicine to Patients with Spinal Cord Disorders; \\nInsights into Applications of Bioinformatics and Machine Learning from Studies of Degenerative Cervical Myelopathy, Kalum J. Ost, David W. Anderson and David W. Cadotte present an approach towards designing a machine learning-based clinical diagnosis system that supports the diagnostic prediction of DCM severity. The proposed system is intended to serve as a support system to the patients rather than a recommendation system. Extensive discussion has been made on the system design, data collection process, data preprocessing, model building, and performance results of the system.\\nIn Chapter 6, Enhancing Program Management with Predictive Analytics Algorithms \\n(PAAs), Bongs Lainjo identifies various practical aspects of software development with a particular focus on predictive model design and deployment. The author also \\nVdiscusses how predictive analytics algorithms can be used to predict future events in different domains of applications, for example, healthcare, manufacturing, education, sports, and agriculture.\\nI hope that the volume will be very useful for advanced graduate and doctoral \\nstudents, researchers, practicing data scientists and data engineers, professionals, and consultants working on the broad areas of machine learning, deep learning, artificial intelligence, and other allied areas in computer science. It will also be of use to faculty members and scientists in graduate schools, universities, and research labs engaged in teaching research in machine learning and its applications. Since the volume is not an introductory treatise on the subject, the readers are expected to have basic knowledge of the fundamental principles and theoretical backgrounds of machine learning models and algorithms to understand their advanced applications discussed in the book.\\nI express my sincere thanks to all authors of the chapters in the volume for their \\nvaluable contributions. Without their cooperation and eagerness to contribute, this project would never have been successful. All the authors have been extremely cooperative and punctual during the submission, editing, and publication process of the book. I express our heartfelt thanks to Ms. Marica Novakovic, author service manager of IntechOpen Publishers, for her support, encouragement, patience, and cooperation during the project and her wonderful coordination of all activities involved in it. My sincere thanks also go to Ms. Anja Filipovic, commissioning editor of IntechOpen Publishers, for reposing faith in me and delegating me with the critical responsibility of editorship of such a prestigious academic volume. I\\xa0will be certainly failing in my duty if I do not acknowledge the encouragement, motivation, and assistance I received from Ms. Sidra Mehtab, my assistant editor and the co-author of one of the chapters in the book. I sincerely thank the valuable contributions received from the coauthors, of the introductory chapter of the book, Mr. Rajdeep Sen and Mr. Abhishek Dutta. The members of my family have always been the sources of my inspiration and motivation for such scholastic work. I dedicate this volume to my beloved sister, Ms. Nabanita Sen, who unfortunately left us on 27 September 2021, due to the deadly disease of cancer. My sister has been always the pillar of strength for me, and this volume also would not have been a success without her constant support and motivation, despite her suffering due to her terminal illness. Last but not the least, I gratefully acknowledge the support and motivation I received from my wife Ms. Nalanda Sen, my daughter Ms. Ritabrata Sen, my mother Ms. Krishna Sen, my brother Mr. Rajdeep Sen, and my sister-in-law , Ms. Toby Kar. Without their support, motivation, and inspiration, the\\xa0publication of this volume would not have been possible.\\nJaydip Sen\\nProfessor,\\nDepartment of Data Science,\\nPraxis Business School,\\nKolkata, India\\nXVIII', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='869499f3-4eae-4d58-bc66-e071fb41cdad', embedding=None, metadata={'page_label': 'XIX', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Vdiscusses how predictive analytics algorithms can be used to predict future events \\nin different domains of applications, for example, healthcare, manufacturing, education, sports, and agriculture.\\nI hope that the volume will be very useful for advanced graduate and doctoral \\nstudents, researchers, practicing data scientists and data engineers, professionals, and consultants working on the broad areas of machine learning, deep learning, artificial intelligence, and other allied areas in computer science. It will also be of use to faculty members and scientists in graduate schools, universities, and research labs engaged in teaching research in machine learning and its applications. Since the volume is not an introductory treatise on the subject, the readers are expected to have basic knowledge of the fundamental principles and theoretical backgrounds of machine learning models and algorithms to understand their advanced applications discussed in the book.\\nI express my sincere thanks to all authors of the chapters in the volume for their \\nvaluable contributions. Without their cooperation and eagerness to contribute, this project would never have been successful. All the authors have been extremely cooperative and punctual during the submission, editing, and publication process of the book. I express our heartfelt thanks to Ms. Marica Novakovic, author service manager of IntechOpen Publishers, for her support, encouragement, patience, and cooperation during the project and her wonderful coordination of all activities involved in it. My sincere thanks also go to Ms. Anja Filipovic, commissioning editor of IntechOpen Publishers, for reposing faith in me and delegating me with the critical responsibility of editorship of such a prestigious academic volume. I\\xa0will be certainly failing in my duty if I do not acknowledge the encouragement, motivation, and assistance I received from Ms. Sidra Mehtab, my assistant editor and the co-author of one of the chapters in the book. I sincerely thank the valuable contributions received from the coauthors, of the introductory chapter of the book, Mr. Rajdeep Sen and Mr. Abhishek Dutta. The members of my family have always been the sources of my inspiration and motivation for such scholastic work. I dedicate this volume to my beloved sister, Ms. Nabanita Sen, who unfortunately left us on 27 September 2021, due to the deadly disease of cancer. My sister has been always the pillar of strength for me, and this volume also would not have been a success without her constant support and motivation, despite her suffering due to her terminal illness. Last but not the least, I gratefully acknowledge the support and motivation I received from my wife Ms. Nalanda Sen, my daughter Ms. Ritabrata Sen, my mother Ms. Krishna Sen, my brother Mr. Rajdeep Sen, and my sister-in-law , Ms. Toby Kar. Without their support, motivation, and inspiration, the\\xa0publication of this volume would not have been possible.\\nJaydip Sen\\nProfessor,\\nDepartment of Data Science,\\nPraxis Business School,\\nKolkata, India\\nXIX', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='d312b882-427a-4550-a1fe-c92d1a4e71a3', embedding=None, metadata={'page_label': 'XX', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='19272700-ee81-4b2c-8c87-1b9c2cdc241d', embedding=None, metadata={'page_label': '1', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1Chapter 1\\nIntroductory Chapter: Machine \\nLearning in Finance-Emerging Trends and Challenges\\nJaydip\\xa0Sen, Rajdeep\\xa0Sen and Abhishek\\xa0Dutta\\n1. Introduction\\nThe paradigm of machine learning and artificial intelligence has pervaded our \\neveryday life in such a way that it is no longer an area for esoteric academics and \\nscientists putting their effort to solve a challenging research problem. The evolution is quite natural rather than accidental. With the exponential growth in process-ing speed and with the emergence of smarter algorithms for solving complex and challenging problems, organizations have found it possible to harness a humongous volume of data in realizing solutions that have far-reaching business values.\\nFinancial services, banking, and insurance remain one of the most significant \\nsectors that has a very high potential in reaping the benefits of machine learning and artificial intelligence with the availability of rich data, innovative algorithms, and novel methods in its various applications. While the organizations have only skimmed the surface of the rapidly evolving areas such as deep neural networks and reinforcement learning, the possibility of applying these techniques in many applications vastly remains unexplored. Organizations are leveraging the benefits of innovative applications of machine learning in applications like customer seg -\\nmentation for target marketing of their newly launched products, designing optimal portfolio strategies, detection, and prevention of money laundering and other illegal activities in the financial markets, smarter and effective risk management is credit, adherence to the regulatory frameworks in finance, accounts, and other operations, and so on. However, the full capability of machine learning and artificial intelligence still remains unexplored and unexploited. Leveraging such capabilities will be criti -\\ncal for organizations to achieve and maintain a long-term competitive edge.\\nWhile one of the major reasons for the slow adoption of AI/ML models and \\nmethods in financial applications is that the algorithms are not well known and there is an inevitable trust deficit in deploying them in critical and privacy-sensitive applications, the so-called “black-box” nature of such models and frameworks that analyzes their internal operations in producing outputs and their valida -\\ntions also impede faster acceptance and deployment of such models in real-world applications.\\nThis introductory chapter highlights some of the challenges and barriers that \\norganizations in the financial services sector at the present encounter in adopting machine learning and artificial intelligence-based models and applications in their day-to-day operations.\\nThe rest of the chapter is organized as follows. Section 2 presents some emerg -\\ning applications of machine learning in the financial domain. Section 3 highlights emerging computing paradigms in finance. Some important modeling paradigms ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='aa5180f9-6f51-48ce-92b4-2aa374a3be4d', embedding=None, metadata={'page_label': '2', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n2in the era of machine learning and artificial intelligence are discussed in Section 4. \\nSection 5 discusses some new challenges and barriers currently faced by the finan-cial modelers. Some emerging risks, new choices, and modern practices in financial modeling are presented in Section 6. Finally, Section 7 concludes the chapter.\\n2. Emerging application of machine learning in finance\\nWith the increasing availability and declining cost for complex models executing \\non high-power computing devices exploiting the unlimited capacity of data stor-age, the financial industry is geared up to exploit the benefits of machine learning to leverage a competitive business edge. While some of the use cases have already found their applications in the real world, others will need to overcome some existing business and operational challenges before they are deployed. Some of the applications are mentioned below .\\nRisk Modeling: One of the major applications of AI/ML models and algorithms \\nis in the extensive domain of risk modeling and management [1]. While on one hand, the risk modeling credit and market is a critical application of machine learning, on the other hand, a non-finance application such as operational risk management, com-pliance, and fraud management is also quite important. The majority of the classifica -\\ntion approaches and modeling techniques in machine learning such as binary logistic regression, multinomial logistic regression, linear and quadratic discriminant analy -\\nsis, and decision trees, etc., are the foundational building blocks of applied modeling in the real world. However, in data science applications, the availability of data and its richness play a pivotal role. Hence, in data-rich applications such as credit risk model-ing and scoring, designing mortgage schemes, the AI/ML models have already made substantial inroads in comparison to scenarios such as low default credit portfolios for well-known parties that lack the availability of data. Fraud analytics remains another intensive area of AI/ML applications in the non-financial domain.\\nPortfolio Management: The portfolios are designed based on the recommenda -\\ntions of smart algorithms that optimize various parameters with return and risk being the two most important ones [2]. Using the information provided by the users such as their ages of retirement, amount of investment, etc., and other associate details such as their current ages, current assets at hand, the algorithm allocate the invested amount into diverse asset classes to optimize the return and the risk associated with the portfolio. Once an initial allocation is made, the algorithm continuously monitors the market environment and changes the allocation so that the portfolio remains at its optimized level always. These AI-enabled portfolio managers, known as the Robo-advisors are increasingly being used in real-world portfolio design due to their superior adaptability and optimization skill to their human counterparts.\\nAlgorithmic Trading: Algorithmic trading exploits the use of algorithms to \\ncarry out stock trading in an autonomous manner with minimal human interven-tion [3]. Invented in 1970, algorithmic trading deploys automated pre-programmed stock trading instructions that can be executed very fast and at a very short time interval (i.e., at a very high frequency) to optimize trading returns and objectives. Machine learning and artificial intelligence have pushed algorithmic trading into a new dimension where not only advanced trading strategies can be made very fast but also deep insights can be made into the stock price and overall market move-ments. While most hedge funds and financial organizations do not make their trading strategies public, it is well known that machine learning, of late, is playing an increasingly important role in calibrating high-frequency, high-volume trading decisions in real-time for critical applications.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='9ab1b2b3-5553-4e70-862b-f0f108758cad', embedding=None, metadata={'page_label': '3', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3Introductory Chapter: Machine Learning in Finance-Emerging Trends and Challenges\\nDOI: http://dx.doi.org/10.5772/intechopen.101120\\nFraud detection and analysis: Fraud detection and analysis is one of the most \\ncritical machine learning applications in the finance industry [4]. There is an \\nincreased level of security and privacy risk associated with sensitive information both from the organization and personal front due to ubiquitous availability of connectivity, high computational power in devices, an increased amount of data stored and communicated online. These issues have changed the way online fraud analysis and detection are being made. While detection in earlier days used to depend on matching a large set of complex rules, the recent approaches are largely based on the execution of learning algorithms that adapts to new security threats making the detection process more robust while being agile.\\nLoan and Insurance Underwritings: Loans, credit, and insurance underwrit -\\ning is also an area where the large-scale deployment of machine learning models can be made by financial institutions for achieving competitive advantage [5]. At large banks and insurance firms, the availability of historical data of consumers, financial lending/borrowing information, insurance outcomes, and default-related information in paying debts, can be leveraged in training robust machine learning models. The learned patterns and trends can be exploited by the learning algorithms for lending and underwriting risks in the future to minimize future defaults. The deployment of such models can lead to a paradigm shift in business efficiency and profit. However, at present, there is a limited utilization of such models in the industry as their deployments are largely confined within large financial institutions.\\nFinancial Chatbots: Automation in the finance industry is also an outcome of \\nthe deployment of machine learning and artificial intelligence. Accessing the rel-evant data, machine learning models can yield an insightful analysis of the underly -\\ning patterns inside them that helps in making effective decisions in the future. In many cases, these models may provide recommended actions for the future so that the business decision can be made in the most efficient and optimum way. AI-based systems in financial applications also can minimize their errors learning fast from their past actions that also reduce wastages of precious resources including time. AI chatbots provide an effective way of interaction with the customers while automat -\\ning many routine tasks in a financial institution [6].\\nRisk Management: Machine learning techniques are revolutionizing the way \\ncorporates handle the risks associated with their operations. Risk management examples are diverse and infinite ranging from deciding about the amount a bank should lend a customer or how to improve compliance to a process or the way risk associated with a model can be minimized [7].\\nAsset price prediction: Predicting future asset prices is one of the most chal-\\nlenging tasks that finance professionals have to do frequently. The price of an asset is affected by numerous factors driven by the market including speculative activi-ties. In the classical approach, an asset price is determined by analyzing historical financial reports and past market performances. With rich data available, of late, machine learning-based models have started playing significant roles in predicting future asset prices in a robust and precise manner [8].\\nDerivative pricing: In the traditional approach, derivative pricing models are \\ndesigned on numerous assumptions which do not hold good in the real world. These assumptions attempt to establish an empirical relationship among several predictor variables such as the strike price, maturity time, and option type, and the target vari -\\nable which is the price of the derivative. Machine learning models have gotten rid of the requirement of such assumptions as they attempt to fit in the best possible func -\\ntion between the predictors and the target by minimizing the error. Accuracy and the minimal time needed for the deployment of the models in real-world use cases make machine learning the most impactful paradigm in the task of derivative pricing [9].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='dda8d2b8-0e29-4491-abc3-afb2e1113fe8', embedding=None, metadata={'page_label': '4', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n4Money Laundering: As per a report published by the United Nations, it is \\nestimated that 2–5% of the world’s aggregated GDP is accounted for the amount of \\nmoney being laundered worldwide. Machine learning models can find applications in detecting money laundering activities with minimal false-positive cases [10].\\n3. Emerging paradigms in computing in finance\\nSeveral new capabilities and approaches and frameworks in machine learning, \\ndata science, and artificial intelligence have become available to the modelers and engineers for all disciplines including finance professionals and researchers. Some of them are as follows.\\nVirtual Agents: The machine learning paradigm will witness the increasing \\ndeployment of agents in various tasks. These agents have the capability of perform-ing complex data mining tasks through a large set of policy rules, defined proce-dures and regulations, and provide automated responses to queries.\\nCognitive Robotics: The robots in the cognitive domain have the power of \\nautomating several tasks which are currently done by humans. This automation comes with an additional level of sophistication, speed, and precision in perform-ing the tasks.\\nText Analytics: The applications of sophisticated algorithms, frameworks, \\nand models of natural language processing in analyzing voluminous and complex financial contracts and documents help processing and decision making faster and more accurately with minimal associated risks.\\nVideo Analytics: Advancements in the fields of computer vision, image pro-\\ncessing, speech processing, and speech recognition together with the exponential growth in hardware capabilities have led to very promising progress in compliance, audit, model validation in various financial applications including automated generation and presentation of financial reports.\\n4. Emerging trends in modeling techniques\\nWith the increasing proliferation of machine learning models in innovative \\napplications in the financial industry, some computing and modeling paradigms will find more adoption. Some of them are as follows.\\nSparsity-aware learning: Sparsity-aware learning has evolved as an alternative \\nmodel regularization approach to address several problems that are usually encoun-tered in machine learning [11]. Considerable effort has been spent in designing such frameworks in an iterative manner for solving estimation tasks of model parameters avoiding overfit.\\nIteratively designing schemes such frameworks in solving estimation tasks of \\nmodel parameters avoiding overfit.\\nSparsity-aware learning systems are well-suited in financial modeling applications \\nleading to extremely robust and accurate models for various applications in finance.\\nReproducing Kernel Hilbert Spaces: Reproducing Kernel Hilbert Spaces \\n(RKHS) is essentially a Hilbert space function that evaluates a continuous function in the linear space [12]. These functions find important applications in statistical learning as every functional representation in RKHS represents minimization of an empirical function embodying the associated risk, and the representation is made as a linear combination of the data points in the training set transformed by the kernel function. Accordingly, RKHS has a very high potential in risk modeling and evaluation in finance.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='3bcb3fc7-ef02-4068-b77e-f9713dc666d7', embedding=None, metadata={'page_label': '5', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='5Introductory Chapter: Machine Learning in Finance-Emerging Trends and Challenges\\nDOI: http://dx.doi.org/10.5772/intechopen.101120\\nMonte Carlo simulation: This method of modeling provides the modeler with \\na large range of possible outcomes and probabilities that they will occur for any \\nchoice of action that is taken. It is used in a diverse set of domains like finance, energy, project management, and monitoring, research and development, and insurance. It performs risk analysis by designing models of possible results by substituting a range of values – a probability distribution – for any factor that has inherent uncertainty. The ability in handling uncertainty makes this approach particularly popular in modern-day modeling in finance [13].\\nGraph theory: Multivariate financial data pose a very complex challenge in pro-\\ncessing and visualization in addition to being difficult in modeling. Graph theory provides the modeler with a very elegant, efficient, and easily interpretable method of handling multivariate financial data [14].\\nParticle filtering: It is a method of modeling nonlinear and non-Gaussian \\nsystems with a very high level of precision. Its ability to handle multi-modal data makes it one of the most effective and popular modeling techniques in many fields including finance [15]. Stated in simple words, particle filtering is a technique for identifying the distribution of a population that has a minimum variance by identi-fying a set of random samples traversing through all the states to obtain a probabil-ity density function that best fits into the original distribution and then substituting the integral operation on the function by the mean of the sample.\\nParameter learning and convex paths: While optimization methods have been \\nproved to be very effective in training large-scale deep neural networks involving millions of parameters, the regularization of these methods has become of para -\\nmount importance for proper training of such networks [16]. Accordingly, intensive work has been also carried out in estimating the biases associated with the optimum value of the objective function arrived at by the algorithms. The estimation of such biases provides the modeler with an idea about the degree of inaccuracy in the models for critical applications including financial modeling.\\nDeep learning and reinforcement learning: The application of machine \\nlearning in finance has largely been manifested in the form of models built on deep neural network architecture and smarter algorithms for the optimization and training of such networks. Reinforcement learning-based models have made the automation of such models a reality. A vast gamut of applications, such as algo trading, capital asset pricing, stock price prediction, portfolio management can be very effectively designed and executed using deep learning and reinforcement learning frameworks [17–26].\\n5. New challenges in financial modeling\\nDespite the numerous opportunities and advantages that machine learning and \\nartificial intelligence-based applications are likely to provide to the financial sector, there will be some initial challenges and barriers too. This section highlights some of the challenges as follows.\\nData challenges: While the availability of data in finance is quite plenty, the \\ntime series data in finance (e.g., stock prices) are quite small in size for data-hungry machine learning and deep learning models. Models built on limited time series data are naturally less trained and improperly designed. The result is a sub-optimal performance of the models. Another problem in finance is that financial data cannot be synthesized unlike images in the fields of computer vision and image processing. Since finance data cannot be synthesized, one has to wait for financial data to be produced in the real world before using them in model training and vali-dation. The third challenge with financial data is the high level of noise associated ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='dc0d6c16-869f-40bb-a4ac-b2f0922a4770', embedding=None, metadata={'page_label': '6', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n6with high-frequency trading data. Since high-frequency data in finance are invari-\\nably associated with a high level of noise, the machine learning models trained on such noisy data are intrinsically imprecise. Data evolution in finance poses the fourth challenge. Unlike data in most other fields, where the data features do not change with time, the features in financial data in harmony with financial markets evolve and change with time. This implies that financial variables will not carry the same meaning and significance over a long period, say one decade. The changes in the semantic meaning and significance of financial variables make it particularly difficult for the machine learning model to derive a consistent explanation and learning over a reasonably long period [27].\\nBlack-box nature of the models: Machine learning and artificial intelligence-\\nbased models are black-box in nature [28]. In these models, while the outputs from the model are available and most of the time, they are easily interpretable, the biggest shortcoming is their lack of power of explanation of the output. In many critical applications in finance, mere outputs are not sufficient, and strong logical support for explaining the output is mandatory to instill sufficient confidence in the minds of the decision-makers. In absence of such explainable characteristics of the machine learning models, it will always remain a difficult job for the modelers to advocate the suitability of such models in critical business use cases.\\nValidation challenges of the models: Due to their higher complexity and \\nopaqueness in operation, the machine learning models pose some significant chal-lenges to risk management and validation [29]. While the regulators demand the machine learning models to comply with the SR 11–7 and OCC 2011–2012 standards of risk management, the optimum execution of the models may not be possible if all those guidelines are to be strictly adhered to. Model risk is an event that occurs when a model is designed following its intended objective but it introduces errors while in execution yielding inaccurate results from the perspective of its design and business use case. Another manifestation of model risk can happen when a model is built and deployed inaccurately or with faults without proper knowledge about its limitations and shortcoming.\\nChallenges in model testing and outcome analysis: The performance of a model \\nand its accuracy in testing are evaluated by outcome analysis [29]. Since the neural network model has a natural tendency to overfit or underfit the data based on the training, it is imperative on the part of the model evaluation team to address the bias-variance trade-offs in the training and validation process. Since the traditional k cross-validation procedure used in backtesting of predictive models does not work effectively for machine learning model validation, the machine learning model vali-dators should take particular care in carrying out normalization and feature selection before model training and validation. Validation loss and accuracy should be strictly monitored and analyzed to ensure that no overfitting or underfitting is present in the model before it is sent to the production phase. Neural network models are also diffi-cult to evaluate on their sensitivity analysis as these models lack explainability. Since establishing a functional relationship between the explanatory variables and the target variable in a neural network model is a difficult task unlike statistical models, sensitivity analysis between the inputs and the output may involve a computationally involved challenge while the results of the analysis may be quite complex.\\nChallenges with models designed by vendors: As per the requirements speci-\\nfied in SR 11–7 and OCC 2011–2012 standards, models supplied by vendors are required to adhere to the same rigor as internally developed models [29]. However, in many practical situations, due to proprietary restrictions testing of vendors supplied models becomes a challenge. For vendor-supplied models, banks and financial institutions will have to mostly rely on softer forms of validation. The softer form of validation may include periodic review of model performance and ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='f2ef180f-1d06-4b65-889e-4e2ff120d9b7', embedding=None, metadata={'page_label': '7', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='7Introductory Chapter: Machine Learning in Finance-Emerging Trends and Challenges\\nDOI: http://dx.doi.org/10.5772/intechopen.101120\\nconceptual soundness, stringent assessment of model customization, review of the \\ndevelopment process, and applicability of the model in the portfolio of operations of the bank.\\n6. Emerging risks, new choices, and modern practices\\nIn all domains including finance, the major cause that contributes to the risk in a \\nmachine learning model is the complexity associated with the model. The machine learning algorithms are intrinsically very complex as they work on voluminous and possibly unstructured data such as texts, images, and speech. As a consequence, training of such algorithms demands sophisticated computing infrastructure and a high level of knowledge and skill on the part of the modelers. However, countering such complexities with overly sophisticated models can be very counterproduc -\\ntive. Instead of adopting a complex approach, the banks and financial institutions should understand the risks associated with their business and operations and manage them with simple model-validation approaches. The issues that will domi-nate the risk management landscape for machine learning models in the financial industry are – (i) interpretability of the models, (ii) model bias, (iii) extensive feature engineering, (iv) importance of model hyperparameters, (v) production readiness of models, (vi) dynamic calibration of models, and (vii) explainable artificial intelligence. These issues are briefly discussed below .\\nModel interpretability: Since all machine learning models are essentially black \\nboxes, their interpretability requirements have to be determined by the banks and financial institutions based on the risk associated with their use cases [28]. While some use cases may demand a highly granular and transparent interpretation of the model’ s working, the requirements for some use cases may not be so stringent. For example, in credit granting by banks to its customers, there may be a clear explana -\\ntion required to be given by a machine learning model in cases where such credits are refused by the banks. However, another use case that involves minimal risk to the bank’ s operations such as recommendation of a product sent to the mobile app installed on a customer’ s hand-held device may not demand any understanding of the reason why the model has made such recommendation.\\nThe model validation process should make sure that models comply with their \\nintended objectives and policies. Despite being black-box in nature, machine learn-ing models come with various provisions for their interpretation. Depending on the type of the model, these approaches may be widely different as discussed below .\\nModels like linear regression which are not only linear but monotonic in their \\nbehavior, the coefficients associated with the explanatory variables exhibit their respective influence on the target variable in the model.\\nEnsemble models such as ada boosting or gradient boosting, are nonlinear but \\nmonotonic in their behavior. In these monotonic models, if the explanatory vari-ables are restricted in their values, the restriction will cause either an increase or a decrease in the value of the target variable. This monotone nature of the models simplifies the contributions of the explanatory variables in the predicted values of the target variable by the model.\\nThe complex deep neural network-based models which are not only nonlinear \\nbut also non-monotonic have methods like Shapley additive explanations (SHAP), and local interpretable model agnostic explanations (LIME) for their global and local interpretability.\\nModel bias: Machine learning models are susceptible to four different types of \\nbias. These biases are, (i) sample bias, (ii) bias in measurement, (iii) bias due to algorithms, and (iv) bias towards or against a particular category of people [29]. For ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='fe6f841d-dc78-4088-b12c-5c5828b139bb', embedding=None, metadata={'page_label': '8', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n8example, the algorithm used in building a random forest model has a bias towards \\ninput features that have a more distinct set of values. For example, a model built on a random forest algorithm for assessing potential money laundering activities is likely to be biased towards the features with a higher number of levels in its catego-ries (e.g., occupation), while features having a lower number of categorical levels (e.g., country) might be better suited to detect money laundering activities. To counter the issues about algorithmic bias, the validation processes must be equipped with the ability to select the most appropriate algorithm in a given context. Feature engineering and designing challenger models are some of the methods to counter algorithmic biases in models. The bias against or in favor of a particular group of people can be avoided by defining a fair set of policies by the banks and financial institutions. Models should be tested for fairness for various cases, and necessary corrections should be made in case aberrant outputs are produced by the models.\\nExtensive feature engineering: The task of feature engineering involves much \\nmore complications in machine learning and deep learning models than classical statistical models. The factors that contribute to the increased complexity in feature engineering in machine learning are as follows: The first and the most obvious reason is the large number of features involved in machine learning models. First, machine-learning models usually involve a very large number of input variables. The second reason is due to the increased use of unstructured data input in machine learning models. Unstructured data like text, images, and speech involve an enor-mously large number of features after data preprocessing which add to the com-plexity in modeling. The use of commercial-off-the-shelf frameworks in modeling such as AutoML has also led to an increased number of features as these frameworks automatically generate derived features from the raw data for providing a better fit of the models into the data in the training phase. While such an approach leads to better training, it is very likely to yield overfitted models in most practical use cases. The banks must have a robust feature engineering strategy in place for mitigating their operational and business risks. The feature strategy is likely to be different for a diverse set of applications. In the case of highly critical and risk-intensive applica -\\ntions like the evaluation of credit-worthiness of customers, every single feature in the model needs to be assessed very closely. On the other hand, for routine appli-cations involving low risks, an overall review of the feature engineering process involving a robust data wrangling step may be sufficient.\\nModel hyperparameters: In machine learning models, the algorithms have \\nparameters associated with them that are not parameters of the models. For example, the number of levels in the constituent decision trees of a random forest (also known as the depth of the trees), or the number of hidden layers in the architecture of a deep learning model must be decided before the models can be trained. Stated differently, the parameters are not determined from the training data of the models, and these are called hyperparameters of the models. The values of hyperparameters in machine learning models are most often determined by trial-and-error methods or brute force search methods like grid search. The absence of an exact and efficient way of finding the optimum values of the hyperparameters makes designing machine learning and deep learning models a particularly challenging task as a wrong choice of values of the hyperparameters can lead to imprecise models. Of late, banks and other financial institutions are depending more on sophisticated binary classification models built on support vector machines with the additional capability of text analytics for ana -\\nlyzing customer complaints. However, these models will be difficult to generalize for a multitude of applications as they will be sensitive to the kernel used in the training.\\nProduction readiness of models: Unlike statistical models which are designed \\nas an aggregation of rules of codes to be executed in a production system, machine learning models are built on algorithms requiring intensive computations most ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='f5e08bea-1327-4346-9d0b-2f80932268d6', embedding=None, metadata={'page_label': '9', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='9Introductory Chapter: Machine Learning in Finance-Emerging Trends and Challenges\\nDOI: http://dx.doi.org/10.5772/intechopen.101120\\nof the time. However, in many situations, financial model developers ignore this \\nimportant point and tend to build overly complex models only to find later that the production systems of the banks are unable to support such complexity. A very simple example could be a highly complex deep learning model built for detecting frauds in financial transactions that is unable to satisfy the latency constraint in its response. To ensure that the machine learning models are production-ready, the validation step should make a reliable estimation of the volume of data that the model will require to process on the production architecture [30].\\nDynamic calibration of models: There is an adaptable class of machine learn-\\ning models that can dynamically modify their parameters based on the patterns in the data [31]. An obvious example is a model built on the reinforcement learning approach. While the autonomous learning of such models is a great boon, there is also a new type of risk associated with such models. In absence of sufficient external control and with too much emphasis on learning from the short-term patterns on the data, the long-term performance of the models may be adversely affected. The consequence is an additional complexity in financial modeling – when to recalibrate the model dynamically? The dynamic recalibration time will also need to be adapted for different applications like algorithmic trading, creditworthiness determination, etc. A comprehensive validation process should now include a set of policies that will guide the modelers in evaluating dynamic recalibration so that the model can adhere to its intended objectives while appropriate controls are in place for ensuring that risks are mitigated when they emerge. This is surely not going to be an easy task as it will involve the complex job of thresholding, identifying the health of the models based on their critical metrics of performance on out-of-sample data.\\nExplainable artificial intelligence: In the explainable artificial intelligence par-\\nadigm, an AI program scans through the code of another AI program and attempts to explain the operating steps and the output yielded by the latter program. This approach can be exploited to adjust the values of the explanatory variables in a pre-dictive model so that the desired value of the target variable (i.e., the output of the model) is obtained [32]. In this way, explainable AI provides a very easy and elegant way to record, analyze and interpret the learning method of a complex model and for repeating the same in the future. Although the computing paradigm is still in research labs, its adoption in a commercial environment especially in the financial industries is not far away.\\n7. Conclusion\\nIn the days to come, the financial industry will show increasingly more reliance \\non machine learning and artificial intelligence-based emerging methods and mod-els to leverage competitive advantages. While the regulatory and compliance will evolve into a more standardized framework, machine learning will continue to pro-vide the banks and other financial institutions more opportunities to explore and exploit emerging applications, while being more efficient in delivering the existing services. While the emerging techniques discussed in the chapter will play their critical roles in mitigating future risks in models, they will also guide the authorities in designing effective regulations and compliance frameworks in risk-intensive applications like creditworthiness assessment, trade surveillance, and capital asset pricing. The model validation process will increasingly be adapted to mitigate machine learning risks, while considerable effort and time will be spent in fine-tuning the model hypermeters in handling emerging applications. However, banks will have more opportunities to deploy the models in a large gamut of applications, gaining competitive business advantages and mitigating risks in operations.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='fd284baa-27cd-4a6d-8a74-cea80fd12c7c', embedding=None, metadata={'page_label': '10', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n10Author details\\nJaydip\\xa0Sen1*, Rajdeep\\xa0Sen2 and Abhishek\\xa0Dutta3\\n1 Department of Data Science, Praxis Business School, Kolkata, India\\n2 Independent Researcher and Financial Analyst3 School of Computing and Analytics, NASHM Knowledge Campus, Kolkata, India* Address all correspondence to: jaydip.sen@acm.org\\n© 2021 The Author(s). Licensee IntechOpen. This chapter is distributed under the terms \\nof the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='017166e0-92a3-4ba6-a288-67453240473f', embedding=None, metadata={'page_label': '11', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='11Introductory Chapter: Machine Learning in Finance-Emerging Trends and Challenges\\nDOI: http://dx.doi.org/10.5772/intechopen.101120\\nReferences\\n[1] Paltrinieri N, Comfort L, Reniers G. \\nLearning about risk: Machine learning \\nfor risk assessment. Safety Science. 2019;118 (2019):475-486. DOI: 10.1016/j.\\nssci.2019.06.001\\n[2] Sen J, Mehtab S. A comparative study \\nof optimum risk portfolio and eigen portfolio on the Indian stock market. International Journal of Business Forecasting and Marketing Intelligence.  Inderscience, Paper ID: IJBFMI-90288, 2021. (Accepted for publication)\\n[3] Lei Y, Peng Q , Shen Y . Deep learning \\nfor algorithmic trading: Enhancing MACD strategy. In: Proc. of the 6th Int. Conf. on Comptg. and Artificial Intelligence . ACM, NY, USA : Tianjin, \\nChina; April 2020. pp. 51-57. DOI: 10.1145/3404555.3404604\\n[4] Dornadula VN, Geetha S. Credit card \\nfraud detection using machine learning algorithms. Procedia Computer Science. 2019;165 (2019):631-641. DOI: 10.1016/j.\\nprocs.2020.01.057\\n[5] Eling M, Nuessl D, Staubli J. The \\nimpact of artificial intelligence along the insurance value chain and on the insurability of risks. Geneva Paper on Risk and Insurance-Issues and Practices. Springer ; 2021. DOI: 10.1057/\\ns41288-020-00201-7\\n[6] Yu S, Chen Y, Zaidi H. AV A: A \\nfinancial service chatbot based on deep bidirectional transformers. Frontiers in Applied Mathematics and Statistics. 2021;7:604842. DOI: 10.3389/fams. 2021.604842\\n[7] Leo M, Sharma S, Maddulety K. \\nMachine learning in banking risk management: A literature review . Risks. 2019;7(1). DOI: 10.3390/risks7010029\\n[8] Gu S, Kelly B, Xiu D. Empirical asset \\npricing via machine learning. The Review of Financial Studies. 2020; 33(5):2233-2273. DOI: 10.1093/\\nrfs/hhaa009\\n[9] Y e T, Zhang L. Derivatives pricing via \\nmachine learning. Journal of Mathematical Finance. 2019;9(3):561-589. DOI: 10.4236/jmf.2019.93029\\n[10] Zand A, Orwell J, Pfluegel E . A \\nsecure framework for anti-money-laundering using machine learning and secret sharing. In: Proc. of Int. Conf. on Cyber Sec. and Protection of Digital Services. USA : IEEE Xplore; June 15-19 \\n2020. pp. 1-7. DOI: 10.1109/CyberSecurity49315.2020.9138889\\n[11] Theodoridis S, Kopsinis Y, \\nSlavakis K. Sparsity-aware adaptive learning: A set theoretic estimation approach. IFAC Proceedings Volumes. 2013;46 (11):748-756. DOI: \\n10.3182/20130703-3-FR-4038.00157\\n[12] Theodoridis S. Chapter 11: Learning \\nin reproducing Kernel Hilbert space. In: Theodoridis S, editor. Machine Learning. Academic Press; 2015. pp. 509-583. DOI: 10.1016/B978-0-12-801522-3.00011-2\\n[13] Zhang Y. The value of Monte Carlo \\nmodel-based variance reduction technology in the pricing of financial derivatives. PLoS ONE. 2020; 15(2):e0229737. DOI: 10.1371/\\njournal.pone.0229737\\n[14] Cardoso JVDM, Palomar DP . \\nLearning undirected graphs in financial markets. In: Proc. of 54\\nth Asilomar Conf. \\non Signals, Systems, and Computers. Pacific Grove, CA, USA: IEEE Xplore; 2020. pp. 741-745. DOI: 10.1109/IEEECONF51394.2020.9443573\\n[15] Fukui T, Sato S, Takahashi A. Style \\nanalysis with particle filtering and generalized simulated annealing. International Journal of Financial Engineering. 2017;4(2-3):1750037. DOI:\\xa010.1142/S2424786317500372', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='3e1ce7be-42b2-423f-9428-115264c291ba', embedding=None, metadata={'page_label': '12', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n12[16] Boyd S, Vandenberghe L. Convex \\nOptimization. Cambridge, UK: \\nCambridge University Press; 2013. Online ISBN: 9780511804441. DOI: 10.1017/CBO9780511804441\\n[17] Sen J, Mehtab S. A time series \\nanalysis-based stock price prediction using machine learning and deep learning models. International Journal of Business Forecasting and Marketing Intelligence. 2020;6(4):272-335. DOI: 10.1504/IJBFMI.2020.115691\\n[18] Sen J, Mehtab S . Accurate stock \\nprice forecasting using robust and optimized deep learning models. In: Proc. of IEEE Int. Conf. on Intelligent Tech (CONIT), USA : IEEE Xplore; June \\n25-27, 2021. DOI: 10.1109/CONIT51480. 2021.9498565.\\n[19] Sen J, Dutta A , Mehtab S. \\nProfitability analysis in stock investment using an LSTM-based deep learning model. In: Proc. of 2\\nnd IEEE Int. Conf. for \\nEmerging Technologies (INCET), Belagavi, India,  USA : IEEE Xplore; May \\n21-23, 2021. pp. 1-9.  DOI: 10.1109/INCET51464.2021.9456385.\\n[20] Mehtab S,  Sen J . Analysis and \\nforecasting of financial time series using CNN and LSTM-based deep learning models. In: Advances in Distributed Computing and Machine Learning: Proc. of ICADCML 2021. Sahoo, J. P . et  al \\neditors. LNNS , Springer . Vol. 302; 2022\\n[21] Mehtab S, Sen J, Dasgupta S. Robust \\nanalysis of stock price time series using CNN and LSTM-based deep learning models. In: Proc. of 4th IEEE Int. Conf. on Electronics, Communication and Aerospace Tech (ICECA). Coimbatore, India; Nov 5-7, 2020. pp. 1481-1486. DOI: 10.1109/ICECA49313.2020.9297652\\n[22] Mehtab S,  Sen J . Stock price \\nprediction using CNN and LSTM-based deep learning models. In: Proc. of IEEE Int. Conf. on Decision Aid Sciences and Applications (DASA), pp. 447-453, Nov 8-9, 2020, Bahrain. DOI: 10.1109/DASA51403.2020.9317207.\\n[23] Mehtab S,  Sen J,  Dutta A . Stock \\nprice prediction using machine learning and LSTM-based deep learning models. In: Machine Learning and Metaheuristics Algorithms, and Applications (SoMMA), 2020, pp. 88-106, Springer Nature, Singapore. DOI: 10.1007/978-981-16- 0419-5_8.\\n[24] Mehtab S, Sen J. Stock price \\nprediction using convolutional neural networks on a multivariate time series. In: Proc. of 3\\nrd Nat. Conf. on Machine \\nLearning and Artificial Intelligence (NCMLAI). New Delhi, India; Feb 1, 2020. DOI: 10.36227/techrxiv . 15088734.v1\\n[25] Mehtab S, Sen J. A robust predictive \\nmodel for stock price prediction using deep learning and natural language processing. In: Proc. of 7\\nth Int. Conf. on \\nBusiness Analytics and Intelligence (BAICONF). Bangalore, India; Dec 5-7, 2019. DOI: 10.36227/techrxiv .15023361.v1\\n[26] Sen J. Stock price prediction using \\nmachine learning and deep learning frameworks. In: Proc. of 6th Int. Conf. on Business Analytics and Intelligence (ICBAI). Bangalore, India; Dec 20-21, 2018\\n[27] L. Cao. AI in Finance: Challenges, \\nTechniques, and Opportunities. USA: Cornell University; 2021. Available online at: https://arxiv .org/abs/2107.09051 (accessed on Oct 7, 2021)\\n[28] Rudin C. Stop explaining black-box \\nmachine learning models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence. 2019;1:206-215. DOI: 10.1038/s42256- 019-0048-x\\n[29] Huang J, Chai J. Deep learning in \\nfinance and banking: A literature review ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='178ffeab-57a1-4dce-b6c9-3867e304f1fd', embedding=None, metadata={'page_label': '13', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='13Introductory Chapter: Machine Learning in Finance-Emerging Trends and Challenges\\nDOI: http://dx.doi.org/10.5772/intechopen.101120\\nand classification. Frontiers of Business \\nResearch in China. 2020;14 , Art Id: 13. \\nDOI: 10.1186/s11782-020-00082-6\\n[30] Studer S, Bui TB, Drescher C, \\nHanuschkin A, Winkler L, Peters S,  et al. Towards CRISP-ML(Q): A machine learning process model with quality assurance methodology. Machine Learning Knowledge Extraction. 2021;3(2):392-413. DOI: 10.3390/make3020020\\n[31] Liu S, Borovykh A, Grzelak LA, \\nOosterlee CW. A neural network-based framework for financial model calibration. Journal of Mathematics in Industry. 2019;9, Art Id: 9. DOI: 10.1186/s13362-019-0066-7\\n[32] Bussmann N, Giudici P , Marnelli D, \\nPapenbrock J. Explainable AI in fintech risk management. Frontiers in Artificial Intelligence. 2019;3, Art Id: 26. DOI: 10.3389/frai.2020.00026', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='2e4c09e8-e9c9-44ec-a153-6bb1a16db769', embedding=None, metadata={'page_label': '14', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='1f209387-9ea0-40bb-bc4a-515d3520528c', embedding=None, metadata={'page_label': '15', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 2\\nDesign and Analysis of Robust\\nDeep Learning Models for Stock\\nPrice Prediction\\nJaydip Sen and Sidra Mehtab\\nAbstract\\nBuilding predictive models for robust and accurate prediction of stock prices and\\nstock price movement is a challenging research problem to solve. The well-known\\nefficient market hypothesis believes in the impossibility of accurate prediction offuture stock prices in an efficient stock market as the stock prices are assumed to bepurely stochastic. However, numerous works proposed by researchers have dem-onstrated that it is possible to predict future stock prices with a high level ofprecision using sophisticated algorithms, model architectures, and the selection ofappropriate variables in the models. This chapter proposes a collection of predictiveregression models built on deep learning architecture for robust and precise predic-\\ntion of the future prices of a stock listed in the diversified sectors in the National\\nStock Exchange (NSE) of India. The Metastock tool is used to download the histor-ical stock prices over a period of two years (2013 –2014) at 5 minutes intervals.\\nWhile the records for the first year are used to train the models, the testing iscarried out using the remaining records. The design approaches of all the modelsand their performance results are presented in detail. The models are also comparedbased on their execution time and accuracy of prediction.\\nKeywords: Stock Price Forecasting, Deep Learning, Univariate Analysis,\\nMultivariate Analysis, Time Series Regression, Root Mean Square Error (RMSE),\\nLong-and-Short-Term Memory (LSTM) Network, Convolutional Neural Network(CNN)\\n1. Introduction\\nBuilding predictive models for robust and accurate prediction of stock prices and\\nstock price movement is a very challenging research problem. The well-knownefficient market hypothesis precludes any possibility of accurate prediction offuture stock prices since it assumes stock prices to be purely stochastic in nature.Numerous works in the finance literature have shown that robust and preciseprediction of future stock prices is using sophisticated machine learning and deeplearning algorithms, model architectures, and selection of appropriate variables in\\nthe models.\\nTechnical analysis of stocks has been a very interesting area of work for the\\nresearchers engaged in security and portfolio analysis. Numerous approaches to\\ntechnical analysis have been proposed in the literature. Most of the algorithms here\\n15', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='81a08285-9c7c-47a0-a1a4-77702fb05e7f', embedding=None, metadata={'page_label': '16', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='work on searching and finding some pre-identified patterns and sequences in the\\ntime series of stock prices. Prior detection of such patterns can be useful for the\\ninvestors in the stock market in formulating their investment strategies in the\\nmarket to maximize their profit. A rich set of such patterns has been identified inthe finance literature for studying the behavior of stock price time series.\\nIn this chapter, we propose a collection of forecasting models for predicting the\\nprices of a critical stock of the automobile sector of India. The predictive frameworkconsists of four CNN regression models and six models of regression built on thelong-and-short-term memory (LSTM) architecture. Each model has a different archi-\\ntecture, different shapes of the input data, and different hyperparameter values.\\nThe current work has the following three contributions. First, unlike the cur-\\nrently existing works in the literature, which mostly deal with time-series data ofdaily or weekly stock prices, the models in this work are built and tested on stockprice data at a small interval of 5 minutes. Second, our propositions exploit thepower of deep learning, and hence, they achieve a very high degree of precision androbustness in their performance. Among all models proposed in this work, thelowest ratio of the root mean square error (RMSE) to the average of the target\\nvariable is 0.006967. Finally, the speed of execution of the models is very fast. The\\nfastest model requires 174.78 seconds for the execution of one round on the target\\nhardware platform. It is worth mentioning here that the dataset used for traininghas 19500 records, while models are tested on 20500 records.\\nThe chapter is organized as follows. Section 2 briefly discusses some related\\nworks in the literature. In Section 3, we discuss the method of data acquisition, themethodology followed, and the design details of the ten predictive models proposedby us. Section 4 exhibits the detailed experimental results and their analysis. Acomparative study of the performance of the models is also made. In Section 5, we\\nconclude the chapter and identify a few new directions of research.\\n2. Related work\\nThe literature on systems and methods of stock price forecasting is quite rich.\\nNumerous proposals exist on the mechanisms, approaches, and frameworks for\\npredicting future stock prices and stock price movement patterns. At a broad level,these propositions can be classified into four categories. The proposals of the firstcategory are based on different variants of univariate and multivariate regressionmodels. Some of the notable approaches under this category are - ordinary least\\nsquare (OLS) regression, multivariate adaptive regression spline (MARS), penalty-\\nbased regression ,polynomial regression , etc. [1 –4]. These approaches are not, in gen-\\neral, capable of handling the high degree of volatility in the stock price data. Hence,quite often, these models do not yield an acceptable level of accuracy in prediction.Autoregressive integrated moving average (ARIMA) and other approaches of econo-\\nmetrics such as cointegration ,vector autoregression (VAR), causality tests, and quantile\\nregression (QR), are some of the methods which fall under the second category of\\npropositions [5 –16]. The methods of this category are superior to the simple\\nregression-based methods. However, if the stock price data are too volatile and\\nexhibit strong randomness, the econometric methods also are found to be inade-\\nquate, yielding inaccurate forecasting results. The learning-based approach is thesalient characteristic of the propositions of the third category. These proposals arebased on various algorithms and architectures of machine learning, deep learning,and reinforcement learning [17 –41]. Since the frameworks under this category use\\ncomplex predictive models working on sophisticated algorithms and architectures,the prediction accuracies of these models are found to be quite accurate in real-\\n16Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='1f2a3060-89fb-4ade-9965-b641b3d9991a', embedding=None, metadata={'page_label': '17', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='world applications. The propositions of the fourth category are broadly based on\\nhybrid models built of machine learning and deep learning algorithms and archi-\\ntectures and also on the relevant inputs of sentiment and news items extracted from\\nthe social web [42 –47]. These models are found to yield the most accurate predic-\\ntion of future stock prices and stock price movement patterns. The information-\\ntheoretic approach and the wavelet analysis have also been proposed in stock price\\nprediction [48, 49]. Several portfolio optimization methods have also been presented\\nin some works using forecasted stock returns and risks [50– 55].\\nIn the following, we briefly discuss the salient features of some of the works\\nunder each category. We start with the regression-based proposals.\\nEnke et al. propose a multi-step approach to stock price prediction using a\\nmultiple regression model [2]. The proposition is based on a differential-evolution-\\nbased fuzzy clustering model and a fuzzy neural network. Ivanovski et al. present a\\nlinear regression and correlation study on some important stock prices listed in theMacedonian Stock Exchange [3]. The results of the work indicate a strong relation-ship between the stock prices and the index values of the stock exchange. Sen andDatta Chaudhuri analyze the trend and the seasonal characteristics of the capitalgoods sector and the small-cap sector of India using a time series decomposition\\napproach and a linear regression model [4].\\nAmong the econometric approaches, Du proposes an integrated model combin-\\ning an ARIMA and a backpropagation neural network for predicting the future\\nindex values of the Shanghai Stock Exchange [6]. Jarrett and Kyper present anARIMA-based model for predicting future stock prices [7]. The study conducted bythe authors reveals two significant findings: (i) higher accuracy is achieved bymodels involving fewer parameters, and (ii) the daily return values exhibit a strongautoregressive property. Sen and Datta Chaudhuri different sectors of the Indian\\nstock market using a time series decomposition approach and predict the future\\nstock prices using different types of ARIMA and regression models [9 –14, 33].\\nZhong and Enke present a gamut of econometric and statistical models, includingARIMA, generalized autoregressive conditional heteroscedasticity (GARCH), smoothing\\ntransition autoregressive (STAR), linear and quadratic discriminant analysis [16].\\nMachine learning and deep learning models have found widespread applications\\nin designing predictive frameworks for stock prices. Baek and Kim propose aframework called ModAugNet, which is built on an LSTM deep learning model [17].\\nChou and Nguyen preset a sliding window metaheuristic optimization method for\\nstock price prediction [19]. Gocken et al. propose a hybrid artificial neural network\\nusing harmony search and genetic algorithms to analyze the relationship betweenvarious technical indicators of stocks and the index of the Turkish stock market[21]. Mehtab and Sen propose a gamut of models designed using machine learningand deep learning algorithms and architectures for accurate prediction of futurestock prices and movement patterns [22 –28, 34, 35]. The authors present several\\nmodels which are built on several variants of convolutional neural networks (CNNs)\\nand long-and-short-term memory networks (LSTMs) that yield a very high level of\\nprediction accuracy. Zhang et al. present a multi-layer perceptron for financial datamining that is capable of recommending buy or sell strategies based on forecastedprices of stocks [40].\\nThe hybrid models use relevant information in the social web and exploit the\\npower of machine learning and deep learning architectures and algorithms formaking predictions with a high level of accuracy. Among some well-known hybridmodels, Bollen et al. present a scheme for computing the mood states of the public\\nfrom the Twitter feeds and use the mood states information as an input to a\\nnonlinear regression model built on a self-organizing fuzzy neural network [43]. The\\nmodel is found to have yielded a prediction accuracy of 86%. Mehtab and Sen\\n17Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='8f24ddf4-cd05-4a22-9f87-56511aab53cc', embedding=None, metadata={'page_label': '18', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='propose an LSTM-based predictive model with a sentiment analysis module that\\nanalyzes the public sentiment on Twitter and produces a highly accurate forecast of\\nfuture stock prices [45]. Chen et al. present a scheme that collects relevant news\\narticles from the web, converts the text corpus into a word feature set, and feeds thefeature set of words into an LSTM regression model to achieve a highly accurateprediction of the future stock prices [44].\\nThe most formidable challenge in designing a robust predictive model with a\\nhigh level of precision for stock price forecasting is handling the randomness andthe volatility exhibited by the time series. The current work utilizes the power ofdeep learning models in feature extraction and learning while exploiting their\\narchitectural diversity in achieving robustness and accuracy in stock price\\nprediction on very granular time series data.\\n3. Methodology\\nWe propose a gamut of predictive models built on deep learning architectures.\\nWe train, validate, and then test the models based on the historical stock pricerecords of a well-known stock listed in the NSE, viz. Century Textiles . The historical\\nprices of Century Textiles stock from 31st Dec 2012, a Monday to 9th Jan 2015, aFriday, are collected at 5 minutes intervals using the Metastock tool [56]. We carryout the training and validation of the models using the stock price data from 31st\\nDec 2012 to 30th Dec 2013. The models are tested based on the records for the\\nremaining period, i.e., from 31st Dec 2013, to 9th Jan 2015. For maintaining unifor-mity in the sequence, we organize the entire dataset as a sequence of daily recordsarranged on a weekly basis from Monday to Friday. After the dataset is organizedsuitably, we split the dataset into two parts –the training set and the test set. While\\nthe training dataset consists of 19500 records, there are 20500 tuples in the testdata. Every record has five attributes –open, high, low, close, and volume. We have\\nnot considered any adjusted attribute (i.e., adjusted close, adjusted volume, etc.) in\\nour analysis.\\nIn this chapter, we present ten regression models for stock price forecasting\\nusing a deep learning approach. For the univariate models, the objective is to\\nforecast the future values of the variable open based on its past values. On the other\\nhand, for the multivariate models, the job is to predict the future values of open\\nusing the historical values of all the five attributes in the stock data. The models aretested following an approach known as multi-step prediction using a walk-forward\\nvalidation [22]. In this method, we use the training data for constructing the models.\\nThe models are then used for predicting the daily open values of the stock prices for\\nthe coming week. As a week completes, we include the actual stock price records ofthe week in the training dataset. With this extended training dataset, the openvalues are forecasted with a forecast horizon of 5 days so that the forecast for thedays in the next week is available. This process continues till all the records in thetest dataset are processed.\\nThe suitability of CNNs in building predictive models for predicting future stock\\nprices has been demonstrated in our previous work [22]. In the current work, we\\npresent a gamut of deep learning models built on CNN and LSTM architectures and\\nillustrate their efficacy and effectiveness in solving the same problem.\\nCNNs perform two critical functions for extracting rich feature sets from input\\ndata. These functions are: (1) convolution and (2) pooling or sub-sampling [57]. A rich\\nset of features is extracted by the convolution operation from the input, while thesub-sampling summarizes the salient features in a given locality in the featurespace. The result of the final sub-sampling in a CNN is passed on to possibly\\n18Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='7c2a3562-e23d-496d-b0ac-975cf68f27a9', embedding=None, metadata={'page_label': '19', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='multiple dense layers. The fully connected layers learn from the extracted features.\\nThe fully connected layers provide the network with the power of prediction.\\nLSTM is an adapted form of a recurrent neural network (RNN) and can interpret\\nand then forecast sequential data like text and numerical time series data [57]. Thenetworks have the ability to memorize the information on their past states in somedesignated cells in memory. These memory cells are called gates. The information on\\nthe past states, which is stored in the memory cells, is aggregated suitably at theforget gates by removing the irrelevant information. The input gates, on the otherhand, receive information available to the network at the current timestamp.Using the information available at the input gates and the forget gates, the\\ncomputation of the predicted values of the target variable is done by the network.\\nThe predicted value at each timestamp is made available through the output gate ofthe network [57].\\nThe deep learning-based models we present in this paper differ in their design,\\nstructure, and dataflows. Our proposition includes four models based on the CNNarchitecture and six models built on the LSTM network architecture. The proposedmodels are as follows. The models have been named following a convention. Thefirst part of the model ’s name indicates the model type (CNN or LSTM), the second\\npart of the name indicates the nature of the input data (univariate or multivariate).Finally, the third part is an integer indicating the size of the input data to the model(5 or 10). The ten models are as follows:\\n(i) CNN_UNIV_5 –a CNN model with an input of univariate open values of\\nstock price records of the last week, (ii) CNN_UNIV_10 –a CNN model with an\\ninput of univariate open values of stock price records of the last couple of weeks,(iii) CNN_MULTV_10 –a CNN model with an input of multivariate stock price\\nrecords consisting of five attributes of the last couple of weeks, where each variable\\nis passed through a separate channel in a CNN, (iv) CNN_MULTH_10 –a CNN\\nmodel with the last couple of weeks ’multivariate input data where each variable is\\nused in a dedicated CNN and then combined in a multi-headed CNN architecture,\\n(v) LSTM_UNIV_5 –an LSTM with univariate open values of the last week as the\\ninput, (vi) LSTM_UNIV_10 –an LSTM model with the last couple of weeks ’uni-\\nvariate open values as the input, (vii) LSTM_UNIV_ED_10 –an LSTM having an\\nencoding and decoding ability with univariate open values of the last couple ofweeks as the input, (viii) LSTM_MULTV_ED_10 –an LSTM based on encoding and\\ndecoding of the multivariate stock price data of five attributes of the last couple ofweeks as the input, (ix) LSTM_UNIV_CNN_10 –a model with an encoding CNN\\nand a decoding LSTM with univariate open values of the last couple of weeks as theinput, and (x) LSTM_UNIV_CONV_10 –a model having a convolutional block for\\nencoding and an LSTM block for decoding and with univariate open values of thelast couple of weeks as the input.\\nWe present a brief discussion on the model design. All the hyperparameters (i.e.,\\nthe number of nodes in a layer, the size of a convolutional, LSTM or pooling layer,\\netc.) used in all the models are optimized using grid-search. However, we have not\\ndiscussed the parameter optimization issues in this work.\\n3.1 The CNN_UNIV_5 model\\nThis CNN model is based on a univariate input of open values of the last week ’s\\nstock price records. The model forecasts the following five values in the sequence as\\nthe predicted daily open index for the coming week. The model input has a shape\\n(5, 1) as the five values of the last week ’s daily open index are used as the input.\\nSince the input data for the model is too small, a solitary convolutional block and asubsequent max-pooling block are deployed. The convolutional block has a feature\\n19Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='79559f4c-1799-47fe-b28d-904cd682ce8d', embedding=None, metadata={'page_label': '20', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='space dimension of 16 and the filter (i.e., the kernel) size of 3. The convolutional\\nblock enables the model to read each input three times, and for each reading, it\\nextracts 16 features from the input. Hence, the output data shape of the\\nconvolutional block is (3,16). The max-pooling layer reduces the dimension of thedata by a factor of 1/2. Thus, the max-pooling operation transforms the data shapeto (1, 16). The result of the max-pooling layer is transformed into an array structureof one-dimension by a flattening operation. This one-dimensional vector is thenpassed through a dense layer block and fed into the final output layer of the model.\\nThe output layer yields the five forecasted open values in sequence for the coming\\nweek. A batch size of 4 and an epoch number of 20 are used for training the model.\\nThe rectified linear unit (ReLU) activation function and the Adam optimizer for the\\ngradient descent algorithm are used in all layers except the final output layer. In the\\noutput layer of the model, the sigmoid is used as the activation function. The use of\\nthe activation function and the optimizer is the same for all the models. Theschematic architecture of the model is depicted in Figure 1 .\\nWe compute the number of trainable parameters in the CNN_UNIV_5 model. As\\nthe role of the input layer is to provide the input data to the network, there is nolearning involved in the input layer. There is no learning in the pooling layers as all\\nthese layers do is calculate the local aggregate features. The flatten layers do not\\ninvolve any learning as well. Hence, in a CNN model, the trainable parameters areinvolved only in the convolutional layers and the dense layers. The number oftrainable parameters ( n\\n1) in a one-dimensional convolutional layer is given by (1),\\nwhere kis the kernel size, and dand fare the sizes of the feature space in the\\nprevious layer and the current layer, respectively. Since each element in the featurespace has a bias, the term 1 is added in (1)\\nn\\n1¼k∗dþ1 ðÞ ∗f (1)\\nThe number of parameters ( n2) in a dense layer of a CNN is given by (2), in\\nwhich pcurrentand ppreviousrefer to the node count in the current layer and the\\nFigure 1.\\nThe schematic architecture of the model CNN_UNIV_5.\\n20Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='6f097c84-40c2-492f-afcc-5dd36e1d6850', embedding=None, metadata={'page_label': '21', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='previous layer, respectively. The second term on the right-hand side of (2) refers to\\nthebiasterms for the nodes in the current layer.\\nn2¼pcurr∗pprev/C16/C17\\nþ1∗pcurr(2)\\nThe computation of the number of parameters in the CNN_UNIV_5 model is\\npresented in Table 1 . It is observed that the model involves 289 trainable parame-\\nters. The number of parameters in the convolutional layer is 64, while the two denselayers involve 170 and 55 parameters, respectively.\\n3.2 The CNN_UNIV_10 model\\nThis model is based on a univariate input of the open values of the last couple of\\nweeks ’stock price data. The model computes the five forecasted daily open values in\\nsequence for the coming week. The structure and the data flow for this model are\\nidentical to the CNN_UNIV_5 model. However, the input of the model has a shape\\nof (10, 1). We use 70 epochs and 16 batch-size for training the model. Figure 2\\nshows the architecture of the model CNN_UNIV_10. The computation of the num-\\nber of parameters in the model CNN_UNIV_10 is exhibited in Table 2.\\nLayer kd f pprevpcurrn1 n2 #params\\nConv1D (conv1d) 3 1 16 64 64\\nDense (dense) 16 10 170 170\\nDense (dense_1) 10 5 55 55\\nTotal #parameters 289\\nTable 1.\\nComputation of the number of params in the model CNN_ UNIV_5.\\nFigure 2.The architecture of the model CNN_ UNIV_10.\\n21Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='b6bc8aa5-4f0d-450b-99c5-e070dc3ac11e', embedding=None, metadata={'page_label': '22', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='It is evident from Table 2 that the CNN_UNIV_10 involves 769 trainable\\nparameters. The parameter counts for the convolutional layer, and the two dense\\nlayers are 64, 650, and 55 respectively.\\n3.3 The CNN_MULTV_10 model\\nThis CNN model is built on the input of the last two weeks ’multivariate stock\\nprice records data. The five variables of the stock price time series are used in a\\nCNN in five separate channels. The model uses a couple of convolutional layers,each of size (32, 3). The parameter values of the convolutional blocks indicate that32 features are extracted from the input data by each convolutional layer using afeature map size of 32 and a filter size of 3. The input to the model has a shape of\\n(10, 5), indicating ten records, each record having five features of the stock price\\ndata. After the first convolutional operation, the shape of the data is transformed to(8, 32). The value 32 corresponds to the number of features extracted, while thevalue 8 is obtained by the formula: f=(k-n) +1, where, k= 10, n= 3, hence, f= 8.\\nSimilarly, the output data shape of the second convolutional layer is (6, 32). A max-pooling layer reduces the feature space size by a factor of 1/2 producing an outputdata shape of (3, 32). The max-pooling block ’s output is then passed on to a third\\nconvolutional layer with a feature map of 16 and a kernel size of 3. The data shape of\\nthe output from the third convolutional layer becomes (1, 16) following the same\\ncomputation rule. Finally, another max-pooling block receives the results of thefinal convolutional layer. This block does not reduce the feature space since theinput data shape to it already (1, 16). Hence, and the output of the final max-pooling layer remains unchanged to (1,16). A flatten operation follows that convertsthe 16 arrays containing one value to a single array containing 16 values. The outputof the flatten operation is passed on to a fully connected block having 100 nodes.Finally, the output block with five nodes computes the predicted daily open index\\nof the coming week. The epochs size and the batch size used in training the model\\nare 70 and 16, respectively. Figure 3 depicts the CNN_MULTV_10 model. Table 3\\nshows the computation of the number of trainable parameters involved in themodel.\\nFrom Table 3 , it is observed that the total number of trainable parameters in the\\nmodel CNN_MULTV_10 is 7373. The three convolutional layers conv1d_4 ,conv1d_5 ,\\nand conv1d_6 involve 512, 3014, and 1552 parameters, respectively. It is to be noted\\nthat the value of kfor the first convolutional layer, conv1d_4 , is multiplied by a\\nfactor of five since there are five attributes in the input data for this layer. The twodense layers, dense_3 and dense_4 include 1700 and 505 parameters, respectively.\\n3.4 The CNN_MULTH_10 model\\nThis CNN model uses a dedicated CNN block for each of the five input attributes\\nin the stock price data. In other words, for each input variable, a separate CNN isLayer kd f pprevpcurrn1 n2 #params\\nConv1D (conv1d) 3 1 16 64 64\\nDense (dense) 64 10 650 650\\nDense (dense_1) 10 5 55 55\\nTotal #parameters 769\\nTable 2.\\nThe number of parameters in the model CNN_ UNIV_10 model.\\n22Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='00810e8b-f402-40f4-b093-ebaca8fbbd91', embedding=None, metadata={'page_label': '23', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='used for feature extrication. We call this a multivariate and multi-headed CNN\\nmodel. For each sub-CNN model, a couple of convolutional layers were used. Theconvolutional layers have a feature space dimension of 32 and a filter size (i.e.,kernel size) of 3. The convolutional layers are followed by a max-pooling layer. Thesize of the feature space is reduced by a factor of 1/2 by the max-pooling layer.\\nFollowing the computation rule discussed under the CNN_MULTV_10 model, the\\ndata shape of the output from the max-pooling layer for each sub-CNN model is (3,32). A flatten operation follows converting the data into a single-dimensional arrayof size 96 for each input variable. A concatenation operation follows that concate-nates the five arrays, each containing 96 values, into a single one-dimensional arrayof size 96*5 = 480. The output of the concatenation operation is passed successivelythrough two dense layers containing 200 nodes and 100 nodes, respectively. In the\\nFigure 3.\\nThe schematic architecture of the model CNN_MULTV_10.\\nLayer k d fpprevpcurrn1 n2 #params\\nConv1D (conv1d_4) 3*5 1 32 512 512\\nConv1D (conv1d_5) 3 32 32 3104 3014\\nConv1D (conv1d_6) 3 32 16 1552 1552\\nDense (dense_3) 16 100 1700 1700\\nDense (dense_4) 100 5 505 505\\nTotal #parameters 7373\\nTable 3.\\nThe number of parameters in the model CNN_MULTV_10.\\n23Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='cd79d162-9dd4-46cb-bd8c-646f09450879', embedding=None, metadata={'page_label': '24', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='end, the output layer having five nodes yields the forecasted five values as the daily\\nopen stock prices for the coming week. The epoch number and the batch size used in\\ntraining the model are 70 and 16, respectively. Figure 4 shows the structure and\\ndata flow of the CNN_MULTH_10 model.\\nTable 4 presents the necessary calculations for finding the number of parame-\\nters in the CNN_MULTH_10 model. Each of the five convolutions layers, conv1d_1 ,\\nconv1d_3 ,conv1d_5 ,conv1d_7 , and convid_9 , involves 128 parameters. For each of\\nthese layers, k= 3,d= 1 and f= 3, and hence the number of trainable parameters is:\\n(3 * 1 + 1) * 32 = 128. Hence, for the five convolutional layers, the total number ofparameters is 128 * 5 = 640. Next, for each of the five convolutional layers,\\nconv1d_2, conv1d_4, conv1d_6, conv1d_8, and con1d_10, involves 3104. Each layer\\nof this group has k= 3,d= 32, and f= 32. Hence the number of trainable parameters\\nfor each layer is: (3*32 + 1) * 32 = 3104. Therefore, for the five convolutional layers,the total number of parameters is 3104 * 5 = 15, 520. The dense layers, dense_1 ,\\ndense_2 , and dense_3 involve 96200, 20100, and 505 parameters using (2). Hence,\\nthe model includes 132,965 parameters.\\n3.5 The LSTM_UNIV_5 model\\nThis model is based on an input of the univariate information of the open values\\nof the last week ’s stock price records. The model predicts the future five values in\\nFigure 4.\\nThe schematic architecture of the model CNN_MULTH_10.\\nLayer kd fpprevpcurrn1 n2 #params\\nConv1D (conv1d_1, conv1d_3, conv1d_5, conv1d_7,\\nconv1d_9)3 1 32 640\\n640\\nConv1D (conv1d_2, convid_4, conv1d_6, conv1d_8,\\nconv1d_10)3 32 32 15520 15520\\nDense (dense_1) 480 200 96200 96200\\nDense (dense_2) 200 100 20100 20100\\nDense (dense_3) 100 5 505 505\\nTotal #parameters 132965\\nTable 4.\\nThe number of parameters in the model CNN_MULTH_10 model.\\n24Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='058faa46-f0c6-4bb9-8b70-7d406d8dcf4c', embedding=None, metadata={'page_label': '25', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='sequence as the daily open index for the coming week. The input has a shape of\\n(5, 1) that indicates that the previous week ’s daily open index values are passed as\\nthe input. An LSTM block having 200 nodes receives that data from the input layer.\\nThe number of nodes at the LSTM layer is determined using the grid-search . The\\nresults of the LSTM block are passed on to a fully connected layer (also known as adense layer) of 100 nodes. Finally, the output layer containing five nodes receivesthe output of the dense layer and produces the following five future values of openfor the coming week. In training the model, 20 epochs and 16 batch-size are used.Figure 5 presents the structure and data flow of the model .\\nAs we did in the case of the CNN models, we now compute the number of\\nparameters involved in the LSTM model. The input layers do not have any param-eters, as the role of these layers is to just receive and forward the data. There arefour gates in an LSTM network that have the same number of parameters. Thesefour gates are known as (i) forget gate , (ii) input gate , (iii) input modulation gate , and\\ntheoutput gate . The number of parameters ( n\\n1) in each of the gates in an LSTM\\nnetwork is computed using (3), where xdenotes the number of LSTM units, and yis\\nthe input dimension (i.e., the number of features in the input data)\\nn1¼xþyðÞ ∗xþx (3)\\nHence, the total number of parameters in an LSTM layer will be given by 4 * n1.\\nThe number of parameters ( n2) in a dense layer of an LSTM network is computed\\nusing (4), where pprevand pcurrare the number of nodes in the previous layer and\\nthe current layer, respectively. The bias parameter of each node in the current layeris represented by the last term on the right-hand side of (4).\\nn\\n2¼pprev∗pcurrþpcurr/C16/C17\\n(4)\\nThe computation of the number of parameters associated with the model\\nLSTM_UNIV_5 is depicted in Table 5 . InTable 5 , the number of parameters in the\\nLSTM layer is computed as follows: 4*[(200 + 1) * 200 + 200] = 161,600. Thenumber of parameters in the dense layer, dens_4 is computed as: (200 *100 + 100) = 20,100. Similarly, the parameters in the dense layers, dense_5 and\\nFigure 5.\\nThe schematic architecture of the model LSTM_UNIV_5.\\n25Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='2ad40cc6-e0de-4548-8d56-9038d68e7536', embedding=None, metadata={'page_label': '26', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='dense_6 , are computed. The total number of parameters in the LSTM_UNIV_5\\nmodel is found to be 182, 235.\\n3.6 The LSTM_UNIV_10 model\\nLSTM_UNIV_10 model: This univariate model uses the last couple of weeks ’\\nopen index input and yields the daily forecasted open values for the coming week.\\nThe same values of the parameters and hyperparameters of the modelLSTM_UNIV_5 are used here. Only, the input data shape is different. The input datashape of this model is (10, 1). Figure 6 presents the architecture of this model.\\nTable 6 presents the computation of the number of parameters involved in the\\nmodelLSTM_UNIV_10. Since the number of parameters in the LSTM layersdepends only on the number of features in the input data and the node-count in theLSTM layer, and not on the number of input records in one epoch, the model\\nLSTM_UNIV_10 has an identical number of parameters in the LSTM layer as that of\\nthe model LSTM_UNIV_5. Since both the models have the same number of denselayers and have the same architecture for those layers, the total number of param-eters for both the models are the same.\\n3.7 The LSTM_UNIV_ED_10 model\\nThis LSTM model has an encoding and decoding capability and is based on the\\ninput of the open values of the stock price records of the last couple of weeks. TheLayer x ypprevpcurrn1 n2 #params\\nLSTM (lstm_2) 200 1 40,400 161600\\nDense (dense_4) 200 100 20100 20100\\nDense (dense_5) 100 5 505 505\\nDesne (dense_6) 5 5 30 30\\nTotal #parameters 182235\\nTable 5.\\nThe number of parameters in the model LSTM_ UNIV_5 model.\\nFigure 6.\\nThe schematic architecture of the model LSTM_UNIV_10.\\n26Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='aff33bab-6082-4c0e-9b4d-7de0954ec80e', embedding=None, metadata={'page_label': '27', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='model consists of two LSTM blocks. One LSTM block performs the encoding oper-\\nation, while the other does the decoding. The encoder LSTM block consists of 200nodes (determined using the grid-search procedure). The input data shape to the\\nencoder LSTM is (10, 1). The encoding layer yields a one-dimensional vector of size\\n200 –each value corresponding to the feature extracted by a node in the LSTM layer\\nfrom the ten input values received from the input layer. Corresponding to each\\ntimestamp of the output sequence (there are five timestamps for the outputsequence for the five forecasted open values), the input data features are extracted\\nonce. Hence, the data shape from the repeat vector layer ’s output is (5, 200). It\\nsignifies that in total 200 features are extracted from the input for each of the fivetimestamps corresponding to the model ’s output (i.e., forecasted) sequence. The\\nsecond LSTM block decodes the encoded features using 200 nodes.\\nThe decoded result is passed on to a dense layer. The dense layer learns from the\\ndecoded values and predicts the future five values of the target variable (i.e., open)\\nfor the coming week through five nodes in the output layer. However, the fore-casted values are not produced in a single timestamp. The forecasted values for thefive days are made in five rounds. The round-wise forecasting is done using aTimeDistributedWrapper function that synchronizes the decoder LSTM block, the\\nfully connected block, and the output layer in every round. The number of epochsand the batch sizes used in training the model are 70 and 16, respectively. Figure 7\\npresents the structure and the data flow of the LSTM_UNIV_ED_10 model.\\nThe computation of the number of parameters in the LSTM_UNIV_ED_10\\nmodel is shown in Table 7 . The input layer and the repeat vector layer do not\\ninvolve any learning, and hence these layers have no parameters. On the otherhand, the two LSTM layers, lstm_3 andlstm_4 , and the two dense layers,Layer x ypprevpcurrn1 n2 #params\\nLSTM (lstm_2) 200 1 40,400 161600\\nDense (dense_4) 200 100 20,100 20100\\nDense (dense_5) 100 5 505 505\\nDesne (dense_6) 5 5 30 30\\nTotal #parameters 182235\\nTable 6.\\nThe number of parameters in the model LSTM_ UNIV_10.\\nFigure 7.\\nThe schematic architecture of the model LSTM_UNIV_ED_10.\\n27Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='85df7d2e-7d17-4b4d-adac-dbef47f92378', embedding=None, metadata={'page_label': '28', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='time_distributed_3 , and time_distributed_4 involve learning. The number of param-\\neters in the lstm_3 layer is computed as: 4 * [(200 + 1) * 200 + 200] = 161, 600. The\\ncomputation of the number of parameters in the lstm_4 layer is as follows: 4 *\\n[(200 + 200) * 200 + 200] = 320, 800. The computations of the dense layers ’\\nparameters are identical to those in the models discussed earlier. The total number\\nof parameters in this model turns out to be 5,02,601.\\n3.8 The LSTM_MULTV_ED_10 model\\nThis model is a multivariate version of LSTM_UNIV_ED_10. It uses the last\\ncouple of weeks ’stock price records and includes all the five attributes, i.e., open,\\nhigh,low,close, and volume . Hence, the input data shape for the model is (10, 5). We\\nuse a batch size of 16 while training the model over 20 epochs. Figure 8 depicts the\\narchitecture of the multivariate encoder-decoder LSTM model.\\nTable 8 shows the number of parameters in the LSTM_MULTV_ED_10 model.\\nThe computation of the parameters for this model is exactly similar to that for the\\nmodel LSTM_UNIV_ED_50 expect for the first LSTM layer. The number of param-eters in the first LSTM (i.e., the encoder) layer for this model will be different sincethe number of parameters is dependent on the count of the features in the input\\ndata. The computation of the parameter counts in the encoder LSTM layer, lstm_1 ,\\nof the model is done as follows: 4 * [(200 + 5) * 200 + 200] = 164800. The total\\nnumber of parameters for the model is found to be 505801.Layer x ypprevpcurrn1 n2 #params\\nLSTM (lstm_3) 200 1 40,400 161600\\nLSTM (lstm_4) 200 200 80, 200 320800\\nDense (time_dist_dense_3) 200 100 20,100 20100\\nDense (time_dist_dense_4) 100 1 101 101\\nTotal #parameters 502601\\nTable 7.\\nThe number of parameters in the model LSTM_ UNIV_ED_10.\\nFigure 8.The schematic architecture of the model LSTM_MULTV_ED_10.\\n28Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='7e7a593f-c11b-40e4-97ac-df8d35cd254d', embedding=None, metadata={'page_label': '29', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.9 The LSTM_UNIV_CNN_10 model\\nThis model is a modified version of the LSTM_UNIV_ED_N_10 model. A dedi-\\ncated CNN block carries out the encoding operation. CNNs are poor in their ability\\nto learn from sequential data. However, we exploit the power of a one-dimensionalCNN in extracting important features from time-series data. After the feature\\nextraction is done, the extracted features are provided as the input into an LSTM\\nblock. The LSTM block decodes the features and makes robust forecasting of thefuture values in the sequence. The CNN block consists of a couple of convolutionallayers, each of which has a feature map size of 64 and a kernel size of 3. The inputdata shape is (10, 1) as the model uses univariate data of the target variable of thepast couple of weeks. The output shape of the initial convolutional layer is (8, 64).The value of 8 is arrived at using the computation: (10 –3 + 1), while 64 refers to the\\nfeature space dimension.\\nSimilarly, the shape of the output of the next convolutional block is (6, 64). A\\nmax-pooling block follows, which contracts the feature-space dimension by 1/2.Hence, the output data shape of the max-pooling layer is (3, 64). The max-poolinglayer ’s output is flattened into an array of single-dimension and size 3*64 = 192. The\\nflattened vector is fed into the decoder LSTM block consisting of 200 nodes. Thedecoder architecture remains identical to the decoder block of theLSTM_UNIV_ED_10 model. We train the model over 20 epochs, with each epochusing 16 records. The structure and the data flow of the model are shown in\\nFigure 9 .\\nTable 9 presents the computation of the number of parameters in the model\\nLSTM_UNIV_CNN_10. The input layer, the max-pooling layer, the flatten opera-\\ntion, and the repeat vector layer do not involve any learning, and hence they haveno parameters. The number of parameters in the first convolutional layer is com-puted as follows: (3 + 1) * 64 = 256. For the second convolutional layer, the numberof parameters is computed as: (3 * 64 + 1) * 64 = 12352. The number of parametersfor the LSTM layer is computed as follows: 4 * [(200 + 192) * 200 + 200] = 314400.\\nIn the case of the first dense layer, the number of parameters is computed as\\nfollows: (200 * 100 + 100) = 20100. Finally, the number of parameters in the seconddense layer is computed as (100 * 1 + 1) = 101. The total number of parameters inthe model is found out to be 347209.\\n3.10 The LSTM_UNIV_CONV_10 model\\nThis model is a modification of the LSTM_UNIV_CNN_10 model. The encoder\\nCNN ’s convolution operations and the decoding operations of the LSTM sub-\\nmodule are integrated for every round of the sequence in the output. This encoder-\\ndecoder model is also known as the Convolutional-LSTM model [58]. ThisLayer x ypprevpcurrn1 n2 #params\\nLSTM (lstm_1) 200 5 41200 164800\\nLSTM (lstm_2) 200 200 80, 200 320800\\nDense (time_dist_dense_1) 200 100 20,100 20100\\nDense (time_dist_dense_2) 100 1 101 101\\nTotal #parameters 505801\\nTable 8.\\nThe number of parameters in the model LSTM_MULTV_ED_10.\\n29Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='ab987412-f66a-43a0-9926-7f86dce6d039', embedding=None, metadata={'page_label': '30', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='integrated model reads sequential input data, performs convolution operations on\\nthe data without any explicit CNN block, and decodes the extracted features using a\\ndedicated LSTM block. The Keras framework contains a class, ConvLSTM2d , which\\nis capable of performing two-dimensional convolution operations [58]. The two-\\ndimensional ConvLSTM class is tweaked to enable it to process univariate data ofone dimension. The architecture of the model LSTM_UNIV_CONV_10 isrepresented in Figure 10 .\\nThe computation of the number of parameters for the LSTM_UNIV_CONV_10\\nmodel is shown in Table 10 . While the input layer, the flatten operation, and the\\nrepeat vector layer do not involve any learning, the other layers include trainable\\nparameters. The number of parameters in the convolutional LSTM layer (i.e.,\\nconv_1st_m2d ) is computed as follows: 4* x*[k(1+x) + 1] = 4*64[3\\n(1 + 64) + 1] = 50176. The number of parameters in the LSTM layer is computed asfollows: 4*[(200 + 192)*200 + 100] = 314400. The number of parameters in the first\\ntime distributed dense layer is computed as (200*100 + 100) = 20100. The computa-\\ntion for the final dense layer is as follows: (100*1 + 1) = 101. The total number of\\nparameters involved in the model, LSTM_UNIV_CONV_10 is 38,4777.\\nFigure 9.\\nThe schematic architecture of the model LSTM_UNIV_CNN_10.\\nLayer kd f x y pprevpcurrn1 n2 #param\\nConv1D (conv1d_4) 3 1 64 256 256\\nConv1D (conv1d_5) 3 64 64 12352 12352\\nLSTM (lstm_2) 200 192 78600 314400\\nDense (time_dist_4) 200 100 20,100 20100\\nDense (time_dist_5) 100 1 101 101\\nTotal #parameters 347209\\nTable 9.The number of parameters in the model LSTM_ UNIV_CNN_10.\\n30Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='ef2b9bfa-bfd1-4a7d-a28b-7978f433857e', embedding=None, metadata={'page_label': '31', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4. Performance results\\nWe present the results on the performance of the ten deep learning models on\\nthe dataset we prepared. We also compare the performances of the models. For\\ndesigning a robust evaluation framework, we execute every model over ten rounds.The average performance of the ten rounds is considered as the overall performanceof the model. We use four metrics for evaluation: (i) average RMSE, (ii) the RMSE\\nfor different days (i.e., Monday to Friday) of a week, (iii) the time needed for\\nexecution of one round, and (iv) the ratio of the RMSE to the response variable ’s\\n(i.e., open value ’s) mean value. The models are trained on 19500 historical stock\\nrecords and then tested on 20250 records. The mean value of the response variable,open, of the test dataset is 475.70. All experiments are carried on a system with an\\nIntel i7 CPU with a clock frequency in the range 2.60 GHz –2.56 GHz and 16GB\\nRAM. The time needed to complete one round of execution of each model isrecorded in seconds. The models are built using the Python programming language\\nversion 3.7.4 and the frameworks TensorFlow 2.3.0 and Keras 2.4.5.\\nTable 11 shows the results of the performance of the CNN_UNIV_5 model. The\\nmodel takes, on average, 174.78 seconds to finish its one cycle of execution. For this\\nmodel, the ratio of RMSE to the mean open values is 0.007288. The ratio of the\\nRMSE to the average of the actual open values for day1 through day5 are 0.0062,\\n0.0066, 0.0073, 0.0078, and 0.0083, respectively. Here, day1 refers to Monday,and day5 is Friday. In all subsequent Tables, we will use the same notations. The\\nFigure 10.\\nThe schematic architecture of the model LSTM_UNIV_CONV_10.\\nLayer kd f x y pprevpcurrn1 n2 #param\\nConvLSTM2D(conv_1st_m2d) 3 1 64 64 1 12544 50176\\nLSTM (lstm) 200 192 78600 314400\\nDense (time_dist) 200 100 20,100 20100\\nDense (time_dist_1) 100 1 101 101\\nTotal #parameters 384777\\nTable 10.\\nComputation of the no. of params in the model LSTM_ UNIV_CONV_10.\\n31Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='f8a237db-e64f-4637-b47b-d3841dd44725', embedding=None, metadata={'page_label': '32', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='RMSE values of the model CNN_UNIV_N_5 plotted on different days in a week are\\ndepicted in Figure 11 as per record no 2 in Table 11.\\nTable 12 depicts the performance results of the model CNN_UNIV_10. The\\nmodel needs 185.01 seconds on average for one round. The ratio of the RMSE to theaverage of the open values for the model is 0.006967. The ratios of the RMSE to the\\naverage open values for day1 through day5 for the model are 0.0056, 0.0067,\\n0.0070, 0.0075, and 0.0080, respectively. Figure 12 presents the RMSE values for\\nthe results of round 7 in Table 12 .\\nTable 13 depicts the performance results of the model CNN_MULTV_10. One\\nround of execution of the model requires 202.78 seconds. The model yields a valueof 0.009420 for the ratio of the RMSE to the average of the open values. The ratios\\nof the RMSE values to the mean of the open values for day1 through day5 of a week\\nare 0.0085, 0.0089, 0.0095, 0.0100, and 0.0101, respectively. The RMSE values ofthe model CNN_MULTV_N_10 plotted on different days in a week are depicted inFigure 13 based on record number 6 of Table 13 .\\nTable 14 depicts the results of the model CNN_MULTH_10. The model needs,\\non average, 215.07 seconds to execute its one round. The ratio of the RMSE to theaverage of the open values is 0.008100. The ratios of the RMSE to the average openNo. Agg RMSE Day1 Day2 Day3 Day4 Day5 Time (sec)\\n1 4.058 4.00 3.40 3.90 4.40 4.50 173.95\\n2 3.782 3.10 3.30 3.80 4.10 4.40 176.92\\n3 3.378 2.80 3.00 3.40 3.60 3.90 172.21\\n4 3.296 2.60 3.00 3.30 3.60 3.90 173.11\\n5 3.227 2.60 3.00 3.30 3.50 3.70 174.72\\n6 3.253 2.60 3.00 3.30 3.50 3.70 183.77\\n7 3.801 3.60 3.60 3.80 3.80 4.10 172.29\\n8 3.225 2.60 2.90 3.30 3.50 3.70 171.92\\n9 3.306 2.80 3.00 3.30 3.50 3.70 174.92\\n10 3.344 2.70 3.10 3.40 3.60 3.80 174.01\\nMean 3.467 2.94 3.13 3.48 3.71 3.94 174.78\\nRMSE/Mean 0.007288 0.0062 0.0066 0.0073 0.0078 0.0083\\nTable 11.\\nThe RMSE and the execution time of the CNN_ UNIV_5 model.\\nFigure 11.RMSE vs. day plot of CNN_UNIV_5 (depicted by tuple#2 in Table 11).\\n32Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='9072ba5d-2a17-4294-b7bd-910b321cbca7', embedding=None, metadata={'page_label': '33', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='value for day1 to day5 are 0.0076, 0.0075, 0.0082, 0.0084, and 0.0088, respec-\\ntively. The pattern of variations exhibited by the model daily RMSE is shown inFigure 14 as per record no 4 in Table 14 .\\nThe results of the LSTM_ UNIV_5 model are depicted in Table 15 . The average\\ntime needed to complete one round of the model is 371.62 seconds. The ratio of theRMSE and the average value of the target variable is 0.007770. The RMSE values forday1 to day5 are 0.0067, 0.0071, 0.0074, 0.0081, and 0.0086, respectively. Thepattern of variation of the daily RMSE is as per record no 9 in Table 15 is depicted in\\nFigure 15 .\\nTable 16 exhibits the results of the model LSTM_UNIV_10 . The model yields a\\nvalue of 0.007380 for the ratio of its RMSE to the average open values, while one\\nround of its execution needs 554.47 seconds. The RMSE values for day1 to day5 are0.0061, 0.0070, 0.0074, 0079, and 0.0083 respectively. The RMSE pattern of themodel as per record no 10 in Table 16 is exhibited in Figure 16.\\nTable 17 shows that the model LSTM_UNIV_ED_10 needs, on average,\\n307.27 seconds to execute its one round. The average value of the ratio of the RMSEto the average value of the target variable (i.e., the open values) for the model is\\n0.008350. The daily ratio values for day1 to day 5 of the model are, 0.0067, 0.0078,No. Agg RMSE Day1 Day2 Day3 Day4 Day5 Time (sec)\\n1 3.165 2.50 3.20 3.10 3.50 3.50 177.86\\n2 3.813 3.30 3.90 3.30 3.60 4.80 202.25\\n3 3.230 2.60 2.90 3.30 3.50 3.80 183.45\\n4 3.209 2.50 3.10 3.40 3.40 3.60 188.35\\n5 3.176 2.80 3.00 3.10 3.40 3.60 180.30\\n6 3.233 2.60 3.00 3.30 3.50 3.70 181.20\\n7 3.312 2.70 3.20 3.20 3.50 3.80 188.81\\n8 3.082 2.20 2.80 3.30 3.30 3.50 180.89\\n9 3.772 2.80 3.70 3.90 4.30 4.10 186.23\\n10 3.150 2.40 2.90 3.20 3.50 3.60 180.78\\nMean 3.3142 2.64 3.17 3.31 3.55 3.80 185.01\\nRMSE/Mean 0.006967 0.0056 0.0067 0.0070 0.0075 0.0080\\nTable 12.\\nThe RMSE and the execution time of the CNN_ UNIV_10 model.\\nFigure 12.RMSE vs. day plot of CNN_UNIV_10 (depicted by tuple#7 in Table 12 ).\\n33Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='5cd761de-d7e3-4b31-b1ff-e782d52ba1b5', embedding=None, metadata={'page_label': '34', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='No. Agg RMSE Day1 Day2 Day3 Day4 Day5 Time (sec)\\n1 4.525 4.00 4.30 4.50 4.70 5.00 206.92\\n2 3.606 3.10 3.30 3.70 3.80 4.00 202.61\\n3 4.830 4.60 4.70 4.70 5.10 5.00 202.87\\n4 4.938 4.40 4.80 4.70 5.30 5.40 201.49\\n5 4.193 3.50 4.00 4.10 4.60 4.60 214.66\\n6 5.101 4.70 4.90 5.20 5.30 5.30 190.73\\n7 4.751 4.40 4.50 4.80 5.00 5.00 201.73\\n8 3.927 3.20 3.70 4.00 4.30 4.40 200.04\\n9 4.267 3.90 3.80 4.50 4.60 4.40 199.09\\n10 4.661 4.40 4.50 4.60 4.90 4.90 207.62\\nMean 4.4799 4.02 4.25 4.53 4.76 4.80 202.78\\nRMSE/Mean 0.009420 0.0085 0.0089 0.0095 0.0100 0.0101\\nTable 13.\\nThe RMSE and the execution time of the CNN_MULTV_10 model.\\nFigure 13.RMSE vs. day plot of CNN_MULTV_10 (based on tuple#6 in Table 13 ).\\nNo. Agg RMSE Day1 Day2 Day3 Day4 Day5 Time (sec)\\n1 3.338 2.70 2.80 3.30 3.70 4.00 224.63\\n2 3.264 2.80 3.10 3.30 3.50 3.70 216.44\\n3 3.015 2.30 2.70 3.10 3.30 3.50 218.14\\n4 3.692 3.20 3.40 4.00 3.80 4.00 220.01\\n5 3.444 2.80 3.20 3.40 3.80 3.90 212.54\\n6 4.019 4.50 3.70 3.70 4.20 3.90 210.95\\n7 6.988 6.40 7.40 7.20 6.80 7.10 210.24\\n8 3.133 2.50 2.80 3.20 3.40 3.60 214.48\\n9 3.278 2.40 3.10 3.70 3.40 3.60 211.53\\n10 4.469 5.90 3.60 4.00 4.10 4.40 211.78\\nMean 3.864 3.55 3.58 3.89 4.00 4.17 215.07\\nRMSE/Mean 0.008100 0.0076 0.0075 0.0082 0.0084 0.0088\\nTable 14.\\nThe RMSE and the execution time of the CNN_MULTH_10 model.\\n34Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='9365fa82-6dca-4b0e-ac72-dbbd968e378d', embedding=None, metadata={'page_label': '35', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='0.0085, 0.0090, and 0.0095, respectively. Figure 17 exhibits the pattern of\\nvariation of the daily RMSE as per record no 9 in Table 17 .\\nTable 18 shows that the model LSTM_MULTV_ED_10, on average, requires\\n634.34 seconds to complete the execution of its one round. For this model, the ratio\\nof the RMSE to the average value of the target variable (i.e., the open values) is\\n0.010294. The ratios of the daily RMSE to the mean value of open for day1 to day5\\nFigure 14.\\nRMSE vs. day plot of CNN_MULTH_10 (based on tuple#4 in Table 14).\\nNo. Agg RMSE Day1 Day2 Day3 Day4 Day5 Time (sec)\\n1 3.125 2.40 2.90 3.00 3.50 3.70 372.28\\n2 3.376 3.00 2.90 3.40 3.90 3.70 371.73\\n3 2.979 2.10 2.60 3.00 3.30 3.70 368.72\\n4 3.390 3.20 3.40 3.30 3.60 3.50 368.58\\n5 4.387 4.20 4.60 4.10 4.40 4.60 379.10\\n6 5.173 4.40 5.10 4.60 5.20 6.30 373.84\\n7 3.434 4.30 2.60 2.90 3.70 3.50 368.91\\n8 3.979 3.70 3.10 4.60 4.30 4.10 371.02\\n9 2.892 1.90 2.50 2.90 3.30 3.50 371.95\\n10 3.683 2.70 4.00 3.30 3.50 4.60 370.07\\nMean 3.6418 3.19 3.37 3.51 3.87 4.12 371.62\\nRMSE/Mean 0.007770 0.0067 0.0071 0.0074 0.0081 0.0086\\nTable 15.The RMSE and the execution time of the LSTM_ UNIV_5 model.\\nFigure 15.RMSE vs. day plot of LSTM_UNIV_5 (depicted by tuple#9 in Table 15 ).\\n35Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='1f5bcfb1-7652-4365-9c7e-17c7050ddc04', embedding=None, metadata={'page_label': '36', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='No. Agg RMSE Day1 Day2 Day3 Day4 Day5 Time (sec)\\n1 3.005 2.40 2.40 2.80 3.70 3.50 547.22\\n2 3.859 3.50 3.30 3.80 3.90 4.70 554.03\\n3 4.601 4.50 4.50 4.60 4.80 4.60 550.24\\n4 3.342 2.70 4.00 3.10 3.40 3.50 555.50\\n5 4.714 4.80 4.40 4.70 4.60 5.10 563.44\\n6 3.336 2.50 3.20 3.30 3.60 3.90 553.83\\n7 3.711 3.10 4.00 4.00 3.60 3.90 559.31\\n8 2.795 1.90 2.40 2.80 3.20 3.40 552.50\\n9 3.012 1.80 2.80 2.90 3.60 3.50 551.20\\n10 2.751 1.70 2.30 3.00 3.00 3.30 557.39\\nMean 3.5126 2.89 3.33 3.50 3.74 3.94 554.47\\nRMSE/Mean 0.007380 0.0061 0.0070 0.0074 0.0079 0.0083\\nTable 16.\\nThe RMSE and the execution time of the LSTM_ UNIV_10 model.\\nFigure 16.\\nRMSE vs. day plot of LSTM_UNIV_10 (depicted by tuple#10 in Table 16 ).\\nNo. Agg RMSE Day1 Day2 Day3 Day4 Day5 Time (sec)\\n1 2.975 2.00 2.70 3.00 3.40 3.60 310.28\\n2 4.856 4.10 4.60 5.00 5.20 5.30 306.22\\n3 5.500 4.30 5.20 5.50 6.00 6.40 306.08\\n4 3.656 3.20 3.40 3.70 3.90 4.10 305.64\\n5 2.859 1.90 2.60 2.90 3.20 3.40 306.03\\n6 3.887 3.30 3.60 3.90 4.20 4.40 305.34\\n7 4.007 3.60 3.70 4.00 4.10 4.50 304.69\\n8 3.489 2.70 3.20 3.60 3.80 3.90 305.26\\n9 2.944 2.10 2.80 3.00 3.20 3.50 314.37\\n10 5.497 4.70 5.10 5.60 6.00 5.90 308.78\\nMean 3.971 3.19 3.69 4.02 4.30 4.50 307.27\\nRMSE/Mean 0.008350 0.0067 0.0078 0.0085 0.0090 0.0095\\nTable 17.The RMSE and the execution time of the LSTM_ UNIV_ED_10 model.\\n36Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='657bf6e7-0ac7-44b3-a6cd-2e7685dea045', embedding=None, metadata={'page_label': '37', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='are, respectively, 0.0094, 0.0099, 0.0102, 0.0107, and 0.0111. Figure 18 shows the\\npattern of the daily RMSE values of the model as per record no 10 in Table 18 .\\nTable 19 depicts that the model LSTM_UNIV_CNN_N_10 requires, on average,\\n222.48 seconds to finish one round. For this model, the ratio of the RMSE to the\\naverage value of the target variable (i.e., the open values) is found to be 0.007916.\\nThe daily RMSE values for day1 to day5 are, 0.0065, 0.0074, 0.0080, 0.0085, and\\nFigure 17.\\nRMSE vs. day plot of LSTM_UNIV_ED_10 (as per tuple#5 in Table 17 ).\\nNo. Agg RMSE Day1 Day2 Day3 Day4 Day5 Time (sec)\\n1 5.858 5.50 5.70 5.90 6.00 6.20 631.53\\n2 4.062 3.60 3.90 4.00 4.20 4.50 617.62\\n3 6.623 6.20 6.50 6.60 6.80 6.90 640.09\\n4 3.661 3.20 3.30 3.60 3.90 4.10 624.22\\n5 5.879 5.80 5.90 5.70 6.00 6.10 632.34\\n6 4.808 4.20 4.60 4.80 5.10 5.20 644.48\\n7 4.657 4.10 4.50 4.70 4.90 5.10 631.72\\n8 3.866 3.30 3.60 3.90 4.10 4.30 633.28\\n9 3.910 3.30 3.70 3.90 4.20 4.40 647.29\\n10 5.644 5.30 5.50 5.60 5.90 6.00 640.86\\nMean 4.897 4.50 4.72 4.87 5.11 5.28 634.34\\nRMSE/Mean 0.010294 0.0094 0.0099 0.0102 0.0107 0.0111\\nTable 18.The RMSE and the execution time of the LSTM_MULTV_ED_10 model.\\nFigure 18.RMSE vs. day plot of LSTM_MULTV_ED_10 (as per tuple#10 in Table 18 ).\\n37Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='a0175915-dff1-48ea-9513-c99464f4ddd0', embedding=None, metadata={'page_label': '38', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='No. Agg RMSE Day1 Day2 Day3 Day4 Day5 Time (sec)\\n1 3.832 3.30 3.50 3.90 4.10 4.30 221.18\\n2 3.256 2.50 3.00 3.30 3.60 3.80 219.74\\n3 4.308 3.80 4.00 4.40 4.60 4.60 222.59\\n4 4.081 3.30 4.00 4.10 4.30 4.50 227.95\\n5 3.325 2.60 3.00 3.30 3.60 3.90 224.46\\n6 3.870 3.20 3.70 3.90 4.10 4.10 223.40\\n7 3.688 3.10 3.40 3.80 4.00 4.10 222.89\\n8 3.851 3.20 3.60 3.80 4.20 4.40 221.87\\n9 3.710 2.60 3.40 4.00 4.00 4.40 219.74\\n10 3.736 3.30 3.70 3.70 3.90 4.10 220.96\\nMean 3.766 3.09 3.53 3.82 4.04 4.22 222.48\\nRMSE/Mean 0.007916 0.0065 0.0074 0.0080 0.0085 0.0089\\nTable 19.\\nThe RMSE and the execution time of the LSTM_ UNIV_CNN_10 model.\\nFigure 19.RMSE vs. day plot of LSTM_UNIV_CNN_10 (as per tuple#3 in Table 19 ).\\nNo. Agg RMSE Day1 Day2 Day3 Day4 Day5 Time (sec)\\n1 3.971 3.00 3.60 4.00 4.40 4.60 263.84\\n2 3.103 2.40 2.80 3.20 3.40 3.60 262.06\\n3 3.236 2.30 2.90 3.30 3.60 3.80 266.47\\n4 4.347 3.10 4.00 4.60 4.70 5.00 257.43\\n5 2.860 2.20 2.50 2.80 3.20 3.40 260.05\\n6 3.525 2.50 3.60 3.50 3.80 4.00 282.27\\n7 3.163 2.30 2.80 3.20 3.50 3.80 265.26\\n8 2.870 2.00 2.60 2.90 3.20 3.50 272.18\\n9 3.504 2.20 3.10 3.70 3.70 4.40 265.46\\n10 5.053 4.70 4.40 5.20 5.30 5.60 264.66\\nMean 3.563 2.67 3.23 3.64 3.88 4.17 265.97\\nRMSE/Mean 0.007490 0.0056 0.0068 0.0077 0.0082 0.0088\\nTable 20.\\nThe RMSE and the execution time of the LSTM_ UNIV_CONV_10 model.\\n38Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='88725d59-1aa9-4804-9b85-76074281b15a', embedding=None, metadata={'page_label': '39', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='0.0089 respectively. Figure 19 depicts the pattern of variation of the daily RMSE\\nvalues for this model as per record no 3 in Table 19.\\nThe results of the model LSTM_UNIV_CONV_N_10 are presented in Table 20 .\\nThe model completes its one round, on average, in 265.97 seconds. The ratio of the\\nRMSE to the average of the open values is 0.007490. The daily RMSE for day1 to\\nday5 are 0.0056, 0.0068, 0.0077, 0.0082, and 0.0088, respectively. Figure 20\\nshows the patterns of daily RMSE values for this model as per record no 8 inTable 20 .\\nTable 21 summarizes the performance of the ten models proposed in this chap-\\nter. We evaluate the models on two metrics and then rank the models on the basis of\\neach metric. The two metrics used for the model evaluation are: (i) an accuracy\\nmatric computed as the ratio of the RMSE to the mean value of the target variable(i.e., open values), and (ii) a speed metric as measured by the time (in seconds)\\nrequired for execution of one round of the model. The number of parameters ineach model is also presented. It is noted that the CNN_UNIV_5 model is ranked 1 onits execution speed, while it occupies rank 2 on the accuracy parameter. TheCNN_UNIV_10 model, on the other hand, is ranked 2 in terms of its speed ofexecution, while it is the most accurate model. It is also interesting to note that all\\nthe CNN models are faster than their LSTM counterparts. However, there is no\\nappreciable difference in their accuracies except for the multivariate encoder-decoder LSTM model, LSTM_MULTV_ED_10.\\nAnother interesting observation is that the multivariate models are found to be\\ninferior to the corresponding univariate models on the basis of the accuracy metric.\\nFigure 20.\\nRMSE vs. day plot of LSTM_UNIV_CONV_10 (as per tuple#8 in Table 20 ).\\nNo. Model #param RMSE/Mean Rank Exec. Time (s) Rank\\n1 CNN_UNIV_5 289 0.007288 2 174.78 1\\n2 CNN_UNIV_10 769 0.006967 1 180.01 2\\n3 CNN_MULTV_10 7373 0.009420 9 202.78 34 CNN_MULTH_10 132965 0.008100 7 215.07 45 LSTM_UNIV_5 182235 0.007770 5 371.62 8\\n6 LSTM_UNIV_10 182235 0.007380 3 554.47 97 LSTM_UNIV_ED_10 502601 0.008350 8 307.27 78 LSTM_MULTV_ED_10 505801 0.010294 10 634.34 109 LSTM_UNIV_CNN_10 347209 0.007916 6 222.48 510 LSTM_UNIV_CONV_10 384777 0.007490 4 265.97 6\\nTable 21.\\nComparative analysis of the accuracy and execution speed of the models.\\n39Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='bddbafc3-63ff-4951-83aa-7a651363d799', embedding=None, metadata={'page_label': '40', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The multivariate models, CNN_MULTV_10 and LSTM_MULTV_ED_10, are\\nranked 9 and 10, respectively, under the accuracy metric.\\nFinally, it is observed that the number of parameters in a model has an effect on\\nits execution time, barring some notable exceptions. For the four CNN models, it isnoted that with the increase in the number of parameters, there is a monotoneincrease in the execution time of the models. For the LSTM models, even though themodels, LSTM_UNIV_CNN_10, LSTM_UNIV_CONV_10, andLSTM_UNIV_ED_10, have higher number of parameters than the vanilla LSTMmodels (i.e., LSTM_UNIV_5 and LSTM_UNIV_10), they are faster in execution.Evidently, the univariate encoder-decoder LSTM models are faster even when they\\ninvolve a higher number of parameters than the vanilla LSTM models.\\n5. Conclusion\\nPrediction of future stock prices and price movement patterns is a challenging\\ntask if the stock price time series has a large amount of volatility. In this chapter, we\\npresented ten deep learning-based regression models for robust and precise predic-tion of stock prices. Among the ten models, four of them are built on variants ofCNN architectures, while the remaining six are constructed using different LSTMarchitectures. The historical stock price records are collected using the Metastocktool over a span of two years at five minutes intervals. The models are trained using\\nthe records of the first year, and then they are tested on the remaining records. The\\ntesting is carried out using an approach known as walk-forward validation, inwhich, based on the last one- or two-weeks historical stock prices, the predictions ofstock prices for the five days of the next week are made. The overall RMSE and theRMSE for each day in a week are computed to evaluate the prediction accuracy ofthe models. The time needed to complete one round of execution of each model isalso noted in order to measure the speed of execution of the models. The resultsrevealed some very interesting observations. First, it is found that while the CNN\\nmodels are faster, in general, the accuracies of both CNN and LSTM models are\\ncomparable. Second, the univariate models are faster and more accurate than theirmultivariate counterparts. And finally, the number of variables in a model has asignificant effect on its speed of execution except for the univariate encoder-decoder LSTM models. As a future scope of work, we will design optimized modelsbased on generative adversarial networks (GANs) for exploring the possibility of\\nfurther improving the performance of the models.\\n40Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='4855059b-bc39-477a-8953-72c764944682', embedding=None, metadata={'page_label': '41', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Author details\\nJaydip Sen1* and Sidra Mehtab2\\n1 Department of Data Science, Praxis Business School, Kolkata, India\\n2 School of Computing and Analytics, NSHM Knowledge Campus, Kolkata, India\\n*Address all correspondence to: jaydip.sen@acm.org\\n© 2021 The Author(s). Licensee IntechOpen. T his chapter is distributed under the terms\\nof the Creative Commons Attribution License ( http://creativecommons.org/licenses/\\nby/3.0), which permits unrestricted use, distribution, and reproduction in any medium,\\nprovided the original work is properly cited.\\n41Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='de7c38e4-f93c-4ac6-b619-c92e7d0d7bb2', embedding=None, metadata={'page_label': '42', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"References\\n[1]Asghar, M. Z., Rahman, F., Kundi, F.\\nM., Ahmed, S. Development of stock\\nmarket trend prediction system usingmultiple regression. Computational andMathematical Organization Theory,Vol 25, p. 271-301, 2019. DOI: 10.1007/s10588-019-09292-7.\\n[2]Enke, D., Grauer, M., Mehdiyev, N.\\nStock market prediction with multipleregression, fuzzy type-2 clustering, and\\nneural network. Procedia Computer\\nScience, Vol 6, p. 201-206, 2011. DOI:10.1016/j.procs.2011.08.038.\\n[3]Ivanovski, Z., Ivanovska, N.,\\nNarasanov, Z. The regression analysis ofstock returns at MSE. Journal of ModernAccounting and Auditing, Vol 12, No 4,\\np. 217-224, 2016. DOI: 10.17265/\\n1548-6583/2016.04.003.\\n[4]Sen, J., Datta Chaudhuri, T. An\\nalternative framework for time seriesdecomposition and forecasting and itsrelevance for portfolio choice –A\\ncomparative study of the Indian\\nconsumer durable and small cap sector.\\nJournal of Economics Library, Vol 3,No 2, p. 303 –326, 2016. DOI: 10.1453/\\njel.v3i2.787.\\n[5]Adebiyi, A. A., Adewumi, A. O., Ayo,\\nC. K. Comparison of ARIMA andartificial neural networks models for\\nstock price prediction. Journal of\\nApplied Mathematics, Vol 2014, Art ID:614342, 2014. DOI: 10.1155/2014/614342.\\n[6]Du, Y. Application and analysis of\\nforecasting stock price index based oncombination of ARIMA model and BP\\nneural network. In: Proceedings of the\\nIEEE Chinese Control and DecisionConference (CCDC' 18), June 9-10,2018, Shenyang, China, p. 2854-2857.DOI: 10.1109/CCDC.2018.8407611.\\n[7]Jarrett, J. E., Kyper, E. ARIMA\\nmodeling with intervention to forecastand analyze Chinese stock prices.International Journal of EngineeringBusiness Management, Vol 3, No 3,p. 53-58, 2011. DOI: 10.5772/50938.\\n[8]Ning, Y., Wah, L. C., Erdan, L. Stock\\nprice prediction based on errorcorrection model and Granger causalitytest. Cluster Computing, Vol 22,p. 4849-4958, 2019. DOI:10.1007/s10586-018-2406-6.\\n[9]Sen, J., Datta Chaudhuri, T. An\\ninvestigation of the structuralcharacteristics of the Indian IT sectorand the capital goods sector –An\\napplication of the R programminglanguage in time series decompositionand forecasting. Journal of Insurance\\nand Financial Management, Vol 1, No 4,\\np. 68-112, 2016.\\n[10]Sen, J. A robust analysis and\\nforecasting framework for the Indianmid cap sector using time seriesdecomposition. Journal of Insurance andFinancial Management, Vol 3, No 4,\\np. 1-32, 2017. DOI: 10.36227/\\ntechrxiv.15128901.v1\\n[11]Sen, J., Datta Chaudhuri, T.\\nDecomposition of time series data ofstock markets and its implications forprediction –An application for the\\nIndian auto sector. In: Proceedings of\\nthe 2\\nndNational Conference on\\nAdvances in Business Research and\\nManagement Practices (ABRMP'16),January 6 –7, 2016, Kolkata, p. 15-28.\\nDOI: 10.13140/RG.2.1.3232.0241.\\n[12]Sen, J., Datta Chaudhuri, T. A time\\nseries analysis-based forecasting\\nframework for the Indian healthcare\\nsector. Journal of Insurance andFinancial Management, Vol 3, No 1,p. 66-94, 2017.\\n[13]Sen, J., Datta Chaudhuri, T. A\\npredictive analysis of the Indian FMCGsector using time series decomposition-\\n42Machine Learning - Algorithms, Models and Applications\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='28f5cf79-fbb7-46aa-ba84-51fd17761b6b', embedding=None, metadata={'page_label': '43', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"based approach. Journal of Economics\\nLibrary, Vol 4, No 2, p. 206-226, 2017.DOI: 10.1453/jel.v4i2.1282.\\n[14]Sen, J., Datta Chaudhuri, T.\\nUnderstanding the sectors of Indianeconomy for portfolio choice.\\nInternational Journal of Business\\nForecasting and Marketing Intelligence,Vol 4, No 2, p. 178-222, 2018. DOI:10.1504/IJBFMI.2018.090914.\\n[15]Wang, L., Ma, F., Liu, J., Yang, L.\\nForecasting stock price volatility: Newevidence from the GARCH-MIDAS\\nmodel. International Journal of\\nForecasting, Vol 36, N0 2, p. 684-694,2020. DOI: 10.1016/j.ijforecast.2019.08.005.\\n[16]Zhong, X., Enke, D. Forecasting\\ndaily stock market return usingdimensionality reduction. Expert\\nSystems with Applications, Vol 67,\\np. 126-139, 2017. DOI: 10.1016/j.eswa.2016.09.027.\\n[17]Baek, Y., Kim, H. Y. ModAugNet: A\\nnew forecasting framework for stockmarket index value with an overfittingprevention LSTM module and a\\nprediction LSRM module. Expert\\nSystems with Applications, Vol 113,p. 457-480, 2015. DOI: 10.1016/j.eswa.2018.07.019.\\n[18]Bao, W., Yue, J., Rao, Y. A deep\\nlearning framework for financial timeseries using stacked autoencoders and\\nlong-and-short-term memory. PLOS\\nONE, Vol 12, No 7, 2017. DOI: 10.1371/journal.pone.0180944.\\n[19]Chou, J., Nguyen, T. Forward\\nforecast of stock price using sliding-window metaheuristic-optimizedmachine-learning regression. IEEE\\nTransactions on Industrial Informatics,\\nVol 14, No 7, p. 3132-3142, 2018, DOI:10.1109/TII.2018.2794389.\\n[20]Ding, G., Qin, L. Study on\\nprediction of stock price based on theassociated network model of LSTM.International Journal of MachineLearning and Cybernetics, Vol 11,p. 1307-1317, 2020. DOI: 10.1007/s13042-019-01041-1.\\n[21]Gocken, M., Ozcalici, M., Boru, A.,\\nDosdogru, A. T. Integratingmetaheuristics and artificial neuralnetworks for improved stock priceprediction. Expert Systems withApplications, Vol 44, p. 320-331, 2016.DOI: 10.1016/j.eswa.2015.09.029.\\n[22]Mehtab, S., Sen, J. Stock price\\nprediction using convolutional neuralnetworks on a multivariate time series.In: Proceedings of the 3\\nrdNational\\nConference on Machine Learning andArtificial Intelligence (NCMLAI'20),February 1-2, 2020, New Delhi, India.DOI: 10.36227/techrxiv.15088734.v1\\n[23]Mehtab, S., Sen, J. Time Series\\nAnalysis-Based Stock Price PredictionFramework Using Machine Learningand Deep Learning Models. TechnicalReport No: NSHM_KOL_2020_SCA_DS_1, 2020. DOI: 10.13140/RG.2.2.14022.22085/2.\\n[24]Mehtab, S., Sen, J. Stock price\\nprediction using CNN and LSTM-baseddeep learning models. In: Proceedings ofthe IEEE International Conference onDecision Aid Sciences and Applications(DASA'20), November 8-9, 2020,Sakheer, Bahrain, p. 447-453. DOI:10.1109/DASA51403.2020.9317207.\\n[25]Mehtab, S., Sen, J., Dasgupta, S.\\nRobust analysis of stock price timeseries using CNN and LSTM-based deeplearning models. In: Proceedings of the4\\nthIEEE International Conference on\\nElectronics, Communication andAerospace Technology (ICECA'20),\\nNovember 5-7, 2020, Coimbatore, India,\\np. 1481-1486. DOI: 10.1109/ICECA49313.2020.9297652.\\n[26]Mehtab, S., Sen, J., Dutta, A. Stock\\nprice prediction using machine learning\\n43Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='07141e18-af9d-48f5-badc-5fd2f3172485', embedding=None, metadata={'page_label': '44', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"and LSTM-based deep learning models.\\nIn: Thampi, S. M., Piramuthu, S., Li, K.C., Beretti, S., Wozniak, M., Singh, D.(eds), Machine Learning andMetaheuristics Algorithms andApplications, SoMMA 2020.Communications in Computer and\\nInformation Science, Vol 1366,\\np. 88-106, Springer, Singapore. DOI:10.1007/978-981-16-0419-5_8.\\n[27]Mehtab, S., Sen, J. Analysis and\\nforecasting of financial time series usingCNN and LSTM-based deep learningmodels. In: Proceedings of the 2\\nnd\\nInternational Conference on Advancesin Distributed Computing and MachineLearning (ICADCML'21), January 15-16,2021, Bhubaneswar, India. (Accepted\\nfor publication)\\n[28]Mehtab, S., Sen, J. A time series\\nanalysis-based stock price prediction using\\nmachine learning and deep learningmodels. International Journal of BusinessForecasting and Marketing Intelligence(IJBFMI), Vol 6, No 4, p. 272-335. DOI:\\n10.1504/IJBFMI.2020.115691.\\n[29]Ning, B., Wu, J., Peng, H., Zhao, J.\\nUsing chaotic neural network to forecaststock index. In: Yu, W., He, H., Zhang,\\nN. (eds.), Advances in NeuralNetworks. Lecture Notes inComputer Science, Vol 5551,p. 870-876, 2009. DOI: 10.1007/978-3-642-01507-6_98.\\n[30]Patel, J., Shah, S., Thakkar, P.,\\nKotecha, K. Predicting stock and stockprice index movement using trenddeterministic data preparation andmachine learning techniques. Expert\\nSystems with Applications, Vol 42,\\nNo 1, p. 259-268, 2015. DOI: 10.1016/j.eswa.2014.07.040.\\n[31]Qiao, J., Wang, H. A self-organizing\\nfuzzy neural network and its applicationto function approximation and forecastmodeling. Neurocomputing, Vol 71, Nos4-6, pp. 564-569, 2008. DOI: 10.1016/j.neucom.2007.07.026.[32]Sen, J. Stock price prediction using\\nmachine learning and deep learningframeworks. In: Proceedings of the 6\\nth\\nInternational Conference on BusinessAnalytics and Intelligence (ICBAI'18),December 20-22, Bangalore, 2018,India.\\n[33]Sen, J., Datta Chaudhuri, T. A robust\\npredictive model for stock priceforecasting. In: Proceedings of the 5\\nth\\nInternational Conference on BusinessAnalytics and Intelligence (BAICONF'17),December 11-13, 2017, Bangalore, India.\\n[34]Sen, J., Dutta, A., Mehtab, S.\\nProfitability analysis in stockinvestment using an LSTM-based deeplearning model. In: Proceedings of the2nd IEEE International Conference onEmerging Technologies (INCET’ 21), pp.\\n1-9, May 21-23, 2021, Belgaum, India.DOI: 10.1109/INCET51464.2021.\\n9456385\\n[35]Sen, J., Mehtab, S. Accurate stock\\nprice forecasting using robust and\\noptimized deep learning models. In:Proceedings of the IEEE InternationalConference on Intelligent Computing(CONIT ’21), June 25-27, 2021, Hubli,\\nIndia. DOI: 10.1109/CONIT51480.2021.9498565\\n[36]Senol, D., Ozturan, M. Stock price\\ndirection prediction using artificialneural network approach: The case ofTurkey. Journal of ArtificialIntelligence, Vol 1, No 2, p. 70-77, 2008.\\nDOI: 10.3923/jai.2008.70.77.\\n[37]Shen, J., Fan, H., Chang, S. Stock\\nindex prediction based on adaptive\\ntraining and pruning algorithm. In: Liu,D., Fei, S., Hou, Z., Zhang, H., Sun, C.(eds.), Advances in Neural Networks.Lecture Notes in Computer Science,\\nSpringer-Verlag, Vol 4492,\\np. 457-464, 2007. DOI: 10.1007/978-3-540-72393-6_55.\\n[38]Tseng, K-C., Kwon, O., Tjung, L. C.\\nTime series and neural network forecast\\n44Machine Learning - Algorithms, Models and Applications\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='be39ad40-c011-421c-99e9-b6ad7191bcd7', embedding=None, metadata={'page_label': '45', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"of daily stock prices. Investment\\nManagement and Financial Innovations,Vol 9, No 1, p. 32-54, 2012.\\n[39]Wu, Q., Chen, Y., Liu, Z. Ensemble\\nmodel of intelligent paradigms for stockmarket forecasting. In: Proceedings of\\nthe 1\\nstInternational Workshop on\\nKnowledge Discovery and Data Mining,\\nWashington DC, USA, p. 205-208,2008. DOI: 10.1109/WKDD.2008.54.\\n[40]Zhang, D., Jiang, Q, Li, X.\\nApplication of neural networks infinancial data mining. International\\nJournal of Computer, Electrical,\\nAutomation, and InformationEngineering, Vol 1, No 1, p. 225-228,2007. DOI: 10.5281/zenodo.1333234.\\n[41]Zhu, X., Wang, H., Xu, L., Li, H.\\nPredicting stock index increments byneural networks: The role of trading\\nvolume under different horizons. Expert\\nSystems with Applications, Vol 34,No 4, pp. 3043-3054, 2008. DOI:10.1016/j.eswa.2007.06.023.\\n[42]Ballings, M., den Poel, D. V.,\\nHespeels, N., Gryp, R. Evaluatingmultiple classifiers for stock price\\ndirection prediction. Expert Systems\\nwith Applications, Vol 42, No 20,p. 7046-7056, 2015. DOI: 10.1016/j.eswa.2015.05.013.\\n[43]Bollen, J., Mao, H., Zeng, X. Twitter\\nmood predicts the stock market. Journalof Computational Science, Vol 2, No 1,\\np. 1-8, 2011. DOI: 10.1016/j.\\njocs.2010.12.007.\\n[44]Chen, M-Y., Liao, C-H., Hsieh, R-P.\\nModeling public mood and emotion:Stock market trend prediction withanticipatory computing approach.Computers in Human Behavior,\\nVol 101, p. 402-408, 2019. DOI:\\n10.1016/j.chb.2019.03.021.\\n[45]Mehtab, S., Sen, J. A robust\\npredictive model for stock priceprediction using deep learning andnatural language processing. In:Proceedings of the 7\\nthInternational\\nConference on Business Analytics andIntelligence (BAICONF'19), December5-7, 2019, Bangalore, India. DOI:10.2139/ssrn.3502624.\\n[46]Nam, K., Seong, N. Financial news-\\nbased stock movement prediction usingcausality analysis of influence in theKorean stock market. Decision SupportSystems, Vol 117, p. 100-112, 2019. DOI:10.1016/j.dss.2018.11.004.\\n[47]Vargas, M. R., de Lima, B. S. L. P.,\\nEvsukoff, A. G. Deep learning for stockmarket prediction from financial newsarticles. In: Proceedings of the IEEEInternational Conference onComputational Intelligence and VirtualEnvironments for Measurement systemsand Applications (CIVEMSA'17), June26-28, 2017, Annecy, France, p. 60-65.\\nDOI: 10.1109/CIVEMSA.2017.7995302.\\n[48]Kim, M., Sayama, H. Predicting\\nstock market movements using network\\nscience: An information theoreticapproach. Applied Network Science,Vol 2, Article No: 35, 2017. DOI:10.1007/s41109-017-0055-y.\\n[49]Lin, F-L., Yang, S.-Y., March, T.,\\nChen, Y.-F. Stock and bond returnrelations and stock market uncertainty:Evidence from wavelet analysis.International Review of Economics &Finance, Vol 55, p. 285-294, 2018. DOI:10.1016/j.iref.2017.07.013.\\n[50]Akcay, Y., Yalcin, A. Optimal\\nportfolio selection with a shortfallprobability constraint: Evidence fromalternative distribution functions.Journal of Financial Research, Vol 33,No 1, p. 77-102, 2010. DOI: 10.1111/j.1475-6803.2009.01263.x.\\n[51]Caldeira, J. F., Moura, G. V., Santos,\\nA. A. Yield curve forecast combinationsbased on bond portfolio performance.Journal of Forecasting, Special IssueArticle, 2017. DOI: 101.1002/for.2476.\\n45Design and Analysis of Robust Deep Learning Models for Stock Price Prediction\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9982\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c3b2a158-b254-4611-9ee9-2863c815a131', embedding=None, metadata={'page_label': '46', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"[52]Li, T., Zhang, W., Xu, W. A fuzzy\\nportfolio selection model with\\nbackground risk. Applied Mathematicsand Computation, Vol 256, p. 505-513,2015. DOI: 10.1016/j.amc.2015.01.007.\\n[53]Liu, Y. J., Zhang, W. G. A multi-\\nperiod fuzzy portfolio optimizationmodel with minimum transaction lots.European Journal of OperationalResearch, Vol 242, No 3, p. 933-941,2015. DOI: 10.1016/j.ejor.2014.10.061.\\n[54]Mehlawat, M. K., Gupta, P. Fuzzy\\nchance-constrained multiobjective\\nportfolio selection model. IEEE\\nTransaction on Fuzzy Systems, Vol 22,No 3, p. 653-671, 2014. DOI: 10.1109/TFUZZ.2013.2272479.\\n[55]Sen, J., Mehtab, S. A comparative\\nstudy of optimum risk portfolio andeigen portfolio on the Indian stock\\nmarket. International Journal of\\nBusiness Forecasting and MarketingIntelligence (IJBFMI), Paper ID:IJBFMI-90288, Inderscience Publishers.(Accepted for publications).\\n[56]Metastock Tool: http://metastock.\\ncom.\\n[57]Geron, A. Hands-On Machine\\nLearning with Scikit-Learn Keras &Tensorflow. O'Reilly Publications, USA,2019.\\n[58]Shi, X., Chen, Z., Wang, H., Yeung,\\nD-Y., Wong, W-K. Convolutional LSTM\\nnetwork: a machine learning approach\\nfor precipitation nowcasting. In:Proceedings of the 28\\nthInternational\\nConference on Neural InformationProcessing Systems, December 7 –12,\\nCambridge, MA, USA, Vol 1,pp. 802-810.\\n46Machine Learning - Algorithms, Models and Applications\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='442b573f-2517-473b-b09d-5f1cccae8805', embedding=None, metadata={'page_label': '47', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 3\\nArticulated Human Pose\\nEstimation Using Greedy\\nApproach\\nPooja Kherwa, Sonali Singh, Saheel Ahmed, Pranay Berry\\nand Sahil Khurana\\nAbstract\\nThe goal of this Chapter is to introduce an efficient and standard approach for\\nhuman pose estimation. This approach is based on a bottom up parsing technique\\nwhich uses a non-parametric representation known as Greedy Part Association Vec-tor (GPAVs), generates features for localizing anatomical key points for individuals.Taking leaf out of existing state of the art algorithm, this proposed algorithm aims to\\nestimate human pose in real time and optimize its results. This approach simulta-\\nneously detects the key points on human body and associates them by learning theglobal context. However, In order to operate this in real environment where noise isprevalent, systematic sensors error and temporarily crowded public could pose achallenge, an efficient and robust recognition would be crucial. The proposed archi-tecture involves a greedy bottom up parsing that maintains high accuracy whileachieving real time performance irrespective of the number of people in the image.\\nKeywords: Neural networks, Pose- estimation, Greedy Search, Neural Network,\\nHeat-maps\\n1. Introduction\\nHuman pose estimation is a complex field of study in artificial intelligence,\\nwhich requires a depth knowledge of computer vision, calculus, graph theory and\\nbiology. Initially this work start by introducing an image to a computer throughcamera and detect humans in the image known as object detection, as one ofcomputer vision problem. In real world detecting an object from an image [1] andestimating its posture [2, 3] is two different aspects of objects. The latter is a verychallenging and complex task. Images are filled with occluded objects, humans inclose proximity, occlusions or spatial interference makes the task even more stren-uous. One way of solving this problem is to use single person detector for estimation\\nknown as top down parsing [4 –9]. This approach suffers from preconceived\\nassumptions and lacks robustness. The approach is biased towards early decisions\\nwhich makes it hard to recover if failed. Besides this, the computational timecomplexity is commensurate with the number of people in the image which makesit not an ideal approach for practical purpose. On a contrary the bottom upapproach seems to perform well as compare to its counterpart. However earlierbottom up versions could not able to reduce the computational complexity as it\\n47', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='cb444adf-4a2b-45e8-9e8f-5c8aa166e6ad', embedding=None, metadata={'page_label': '48', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='unable to sustain the benefits of being consistent. For instance, the pioneering work\\nE. Insafutdinov et al. Proposed a bottom up approach that simultaneous detects joints\\nand label them as part candidates [10]. Later it associates them to individual person.\\nEven solving the combinatorial optimization problem over a complete graph is itselfNP hard. Another approach built on with stronger joint detectors based on ResNet[11] and provides ranking based on images, significantly improved its runtime butstill performs in the order of minutes per image. The approach also requires a separatelogistic regression for precise regression. After studying sufficient approaches andtheir shortcomings in the literature of image processing and object detection, thischapter introduces a efficient approach for human pose estimation.\\n1.1 Contribution of the work\\nOptimizing the current state of the art r esults and introducing a new approach to\\nsolving this problem is the highlight of this chapter. In this chapter, we presented a\\nbottom up parsing technique which uses a non-p arametric representation, features for\\nlocalizing anatomical key points for individuals. We further introduced a multistagearchitecture with two parallel branches one of the branches estimates the body joints via\\nhotspots while the other branch captures the orientations of the joints through vectors\\nThis proposed approach is based on bottom u p parsing, localizes the anatomical key\\npoints and associates them using greedy parsing technique known as greedy part asso-ciation vectors. These 2D vectors aims to p rovide not only the encoded translator\\nposition but also the respective directional o rientations of body parts. This approach also\\nable to decouple the dependency of number of persons with running time complexity.\\nOur approach has resulted in competitive performance on some of the best public\\nbenchmarks. The model maintains its accura cy while providing real time performance.\\nThis chapter comprises of 6 sections: Section 2 discussed related work, in Section\\n3, proposed methodology is explained, in details with algorithms, in Section 4 resultsare discussed, and finally the chapter is concluded with future work in Section 5.\\n2. Related work\\nThe research trend that was primarily focused on detection of objects, visual\\nobject tracking and human body part detection, has advanced to pose estimationrecently. Various visual tracking architectures have been proposed such as thosebased on convolutional neural networks and particle filtering and colored area track-ing using mean shift tracking through temporal image sequence [12]. A survey of\\napproaches for intruder detection systems in a camera monitored frame for surveil-\\nlance was explained by C. Savitha and D. Ramesh [13]. A. Shahbaz and K. Jo alsoproposed a human verifier which is a SVM classifier based on histogram of orientedgradients along with an algorithm for change detection based on Gaussian mixturemodel [14]. But still there was a need of more precise detection algorithm that wouldaccurately predict minor features as well. Human and Object detection evolved todetection of human body parts. L. Kong, X. Yuan and A.M.Maharajan introducedframework for automated joint detection using depth frames [15]. A cascade of Deep\\nneural networks was used for Pose Estimation formulated as a joint regression prob-\\nlem and cast in DNN [16]. A full image and 7-layered generic convolutional DNN istaken as input to regress the location of each body joint. In [17], long-term temporalcoherence was propagated to each stage of the overall video and data of joint positionof initial posture was generated. A multi-feature, three-stage deep CNN was adoptedto maintain temporal consistency of video by halfway temporal evaluation methodand structured space learning. Speeded up Robust features (SURF) and Scale\\n48Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='7aa375bb-02e0-415c-8124-4d75e24096aa', embedding=None, metadata={'page_label': '49', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Invariant Feature Transform (SIFT) was proposed by A. Agarwal, D. Samaiya and K.\\nK. Gupta to deal with blur and illumination changes for different background condi-\\ntions [18]. Paper [19] aims to improve human ergonomics using Wireless vibrotactile\\ndisplays in the execution of repetitive or heavy industrial tasks. Different approachwas presented to detect human pose. Coarse-Fine Network for Key point Localization(CFN)[20], G-RMI [21] and Regional Multi-person Pose Estimation (RMPE)[22]techniques have been used to implement top-down approach of pose detection (i.e.the person is identified first and then the body parts). An alternate bottom-upapproach was proposed by Z. Cao, T. Simon, S. Wei and Y. Sheikh based on PartialAffinity Fields to efficiently detect the 2D pose [23]. X. Chen and G. Yang also\\npresented a generic multi-person bottom-up approach for pose estimation formulated\\nas a set of bipartite graph matching by introducing limb detection heatmaps. Theseheatmaps represent association of body joint pairs, that are simultaneously learnedwith joint detection [24]. L. Ke, H. Qi, M. Chang and S. Lyu proposed a deep conv-deconv modules-based pose estimation method via keypoint association using aregression network [25]. K. Akila and S. Chitrakala introduced a highly discriminatingHOI descriptor to recognize human action in a video. The focus is to discriminateidentical spatio-temporal relations actions by human-object interaction analysis and\\nwith similar motion pattern [26] Y. Yang and D. Ramanan proposed methods for pose\\ndetection and estimation for static images based on deformable part models withaugmentation of standard pictorial structure model by co-occurrence relationsbetween spatial relations of part location and part mixtures [27]. A Three-dimensional (3D) human pose estimation methods are explored and reviewed in apaper, it nvolves estimating the articulated 3D joint locations of a human body froman image or video [28]. One more study includes a 2-D technique which localizedense landmark on the entire body like face, hands and even on skin [29].\\n3. Proposed approach for human pose detection\\n3.1 Methodology\\nFigure 1 depicts the methodology of our proposed approach, our approach works\\nas black box which receive an image of a fixed size and produces a 2D anatomical keypoint of every person in the image. After performing the needed preprocessing, theimage is passed through a feed forward convolutional neural network. The architec-ture has two separate branches that runs simultaneously\\ni. On one branch it predicts an approximations represented by a set of\\nhotspots H for each body joint locations while the\\nii. Other branch predicts a set of 2D vectors representing joints associations P\\nfor each pair of different joints. Each set H is a collection of\\nH1,H2,H3,…Hj fg j hotspots one for each joint and P is a collection of\\nL1,L2,L3,…::Lk fg k part association vector field for each pair or limb. The\\noutput of these two branches will be summed up using parsing algorithmand feed forward to multiple layers of convolutional net ultimately giving2D anatomical key points for every person in the image.\\n3.2 Part detection using heat-maps\\nThe heat maps produced by convolutional neural net are highly reliable\\nsupporting features. The heat maps are set of matrices that stores the confidence\\n49Articulated Human Pose Estimation Using Greedy Approach\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9354', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='8db947fa-7054-417f-b8f5-a3fa22be1bfc', embedding=None, metadata={'page_label': '50', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='that the network has that a pixel contains a body joint. As many as 16 matrices for\\neach of the true body joints. The heat map specifies the probability that a particularjoint exist within a particular pixel location. The very idea of having heat mapsprovide support in predicting the joint location. The visual representation of heatmaps could give an intuition of a presence of body joint. The darker the shade orsharper the peak represents a high probability of a joint. Several peaks represent a\\ncrowded image representing one peak for one person ( Figure 2 ).\\nCalculating the confidence map or heat maps C\\n∗\\njkfor each joint requires\\nsome prior information for comparison. Let xjkbe the empirical position of a body\\njoint j of the person k. These confidence maps at any position m can be created by\\nusing the empirical position xjk.The value of confidence map at location p in C∗\\njkis\\ngiven by\\nC∗\\njkmð Þ¼ exp�Δ2\\nσ2/C0/C1\\n(1)\\nwhere σis spread from the mean and Δis the absolute difference of xjkand m.\\nAll the confidence maps get aggregated by the network to produce the final\\nconfidence map. The final confidence map is generated by the network obtainedfrom the aggregation of the individual maps.\\nC\\n∗\\njkmð Þ¼ max C∗\\njkmðÞ/C16/C17\\n(2)\\nFigure 1.\\nSchematic diagram of a multistage architecture. Two parallel branches feeds forward the network. Heat mapspredicts the approximation while part association vectors predict association and orientations.\\n50Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='3d2b5ba4-333b-4e29-a082-826491bd1f28', embedding=None, metadata={'page_label': '51', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='These confidence maps are rough approximations, but we need the value for\\nthat joint. We need to extract value from the hot spot. For the final aggregated\\nconfidence map we take the max of the peak value while suppressing the rest.\\n3.3 Greedy part association vector\\nThe problem that comes while detecting the pose is that even if we have all the\\nanatomical key points how we are going to associate them. The hotspot or the key\\npoints itself have no idea of the context on how they are connected. One way toapproach this problem is to use a geometrical line midpoint formula. But the givenapproach would suffer when the image is crowded as it would tend to give false\\nassociation. The reason behind the false association is the limitation of the approach\\nas it tend to encode only the position of the pair and not the orientations and also itreduces the base support to a single point. In order to address this issue, we want toimplement a greedy approach known as greedy part association vector which willpreserve the position along with the orientation across the entire area of pairsupport. Greedy part association vectors are the 2D vector fields that providesinformation regarding the position and the orientation of the pairs. These are a setof coupled pair with one representing x axis and the other representing the y axis.\\nThere are around 38 GPAVs per pair and numerically index as well ( Figure 3 ).\\nConsider a limb j with 2 points at x\\n1andx2forkthperson in the image. The limb\\nwill have many points between x1andx2. The greedy part association vector at any\\npoint c between x1andx2forkthperson in the image represented by G∗\\nj,kcan be\\ncalculated as.\\nFigure 2.\\nIllustration of one segment of the pipeline i.e. predicting heat maps through neural network. It gives the\\nconfidence metric with regards to the presence of the particular body part in the given pixel.\\nFigure 3.\\nIllustration of the other segment greedy part vectors, preserving the position along with the orientations and\\nfinally associates the joints through greedy parsing.\\n51Articulated Human Pose Estimation Using Greedy Approach\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9354', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='e57d19b6-f8a0-482a-a6e0-6eb609d5038b', embedding=None, metadata={'page_label': '52', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='G∗\\nj,k¼^cif c is on limb j and person k :Or 0 otherwise : (3)\\nwhere ^ca unit vector along the direction of limb equivalent to\\nx2�x1ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ\\nx2\\n2�x21p (4)\\nThe empirical value of final greedy part association vector will be the average of\\nGPAVs of all the person in the image.\\nG∗\\nj¼P\\nkG∗\\nj,k\\nnjcðÞ(5)\\nwhere G∗\\nj,kis the greedy part association vector at any point and njcðÞis the total\\nnumber of vectors at the same point c among all people.\\n3.4 Multi person pose estimation\\nAfter getting the part candidates using non-maximum suppression, we need to\\nassociate those body parts to forms pairs. For each body part there are n numbers of\\npart candidates for association. On an abstract level one-part can form associationwith every possible part candidate forming a complete graph ( Figure 4 ).\\nFor example, we have detected a set of plausible neck candidates and a set of hip\\ncandidates. For each neck candidates there is a possible connection with the righthip candidates giving a complete bipartite graph having the nodes as part candi-\\ndates and the edges as possible connections. We need to associate only the optimal\\npart giving rise to a problem of N dimensional matching problem which itself a NPhard problem. In order to solve this optimal matching problem, we need to assignweights to each of possible connection. This is where the greedy part associationvectors come into the pipeline. These weights are assigned using the aggregatedgreedy part association vector.\\nIn order to measure the association between two detected part candidates. We\\nneed to integrate over the predicted greedy part association vector found in previ-\\nous section, along these two detected part candidates. This integral will give assign a\\nscore to each of the possible connections and store the scores in a complete bipartitegraph. We need the find the directional orientation of the limb with respect to thesedetected part candidates. Empirically we have two detected part candidates namelyt\\n1andt2and the predicted part association vector Gj. An integral over the curve will\\ngive a measure of confidence in their association.\\nFigure 4.\\n(a–d) Solving the assignment problem for associating body joints to form the right pair. Assigning weights to\\neach possible connection with the help of greedy association vectors.\\n52Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='85ba6da7-d717-404c-bb15-8c25da44c86c', embedding=None, metadata={'page_label': '53', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='E¼ði¼1\\ni¼0GjcmðÞðÞ :^d:dm (6)\\nwhere GjcmðÞðÞ greedy part association vector and^dis a unit vector along the\\ndirection two non-zero vectors t1andt2.\\nAfter assigning weights to the edges our aim is to find the edge for a pair of joints\\nwith the maximum weight. For this we choose the most intuitive approach. We\\nstarted with sorting the scores in descending manner followed by selecting theconnection with the max score. We then move to the next possible connection ifnone of the parts have been assigned a score, this is a final connection. Repeat thethird step until done.\\nThe final step involves merging the whole detected part candidates with optimal\\nscores and forming a complete 2D stick figure of human structure. One way toapproach this problem is that let us say each pair of part candidates belong a uniqueperson in the image that way we have a set of humans i.e. H\\n1,H2,H3,…:Hk fg where\\nk is the total number of final connection. Each human in the set contain a pair i.e.pair of body parts. Let represent the pairs as a tuple of indices one in x direction and\\none in y direction. H\\ni¼ midx,mx,my��\\n,nidx,nx,nyÞ�� �\\n. Now comes the merging we\\nconclude that if two human set shares any index coordinates with other set means\\nthat they share a body part. We merge the two sets and delete the other. Weperform the same steps for all of the sets until no two human share a part ultimatelygiving a human structure.\\n4. Results\\nFor the training and evaluating the final build we used a subset of a state-of-the-\\nart public dataset, the COCO dataset. COCO dataset is collection of 100 K imageswith diverse instances. We have used a subset of those person instances withannotated key points. We have trained our model on 3 K images, cross validated on1100 images and tested on 568 images. The metric used for evaluation is OKS standsfor Object key point similarity. The COCO evaluation is based on mean averageprecision calculates over different OKS threshold. The minimum OKS value thatcan have is 0.5. We are only interested in key points that lie within 2.77 of the\\nstandard deviation ( Figure 5 ).\\nAbove table compares the performance of our model with the other state of the\\nart model. Table 1 shows the mAP performance comparison of our model with\\nothers on a testing dataset of 568 images. We can see clearly our novel approach\\nFigure 5.\\nConvergence of training losses for both the heat maps (L) and greedy part vectors (R).\\n53Articulated Human Pose Estimation Using Greedy Approach\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9354', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='5f4f96dc-a37b-4872-98ea-819ab1486e91', embedding=None, metadata={'page_label': '54', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='outperforms the previous key point benchmarks. We can also see our model\\nachieved a significant rise in mean average precision of 6.5%. Our inference time is\\n3 order less. Table 2 presents the performance comparison on a complete testing\\ndataset of 1000 images. Here again we can see our model outperforming the rest.\\nOur model achieved a rise of almost 2.5% in mean average precision as compare toother models. The above comparison of our model with earlier state of the artbottom up approaches presents the significance of our model.\\n5. Conclusion and future work\\nSolving one of the complex problems in computer vision was a huge challenge.\\nOptimizing the current state of the art results and introducing a new approach tosolving this problem is the highlight of this chapter. In this chapter, we presented abottom up parsing technique which uses a non-parametric representation, featuresfor localizing anatomical key points for individuals. We further introduced a mul-tistage architecture with two parallel branches one of the branches estimates the\\nbody joints via hotspots while the other branch captures the orientations of the\\njoints through vectors. We ran our model on a publicly available COCO dataset fortraining, cross validation and testing. Finally, we evaluated the results and achieveda mean average precision of 77.7. We compare our results with existing models andachieved and a significant rise of 2.5% in mAP with less inference time. We haveshowed the results in Tables 1 and 2 . We aim to expand our project in future by\\nproposing a framework for human pose comparator based on the underlying tech-nology used in single person pose estimation to compare the detected pose with that\\nof the target in real-time. This would be done by developing a model to act as an\\nactivity evaluator by learning physical moves using key points detection performedby the source and compare the results with the moves performed by the target alongwith a scoring mechanism that would decide how well the two sequence of posesmatch. In a nutshell, we aim to build an efficient comparison mechanism that wouldaccurately generate the similarity scores based on the series of poses between thesource and the target as the future scope of this project.Method Head Shoulder Elbow Hip Knee Ankle Wrist mAp\\nDeep cut 73.4 71.8 57.9 56.7 44.0 32.0 39.9 54.1\\nIqbal et al 70.0 65.2 56.4 52.7 47.9 44.5 46.1 54.7\\nDeeper cut 87.9 84.0 71.9 68.8 63.8 58.1 63.9 71.2\\nProposed Approach 90.7 90.9 79.8 76.1 70.2 66.3 70.5 77.7\\nTable 1.\\nmAP performance comparison of our model with others on a testing dataset of 568 images.\\nMethod Head Shoulder Elbow Hip Knee Ankle Wrist mAp\\nDeep cut 78.4 72.5 60.2 57.2 52.0 45.0 51.0 54.1\\nIqbal et al 58.4 53.9 44.5 42.2 36.7 31.1 35.0 54.7\\nDeeper cut 87.9 84.0 71.9 68.8 63.8 58.1 63.9 71.2\\nProposed Approach 90.1 87.9 75.8 73.1 65.2 60.3 66.5 73.7\\nTable 2.Performance comparison on a complete testing dataset of 1000 images.\\n54Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='912b5eb0-1380-4178-ab39-331a61d11989', embedding=None, metadata={'page_label': '55', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Author details\\nPooja Kherwa*, Sonali Singh, Saheel Ahmed, Pranay Berry and Sahil Khurana\\nMaharaja Surajmal Institute of Technology, New Delhi, India\\n*Address all correspondence to: poona281280@gmail.com\\n© 2021 The Author(s). Licensee IntechOpen. T his chapter is distributed under the terms\\nof the Creative Commons Attribution License ( http://creativecommons.org/licenses/\\nby/3.0), which permits unrestricted use, distribution, and reproduction in any medium,\\nprovided the original work is properly cited.\\n55Articulated Human Pose Estimation Using Greedy Approach\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9354', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='2f92f5cd-23c2-4b0b-898b-c7d7d573a3b2', embedding=None, metadata={'page_label': '56', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='References\\n[1]J. Redmon, S. Divvala, R. Girshick,\\nand A. Farhadi, “You Only Look Once:\\nUnified, Real-Time Object Detection, ”\\n2016 IEEE Conference on Computer\\nVision and Pattern Recognition\\n(CVPR), 2016.\\n[2]A.Toshev and C. Szegedy,\\n\"DeepPose: Human Pose Estimation viaDeep Neural Networks,\" 2014 IEEE\\nConference on Computer Vision andPattern Recognition , Columbus, OH,\\n2014, pp. 1653-1660.\\n[3]L. Pishchulin, E. Insafutdinov, S.\\nTang, B. Andres, M. Andriluka, P.Gehler, and B. Schiele, “DeepCut: Joint\\nSubset Partition and Labeling for MultiPerson Pose Estimation, ”2016 IEEE\\nConference on Computer Vision and\\nPattern Recognition (CVPR), 2016.\\n[4]S.-E. Wei, V. Ramakrishna, T.\\nKanade, and Y. Sheikh, “Convolutional\\nPose Machines, ”2016 IEEE Conference\\non Computer Vision and PatternRecognition (CVPR), 2016.\\n[5]W. Ouyang, X. Chu, and X. Wang,\\n“Multi-source Deep Learning for\\nHuman Pose Estimation, ”2014 IEEE\\nConference on Computer Vision andPattern Recognition, 2014.\\n[6]J. Tompson, R. Goroshin, A. Jain, Y.\\nLecun, and C. Bregler, “Efficient object\\nlocalization using Convolutional\\nNetworks, ”2015 IEEE Conference on\\nComputer Vision and PatternRecognition (CVPR), 2015.\\n[7]V. Belagiannis and A. Zisserman,\\n“Recurrent Human Pose Estimation, ”\\n2017 12th IEEE International Conference\\non Automatic Face & Gesture Recognition\\n(FG 2017) , 2017.\\n[8]A.Bulat and G. Tzimiropoulos,\\n“Human Pose Estimation via\\nConvolutional Part HeatmapRegression, ”Computer Vision –ECCV2016 Lecture Notes in Computer Science ,\\npp. 717 –732, 2016.\\n[9]T. Pfister, J. Charles, and A.\\nZisserman, “Flowing ConvNets for\\nHuman Pose Estimation in Videos, ”\\n2015 IEEE International Conference onComputer Vision (ICCV) , 2015.\\n[10]E. Insafutdinov, L. Pishchulin, B.\\nAndres, M. Andriluka, and B. Schiele,\\n“DeeperCut: A Deeper, Stronger, and\\nFaster Multi-person Pose Estimation\\nModel, ”Computer Vision –ECCV 2016\\nLecture Notes in Computer Science ,\\npp. 34 –50, 2016.\\n[11]K. He, X. Zhang, S. Ren, and J. Sun,\\n“Deep Residual Learning for Image\\nRecognition, ”2016 IEEE Conference on\\nComputer Vision and PatternRecognition (CVPR), 2016\\n[12]R. J. Mozhdehi and H. Medeiros,\\n\"Deep convolutional particle filter forvisual tracking,\" 2017 IEEE International\\nConference on Image Processing (ICIP) ,\\nBeijing, 2017, pp. 3650-3654.\\n[13]C. Savitha and D. Ramesh, \"Motion\\ndetection in video surveillance: Asystematic survey,\" 2018 2nd\\nInternational Conference on InventiveSystems and Control (ICISC) ,\\nCoimbatore, 2018, pp. 51-54.\\n[14]A. Shahbaz and K. Jo, \"Probabilistic\\nChange Detector with Human Verifierfor Intelligent Sterile Zone Monitoring,\"2018 IEEE 27th International Symposiumon Industrial Electronics (ISIE) , Cairns,\\nAustralia, 2018, pp. 777-781.\\n[15]L. Kong, X. Yuan, and A. M.\\nMaharjan, “A hybrid framework for\\nautomatic joint detection of humanposes in depth frames, ”Pattern\\nRecognition, vol. 77, pp. 216– 225, 2018.\\n[16]A. Toshev and C. Szegedy,\\n\"DeepPose: Human Pose Estimation via\\n56Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='071ef82d-2e8f-4300-9c93-63971a1af780', embedding=None, metadata={'page_label': '57', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Deep Neural Networks,\" 2014 IEEE\\nConference on Computer Vision and\\nPattern Recognition , Columbus, OH,\\n2014, pp. 1653-1660..\\n[17]S. Liu, Y. Li and G. Hua, \"Human\\nPose Estimation in Video via Structured\\nSpace Learning and Halfway Temporal\\nEvaluation,\" in IEEE Transactions on\\nCircuits and Systems for Video Technology\\n[18]A.Agarwal, D. Samaiya and K. K.\\nGupta, \"A Comparative Study of SIFTand SURF Algorithms under DifferentObject and Background Conditions,\"\\n2017 International Conference on\\nInformation Technology (ICIT) ,\\nBHUBANESWAR, India, 2017,pp. 42-45\\n[19]W. Kim, M. Lorenzini, K.\\nKapicioglu and A. Ajoudani, \"ErgoTac:A Tactile Feedback Interface for\\nImproving Human Ergonomics in\\nWorkplaces,\" in IEEE Robotics and\\nAutomation Letters .\\n[20]S. Huang, M. Gong, and D. Tao, “A\\nCoarse-Fine Network for KeypointLocalization, ”2017 IEEE International\\nConference on Computer Vision (ICCV) ,\\n2017.\\n[21]G. Papandreou, T. Zhu, N.\\nKanazawa, A. Toshev, J. Tompson, C.Bregler, and K. Murphy, “Towards\\nAccurate Multi-person Pose Estimationin the Wild, ”2017 IEEE Conference on\\nComputer Vision and Pattern\\nRecognition (CVPR), 2017.\\n[22]H.-S. Fang, S. Xie, Y.-W. Tai, and C.\\nLu,“RMPE: Regional Multi-person Pose\\nEstimation, ”2017 IEEE International\\nConference on Computer Vision (ICCV) ,\\n2017.\\n[23]Z. Cao, T. Simon, S. Wei and Y.\\nSheikh, \"Realtime Multi-person 2D Pose\\nEstimation Using Part Affinity Fields,\"2017 IEEE Conference on Computer Visionand Pattern Recognition (CVPR) ,\\nHonolulu, HI, 2017, pp. 1302-1310[24]X. Chen and G. Yang, \"Multi-Person\\nPose Estimation with LIMB DetectionHeatmaps,\" 2018 25th IEEE International\\nConference on Image Processing (ICIP) ,\\nAthens, Greece, 2018, pp. 4078-4082\\n[25]L. Ke, H. Qi, M. Chang and S. Lyu,\\n\"Multi-Scale Supervised Network forHuman Pose Estimation,\" 2018 25th\\nIEEE International Conference on ImageProcessing (ICIP) , Athens, Greece, 2018,\\npp. 564-568\\n[26]K. Akila and S. Chitrakala,\\n\"Discriminative human action\\nrecognition using -HOI descriptor and\\nkey poses,\" 2014 International Conference\\non Science Engineering and ManagementResearch (ICSEMR) , Chennai, 2014,\\npp. 1-6\\n[27]Y. Yang and D. Ramanan,\\n\"Articulated Human Detection with\\nFlexible Mixtures of Parts,\" in IEEE\\nTransactions on Pattern Analysis and\\nMachine Intelligence , vol. 35, no. 12, p\\n[28]Wang, Jinbao, et al. \"Deep 3D\\nhuman pose estimation: A review.\"Computer Vision and ImageUnderstanding (2021): 103225.\\n[29]Jin, Sheng, et al. \"Whole-body\\nhuman pose estimation in the wild.\"European Conference on ComputerVision. Springer, Cham, 2020.\\n57Articulated Human Pose Estimation Using Greedy Approach\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 9354', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='317cd390-f217-4d85-9a3d-019ba1e5491f', embedding=None, metadata={'page_label': '58', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='4a596f2e-a192-41d4-b520-a058a5b8c188', embedding=None, metadata={'page_label': '59', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 4\\nEnsemble Machine Learning\\nAlgorithms for Prediction and\\nClassification of Medical Images\\nRacheal S. Akinbo and Oladunni A. Daramola\\nAbstract\\nThe employment of machine learning algorithms in disease classification has\\nevolved as a precision medicine for scientific innovation. The geometric growth in\\nvarious machine learning systems has paved the way for more research in themedical imaging process. This research aims to promote the development ofmachine learning algorithms for the classification of medical images. Automatedclassification of medical images is a fascinating application of machine learning andthey have the possibility of higher predictability and accuracy. The technologicaladvancement in the processing of medical imaging will help to reduce the com-plexities of diseases and some existing constraints will be greatly minimized. This\\nresearch exposes the main ensemble learning techniques as it covers the theoretical\\nbackground of machine learning, applications, comparison of machine learning anddeep learning, ensemble learning with reviews of state-of the art literature, frame-work, and analysis. The work extends to medical image types, applications, bene-fits, and operations. We proposed the application of the ensemble machine learningapproach in the classification of medical images for better performance and accu-racy. The integration of advanced technology in clinical imaging will help in theprompt classification, prediction, early detection, and a better interpretation of\\nmedical images, this will, in turn, improves the quality of life and expands the\\nclinical bearing for machine learning applications.\\nKeywords: machine learning, medical image, classification, ensemble method\\n1. Introduction\\nThe application of technology to the health field is growing at a rapid pace and\\nmedical imaging techniques is part of the advancement of technology in the\\nsimplification of the medical imaging processes. It refers to an aspect of medicaloperations in this dispensation as it has overridden the traditional processes.Technological advancement is majorly responsible for the improvement in medicine\\nvia enhancement of imaging. The traditional perspectives on the clarification and\\ndiagnosis of the outcome of image processes require lot of processing time, humanerrors are foreseeable and the general outcome is unable to properly aligned withthe history as the former ones is not easily available for comparison. These limita-tions motivated this research work so as to give insight to the applications ofEnsemble Machine-Learning Algorithms for the Prediction and Classification ofMedical Images.\\n59', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='31df6dcf-7344-4f18-811b-2918d684eefd', embedding=None, metadata={'page_label': '60', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.1 Medical imaging\\nMedical Imaging refers to the application of different techniques to get various\\nimage modalities from the human body especially the affected area for further\\nprocessing and to assist in diagnosis and the treatment of the patients [1]. MedicalImage analysis is very important in today’ s world to be able to meet up with the\\ngrowing population and in the current trend of a low medical expert in anexpanding population. The healthcare industry has witnessed different technologi-cal disruptions that benefit humankind and more progress are being made. Having\\nprecision in the medical analysis of images will enhance the faster diagnosis and the\\ntreatment plan will be predicted along the line, this process increases the turn-around time with lots of lives being saved. It was reported that the market capacityof medical image analysis of software was estimated at USD 2.41 Billion in 2019,globally. In addition, the medical image processing market is forecast to reach about8.1% in 2027 [2].\\nIn medical imaging, radiology is a branch of medicine that uses imaging tech-\\nnology to diagnose and treat disease. The different types of diagnostic radiology\\nexamination comprise, Ultrasound, Plain X-Rays, Mammography, Fluoroscopy,\\nComputed tomography (CT), including CT angiography, Magnetic ResonanceImaging (MRI), and Magnetic Resonance Angiography (MRA), Nuclear medicine,and Positron Emission Tomography [3]. Furthermore, the recent advancements inimage processing as of the year 2020 are, EVP (Enhanced Visualization Processing)Plus, Bone Suppression, Pediatric Capabilities, Tube and Line Visualization, Long-length Imaging, and Pneumothorax Visualization. The operation of computer-mediated imaging processing is done using some computational framework, pro-\\ngramming language, and algorithms which will make the prediction and classifica-\\ntion to be an automated process and produce the result analysis [4].\\nThe techniques involve professional in the medical field to use a particular device\\nto create computerized images of an affected area in the body for diagnosis that willlead to treatment. The process may not necessarily include the opening of the affectedpart before using the radiological equipment in viewing the area that needed diagno-sis. The medical personnel will later produce the image of the affected part from thedevice and then summarized the image analysis. Moreover, some medical imaging\\ninvolves not just bones, blood vessels, and tissue without tearing apart the affected\\nskin. Generally, the imaging techniques allow the healthcare providers to determinethe type of treatment that is required for the ailment. Medical imaging has brought amajor improvement in medicine as the difficult part or layers of the internal systemof humans and animals can now be done using technological devices. The majortechnological improvement has decreased the manual work of the health providersand thereby give rise to specific and better treatment.\\n1.1.1 Medical image applications\\nThe utilization of medical image in ultrasound, presents the internal part of a\\nhuman or even animals; to be examined under an ultrasound device applicable\\njoints, muscles, breast, blood vessels, pelvic, bones, and kidneys to say the least [5].\\nThe X-ray is another category that employ the electromagnetic radiation and\\npenetrates through the outer skin, layer to disclose the internal components [6].Computer Tomography is a medical image that has an opening area in a circularform, the patient will be placed on it and slide inside; it produces images in across-sectional way [7].\\nMagnetic Resonance Imaging harness radio waves with magnetic fields to develop\\nimages with no harmful radiation compared to x-rays. It can generate images from\\n60Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='9dac095a-1266-4822-9441-a6c08579fc95', embedding=None, metadata={'page_label': '61', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='soft tissue, bones, organs, cartilage, brains breast, spinal cord, liver, prostate, and\\nligaments, etc. [8]. Positron emission tomography (PET) scan can be used to scan the\\nwhole body or part of it. It uses a type of tool called tracer which will be swallowed or\\ninjected by the patient and then lie on the PET scanner to be examined by detectingthe gamma rays by the device which is converted to images. PET scans can be appliedin the diagnosis of conditions like brain disorders, tumors, and heart-related diseases,etc. [9]. The application of Ensemble Machine Learning technologies will improve theprocessing of medical images as it allows management, monitoring, early detection,diagnosis, assessment, and treatment of various medical challenges.\\n1.1.2 Challenges in medical image classifications\\nThe application of Machine Learning vis-à-vis image generations promised a\\nbetter way to visualize images and generally improves the medical condition of\\nhumans. This has brought out candid information from the input sample and it hasencouraged a better decision to the treatment pattern of the concerned patient withthe overall benefit of good living. These techniques are mostly used in the radiologyfield and pathology. The traditional model of result interpretation presents theproblems of data bottlenecks, reliability, accuracy, and speed, and most of theissues with the traditional methods are being addressed with the machine learningalgorithms and techniques. The more the technology is advancing, the more there is\\na need to have better analysis and clarity in medical imaging prediction and classi-\\nfication. The challenges that are associated with Machine Learning applications are;data availability, validation of methods, patient-specific model faster and accuratealgorithms [10]. The learning models should be built into clinical operations and beintuitive so as not to cause serious damages. Training of the care providers and thedocumentations of analysis of the algorithms is another challenge that is needed tobe looked into for future adaptation of research students and the users [11].\\n1.1.3 The benefits of medical image processing\\nThe main advantage of medical image processing is the opportunity to explore the\\ninternal system of the human organ called anatomy, it is such an interesting thing to\\nbe able to view the inner system and see how things work. The rate of death isdrastically reduced as more outcomes of the image processes allows timely interven-tion and prompt treatment of the ailment. Another benefit is the deep knowledge ofthe internal anatomy which helps to enhance treatment and diagnosis outcomes.\\n1.1.4 Medical image professional\\nThe professionals that are involved in the operation of medical imaging is the\\nclinicians, radiologist, and engineers ’radiographers, radiologists, and engineers to\\nknow the anatomy patients. The medical imaging device is used to do imaging is\\noperated by the radiographers and the result is sent to the caregiver to interpret it to\\nthe patient. One of the significant of Machine Learning in the aspect imaging is theenhancement, interpretation and analysis of results better than the manual resultfrom human.\\n1.2 Machine learning\\nThe advancement in computational applications and frameworks provides solu-\\ntions to our everyday problems. Machine learning is one of the computational\\napplications of algorithms and statistical models with the use of algorithms and\\n61Ensemble Machine Learning Algorithms for Prediction and Classification of Medical Images\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.1 00602', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='0923ce18-b90f-44f6-8c4e-3fe2d4c35542', embedding=None, metadata={'page_label': '62', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='statistical models, to carry out a task without explicit instructions but with the use\\nof patterns to give inference. Machine learning is referred to the use of computer\\nalgorithms that support systems operation in training to automatically learn and\\nenhance data to predict or classify the nature of such data through the use ofpatterns [12]. Generally, machine learning is a subfield of artificial intelligence thatallows the systems to make decisions autonomously with no external support. Thedecision is made by finding valuable hidden layers of patterns within the complexdata.\\nThe machine-learning approach depends on the data type for input and output\\noperation and problem type which is based on the applications on data for decision\\nmaking and an embedded instruction to carry out the assignment with minimum\\nsupervision from the programmers [12]. Machine learning is classified as supervisedlearning, semi-supervised learning, and unsupervised and reinforcement learningwhile there are few hybrid approaches and other common methods [13].\\n1.2.1 Machine learning techniques\\nThe categories of Machine Learning Techniques are mainly divided into four\\ncategories: Supervised learning, Unsupervised learning, Semi-supervised learning,\\nand Reinforcement learning [12]. The techniques are discussed further according totheir applicability of solving real-world problems.\\n1.2.1.1 Supervised learning\\nIn the supervised learning category of machine learning, the algorithms (step by\\nstep method of solving a problem in a particular format) operates in such a way that\\nit will develop a mathematical model (translating or encoding a problem into amathematical formulations) of the data which comprises the inputs (data sent to acomputer system) and the expected outputs (processed information sent out from acomputer) [14]. The data supplied is also categorized as the training data whichcomprises the sets of training examples with one or more inputs. The mathematicalmodeling is applied in the supervised learning uses array vector (feature vector for\\nextraction) and the data to be trained by matrix. The algorithm that enhances and\\nimproves the outcomes in the accuracy of the outputs for classification or predictionpurposes has learned the task and therefore it can give a good outcome [15].\\n1.2.1.2 Unsupervised learning\\nUnsupervised learning algorithms operate in such a way that it takes set of data\\nand detect the patterns in it for grouping or clustering purpose. Unsupervised\\nlearning algorithms identify resemblance in the data and react based on the pres-ence or absence of such identity in each new piece of data. The algorithms learnfrom test data that is not labeled, classified, or categorized. Unsupervised learning\\nanalyzes unlabeled datasets without the need for human interference, i.e., a data-\\ndriven process [16]. The unsupervised learning tasks that are common are anomalydetection, dimension reduction, clustering, density estimation, feature learning,finding association rules, etc. [17].\\n1.2.1.3 Semi-supervised learning\\nThe semi-supervised learning is situated between unsupervised learning (with\\nno labeled training data) and supervised learning (with labeled training data). It is a\\nhybrid form of machine learning techniques because it operates on labeled and\\n62Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='28ff4f63-40d4-4127-8906-c0dd28091dfb', embedding=None, metadata={'page_label': '63', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='unlabeled data which brings a better accuracy. The major aim of unsupervised\\nlearning is to give great outcomes for prediction than the ones done with labeled\\ndata. The application areas of semi-supervised learning are text classification, fraud\\ndetection, machine translation, etc. [18].\\n1.2.1.4 Reinforcement learning\\nReinforcement learning in machine learning parlance refers is concerned with\\nthe use of software agents and machines to make the decision automatically in an\\nenvironment to improve efficiency. Generally, reinforcement learning is used inoperation research, game theory, information theory, swarm-intelligence, andgenetics algorithms, etc. The learning uses the reward or penalty system, and theprimary goal is to use leading obtained from environmental parameters to validate\\nthe reward or to minimize the risk involved. The algorithms are used in autonomous\\nvehicles or in learning to play a game against a human opponent, it is an effectivetool in training AI models for increase automation which is used in robotics, auton-omous driving tasks, manufacturing, and supply chain logistics [12].\\n1.2.2 Applications of machine learning\\nThe areas of applications of machine learning to various fields are enormous\\nsuch as agriculture, engineering, medical diagnosis, natural language processing,\\nbanking, bioinformatics, games, insurance speech recognition, and recommendedsystem etc. [19], used machine learning technology to make a medical diagnosis in\\ndeveloping a cure for Covid-19. Similarly, machine learning is also applied in [20]\\nwork to predict visitors ’behavior in marine protected areas, while [21] applied\\nmachine learning to smartphone performance optimization. According to [22] byMayo, the most common data science/machine learning methods used from theperiod of 2018 –2019 are regression, decision trees/rules, clustering, visualization,\\nrandom forests, statistics, K-nearest neighbors, time series, ensemble methods, textmining, principal component analysis (PCA), boosting, neural networks (deeplearning), gradient boosted machines, anomaly/deviation detection, neural net-\\nworks Convolutional Neural Networks (CNN) and support vector machine (SVM).\\n1.2.3 Machine learning and deep learning\\nDeep learning refers to a distinctive subtype variant in the machine learning,\\nalso a subclass in the domain of artificial intelligence (AI). Furthermore, Machine\\nlearning primarily means a computer that learns from data and makes predictionsusing algorithms. Machine learning yields to some environmental parameters, con-versely, the deep learning operates in a quick manner and adapt to it using constantfeedback in building on the models. Deep Learning system leverage on the NeuralNetworks which imitates the brain of human with an embedded multiple-layer\\narchitecture. It also learns through the data to carry intelligent decisions [23].\\n1.2.4 Ensemble machine learning\\nEnsemble learning is a general meta-approach to machine learning as it looks for\\nthe best predictive performance using a combination of the methods to achieve the\\nbest accuracy [24]. The use of different machine learning algorithms individuallymay not be able to give the best outcomes, hence the combination of the algorithmswill combine all the strength of the model and brings out a better accuracy. Thediagram below shows different Machine learning algorithms. The Ensemble\\n63Ensemble Machine Learning Algorithms for Prediction and Classification of Medical Images\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.1 00602', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c5aee2c7-834c-45d9-9b93-53bd0dfbbebb', embedding=None, metadata={'page_label': '64', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='learning methodology for the prediction and classification of medical images has\\nbeen established to have a better result than using a single classifier. The reviews on\\nelated works in artificial intelligence systems to detect fractures in the body cited\\nfew works on Convolutional Neural Networks (CNN) for fracture detection [25].\\nThe authors also noted that stacking with Random Forest and Support Vector\\nalgorithm, with neural networks were mostly engaged. The development of anEnsemble deep learning application for ear disease using otoendoscopy images by[26]. They perform well with the average of accuracy taken as 93.67% for the five-fold cross-validation using learning models based on ResNet101 and Inception-V3.Furthermore, another author developed a three-dimensional bone model system\\nwhich is based on employment of x-ray images for distal forearm engaging the\\nconvolutional neural networks [27]. The deep learning framework is employed inestimating and to construct a high accuracy for three-dimensional model of bones.The result gives correctness of the evaluation of CNN to reduce exposure to com-puter tomograph device and cost. In summary, the application of Ensemblemethods to medical imaging can be perused with all intent as the accuracy recordedis far more than the single classifiers or the traditional methods.\\nThere are three classes of ensemble learning, bagging, stacking and boosting.\\nThe bagging is concerned with having many decisions on a different sample of thevery same dataset and get the average of the prediction; while the stacking isconcerned with the fitting of many different types of models on the same data whileusing another type of model to learn the combined predictions. The boostinginvolves the addition of ensemble members in a sequential manner that will correctthe former prediction by the other models then gives the average of the predictions(Figure 1 ) [24].\\n1.3 Neural networks\\nThe Neural Networks is an aspect of machine-learning that comprises different\\nnode layers which include the input, hidden, and output layers. The Network is\\nused in most deep learning architectures. Neural Networks works in a manner that\\nthe nodes connect with their different weight and threshold. More so, if a node forinstance has an output that is more than that of the threshold, then it will betriggered and will send the data involved to the layer that is next and if not, therewill be no data being activated to the succeeding layer in the network.\\nFigure 1.\\nEnsemble machine learning combine several models for better accuracy.\\n64Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='f91b002a-40be-4e5d-ba2d-e39f48551519', embedding=None, metadata={'page_label': '65', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.3.1 Convolutional neural network\\nThe traditional manual process employed in the prediction and classification of\\nimages convincingly, wastes time, wrong diagnosis is another major problem\\nattributed to it. The convolutional neural network provides a better and morescalable method in the medical imaging process. The CNN involves the identifica-tion of images through a computational approach that combines linear algebra andmatrix multiplications. CNN outperformed other networks in applications likeimage processing and speech recognition, The CNN has three parts, the\\nconvolutional, pooling, and fully-connected layer. The convolutional part is where\\nthe major computation happens to be the building block among the three and itcomprises the data, filter, and feature area. Pooling layer is responsible for the datasample dimension reduction known as downsampling. The pooling layers also holdsa filter and it moves over the input but may not have weight. The pooling issub-divided into Max and Average pooling with the functions of calculating themaximum and or average value respectively [28]. The fully-connected layer, outputlayers are fully joined via a node to former layer and do classification tasks through\\nthe feature extracted from the preceding layer.\\n2. Literature review\\nVisual Attention Mechanism-MCNN was developed using classification Algo-\\nrithm According to the authors, the motivation was a result of the complexity of\\nmedical images as a traditional way of analyzing medical images is presented withsome disadvantages and it may not be able to meet up with the growing demands.The methodology is based on a medical classification algorithm that uses visualattention mechanism multiscale convolutional neural network. The results showthat the medical image classification was more accurate with stability, robustnessand improved with the employment of the deep learning methods than the tradi-\\ntional methods [29].\\nIn the article titled “Machine Learning: Algorithms, Real-World Applications\\nand Research Directions ”, they stated the positive impact and the present challenges\\nof Machine Learning algorithms to the real-world application and research direc-\\ntion. The authors explained further that is an enormous advantage to the intelligentand automatic operations of machine learning to a different field of study [13].\\nThe primary goal of machine learning is in the automation of human assistance\\nby training an algorithm on suitable data Machine Learning as they focused on\\nlearning types. The author stated different machine learning techniques and the\\nways to apply them to various operations. The algorithms are used for many appli-cations that include data classification, prediction, or pattern recognition [30].\\nMedical image analysis based on a deep learning approach which helps in dif-\\nferent clinical applications as it occurs in medical procedures for monitoring, diag-nosis, and detection was proposed for early detection, monitoring, diagnosis, andtreatment evaluation of various medical conditions. The methodology employedartificial neural networks and the detailed analysis of deep learning algorithms and\\ndelivers great medical imaging applications [31].\\nThe applications of Machine Learning Predictive Models in the Chronic Disease\\nDiagnosis, presented different reviews on the employment of machine learning\\npredictive models for the diagnosis of chronic diseases. The motivation of theauthors arises from the major health cost of disease especially for those that attractlifelong treatment. The methodology of the predictive models involves the analysisof 453 papers from 2015 and 2019, PubMed (Medline), and Cumulative Index to\\n65Ensemble Machine Learning Algorithms for Prediction and Classification of Medical Images\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.1 00602', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='bd0bc40f-726e-4ee4-a2f9-71f93072cf74', embedding=None, metadata={'page_label': '66', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Nursing and Allied Health Literature (CINAHL) libraries. The result of the investi-\\ngation shows that the support vector machines (SVM), logistic regression (LR),\\nclustering was among the most commonly used models [32].\\nAn ensemble approach in the classification of bone fracture using different CNN\\nis presented. The authors were motivated by the need to help the emergency nature\\nof bone fracture for a prompt response than the usual process of going through theX-ray and then forwarded to the doctors for better interpretations of the result. Theprocess can take a long time as nothing significant can be until the result is out. Toincrease the processes that are involved in carrying out this important aspect of amedical emergency, a new method is proposed by the author. The research employs\\nensemble machine learning techniques using CNN to classify the bone fracture\\nimages with stacking methodology for reliable and robust classification. The resultshows that the ensemble method is more reliable and forms a robust output than themanual works from the providers [33].\\nThe classification of shoulder images using X-ray images with deep learning\\nensemble models for diagnosis, with the data gathered from the X-ray images frommagnetic resonance imaging and computer tomography. The target of the researchis to determine the state of the images through classification using artificial intelli-\\ngence. The study employs twenty-six deep learning models to detect the shoulder\\nfracture and evaluate using the musculoskeletal radiographs datasets, together withensemble learning models. The twenty-eight classification was performed and theoverall accuracy was from Cohen ’s kappa. The best score was 0.6942, taking an\\nensemble of ResNet34, DenseNet169, DenseNet201, and a sub-ensemble of differ-ent convolution networks [34].\\nIn 2019 some authors constructed Xception, Resnet, and Inception-V3 CNNs to\\ndetermine appearance of fractures on the ankle through ensemble methods. The\\napproach involved using five hundred and ninety-six ankle cases both the normal\\nand abnormal for the processing. The programming language applied is Pythonwith the TensorFlow framework. The outputs were in radiographic views of oneand three. The ensembles were made from combined convolutional networks, andthe voting approach was applied to incorporate results from the views and ensemblemodels. The results show 81% accuracy despite the small dataset used [35].\\nFurthermore, in 2021 an investigation was done for the detection of tuberculosis\\nin x-ray images of the chest via Ensemble Learning method together with hybrid\\nfeature descriptors as Tuberculosis (TB) is a major health challenge that has a record\\nof high mortality and early diagnosis is key to early control of the disease. Theauthor proposed an innovative approach to TB detection that combines hand-crafted features with deep features using convolutional neural networks throughEnsemble Learning. The dataset captured from Montgomery and Shenzhen for thecritical evaluation of the system. The result shows the distinction of the Ensemblemachine Learning method over the other classifier as a single unit in classificationsas the operating characteristics curve reaches 0.99 and 0.97 respectively from the\\nShenzhen and Montgomery [36].\\nIn the Ensembles Learning for COVID-19 Detection using Chest X-Rays. The\\ndevelopment applied Ensemble approach for the X-ray classification in detecting\\npulmonary manifestation of COVID-19 is established. The methodology entails acustomized convolutional neural network and ImageNet pre-trained models whilethe dataset is from publicly available collections. The best predictions from the bestaccurate models are combined via different Ensemble approaches for better perfor-mance evaluation. The result shows a major improvement of 99.01% accuracy and\\nthe area under the curve to be 0.9972 for the detection of COVID-19 on the dataset\\ncollections. The blend of the iterative, Ensemble, and modality bases knowledgetransfer shows a major improvement in the prediction level [37].\\n66Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='b9a77490-fb29-4c11-bd40-f79cf834343c', embedding=None, metadata={'page_label': '67', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3. Ensemble methods and design analysis\\nThe ensemble system of machine learning application is a type of method that\\nallows the combination of multiple models to produce an output that is improved\\nand enhanced than applying the single model. The ensemble predictive modelgenerated is to have a decrease in variance (bagging), bias (boosting), or to improvethe predictions (stacking). The ensemble machine learning methods consist ofsequential, parallel, homogenous and heterogenous ensemble, while the technical\\nclassifications of ensemble method are, bagging, boosting, stacking, and random\\nforest [38].\\n3.1 Ensemble methods\\nIn the continuous method, the base learners (where the data dependency stays)\\nare being initiated successively. Moreover, there is a dependency on the former data\\nof all other data in the base level and to get the performance analysis of the system,the wrongfully-labeled are adjusted based on the weight. An example of this type of\\nanalysis is the boosting method. The parallel methodology ensures that the base\\nlearner is initiated in a parallel manner and the data dependency is not available,and all the data are generated separately. A very good example of this model is thestacking method [38].\\nThe homogenous ensemble method can be applied to a large number of the\\ndataset as it employed the combination of the very same types of classifiers. Thedataset is always different for each classifier and the model works well following theresults collection for each of the classifier models. The feature selection method is\\nthe same for different training of data. The major disadvantage of this type of model\\nis that the computational cost is very expensive. The popular type of this model isthe bagging and boosting method. Conversely, the heterogeneous ensemble methodcombines different classifiers and each of them is generated on the same data, thesetypes of methods are used for small datasets and the feature selection method isdifferent for the same training dataset. An example of this type of classifier isstacking [38].\\n3.2 Technical classification of ensemble approach\\n3.2.1 Bagging\\nThe bagging method ensemble learning represents the bootstrapping and aggre-\\ngation of combining two models into one ensemble model. Bagging uses random\\nsampling to reduce the variance of the model by creating more data at the trainingstage of the model and every element in bagging has a way to appear in the newdataset. This method decreases the variance and narrowly changes the prediction toan expected output [38].\\n3.2.2 Boosting\\nThe boosting method of ensemble classification makes use of a continuous\\nmethod of classifying based on the features that the next model will utilize. The\\nboosting methods make a stronger learner out of a weak learner model using weightaverage. The much stronger trained model relies on the multiple weak trainedmodels. The weak learner is the one with the less correlated true classification andthe next one is improved over the last one which will be a bit more correlated, the\\n67Ensemble Machine Learning Algorithms for Prediction and Classification of Medical Images\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.1 00602', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='bc22611a-009f-4b45-b85a-6fa7d29e4965', embedding=None, metadata={'page_label': '68', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='aggregation of the weak learners makes up the strong learner that is well correlated\\nwith accurate classification [38].\\n3.2.3 Stacking\\nIn the stacking method, a different classifier is also used using the regression\\ntechniques or multiple combinations of the models. The operation involves training\\nthe lower-level with the entire dataset in which the outcomes are used to train thecombined model. This is different from boosting in the sense that the lower level isin line with parallel trained. The prediction from the outcome of the lower levelforms the next model as a stack. The stack operation is such that the top of the stackis the most trained and has goo prediction while the down of the stack is the least\\ntrained. The predictions continue until the best surfaced with fewer errors [38].\\n3.2.4 Random forest\\nThe random forest models employ tree operations to carry out the sampling of the\\ndataset. The tree is fitted on bootstrap samples and the output is aggregated together\\nto reduce variance. It uses the features to sample the dataset in a random subset forthe creation of the tree to reduce the correlation of the outputs. This model of randomforest is best for determining the missing data as it selects a random subset of thesample to reduce the possibility of having common prediction values, with each treehaving a different structure. The resultant variance result from the average of the\\nlesser prediction from different trees gives better output [38].\\n3.3 Ensemble framework\\nIn machine learning, ensemble methods and/or models employ the blend of\\ndifferent learning algorithms to give a better predictive performance that displays\\nan outcome that surpasses what could be gathered from the single application ofany of the learning models. Experimentally, ensembles models produce a moreimproved output as there is major distinctiveness among the model. The ensembleframework is depicted in Figures 2 and3below.\\n3.4 Ensemble framework component\\nThe framework of ensemble learning as depicted in Figure 2 consists of the\\ndataset, samples of data, different types of learners and the predicted output.The dataset denotes the medical images such as Ultrasound, Plain X-Rays,Mammography, Fluoroscopy, Computed tomography (CT), including CT angiog-raphy, Magnetic Resonance Imaging (MRI), and Magnetic Resonance Angiography(MRA), Nuclear medicine, and Positron Emission Tomography e.tc. The samplesare the data to be trained by each model of the classifier before combing them\\ntogether for the ensemble classifier to aggregate all the model predictions.\\n3.5 The classification and prediction block diagram\\nThe block diagram of the system incorporates the following: The dataset is the pre-\\nprocessed images that will be divided into training and validation set. The input\\nfunction is then activated while estimate or facilitates construction and training of themodels with appropriate APIs that include four sequential actions, they are training,evaluation, prediction, and export. The training and evaluation will be looped. Thetraining setcompute the loss and adjust the weights of the model using gradient\\n68Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c882fd58-3c78-4058-bb2a-668f2c25162b', embedding=None, metadata={'page_label': '69', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='descent, the evaluation set validate the model while training and adjust the learning\\nrate then and take the best version of the model, while the test set is used to comparedifferent model approaches, and report the final result of the model ( Figure 4 ).\\n3.6 Methodology\\n3.6.1 Techniques/method(s)\\nDifferent tools that can be adopted for this type of research include the\\nfollowing:\\nFigure 3.\\nBlock diagram of the classification and prediction.\\nFigure 2.Ensemble framework for prediction and classification of medical images.\\n69Ensemble Machine Learning Algorithms for Prediction and Classification of Medical Images\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.1 00602', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='b27cd1e2-6674-4672-84b1-d96ba3acb9f7', embedding=None, metadata={'page_label': '70', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='i. TensorFlow image recognition with object detection.\\nii. Python programming language for scripting.\\niii. Evaluation using MATLAB\\n3.6.2 Data extraction\\nData will be extracted from the medical images represented by the distribution of\\npixels. To improve the data, standardization of the data is necessary before the applica-\\ntion of the principal component analysis and these will enable each of the feature to haveits mean = 0 while the variance = 1 Mathematically, this can be done by subtracting themean and dividing by the standard deviation for each value of each variable. PCA makesmaximum variability in the dataset more visible by rotating the axes.\\nZ¼\\nx�μ\\nσ(1)\\n3.6.3 The use of covariance matrix\\nThe next step is to create a covariance matrix by constructing a square matrix to\\nexpress the correlation between two or more features in a multidimensional dataset.\\n3.6.3.1 Principal component analysis\\nThe PCA is used for technique dimensionality reduction with the operation of\\nusing measurement vector for distance classification, it explores the pattern\\nFigure 4.\\nDecision tree structure with tree and subtree.\\n70Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='5f51a370-1a1a-45c9-a109-de02f290c116', embedding=None, metadata={'page_label': '71', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='recognition techniques [39]. It is best used for feature extraction, removal of\\nredundancy, and feature extractions. A simple analysis of the PCA algorithm for\\nimage classification is given below. The PCA employs the Eigenvectors and Eigen-\\nvalues by the sorting of the eigenvectors in highest to lowest order, then select thenumber of principal components using the following equations:\\nPC1¼w\\n1,1Feature Að Þþ w2,1Feature BðÞ …:þwn,1Feature NðÞ (2)\\nPC1¼w1,2Feature Að Þþ w2,2Feature BðÞ …:þwn,2Feature NðÞ (3)\\nPC1¼w1,3Feature Að Þþ w2,3Feature BðÞ …:þwn,3Feature NðÞ (4)\\nThe first of the principal components (PC1) is a synthetic variable built as a linear\\ncombination to determine the magnitude and the direction of the maximum variancein the dataset. The second principal component (PC2) is also a synthetic linear combi-nation that captures the remaining variance in the data set and is not correlated withPC1. The rest of the principal components likewise capture the remaining variationwithout being correlated with the previous component. PCA allows resizing of medicalimages, patterns recognition, dimensionality reduction, and visualization of\\nmultidimensional data. The covariance matrix is symmetrical and has the form:\\nC¼w11w12 w13\\nw21w22 w23\\nwn1 wn2 wn3(5)\\neigenvalues of matrix C are the variances of the principal components.\\nPCi¼w\\ni1X1þwi2X2þ…:wipXp (6)\\nWhere var(Pcii)=λiand the constants w i1,wi2,…,wipare the elements of the\\ncorresponding eigenvector,\\nTherefore, w2\\ni1þw2\\ni2þ…:þw2\\nip¼1 (7)\\nThe sum of variances of the PCA is equal to the sum of variances of the original\\nvariances. The principal components contain all the variation of the original data.\\n3.6.3.2 Logistic regressions\\nLogistic regression is a linear algorithm (with a non-linear transform on output).\\nIt can have a linear relationship between the input variables and the output. Data\\ntransformation can come from the input variables result in a more accurate model[40]. In the following Eqs. (8)-(10) z is the output variable, x is the input variablewhere w and b will be initialized as zeros, to begin with, and they will be modified\\nby numbers of iterations while training the model. The output z is passed through a\\nnon-linear function. The commonly used nonlinear function is the sigmoid functionthat returns a value between 0 and 1. The logistic regression uses the basic linearregression formula as:\\nfor a 0 ≤hθxðÞ≤1 binary/C0/C1\\n(8)\\nh\\nθxðÞ¼ωxþb ðÞ , where θis the vector of parameters w, b ðÞ (9)\\ngzð Þ¼1\\n1þe�zWhere g z ðÞis the Sigmoid function (10)\\n71Ensemble Machine Learning Algorithms for Prediction and Classification of Medical Images\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.1 00602', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='554beaf7-0d0d-47b5-930b-144efbdae2ae', embedding=None, metadata={'page_label': '72', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='hθxðÞ¼1\\n1þe�ωxþb ðÞ(11)\\nTo train a logistic classifier hθxðÞfor each class of y prediction gives:\\nypredict¼gzð Þ¼1\\n1þe�zSigmoid FunctionðÞ which is optimized : (12)\\n3.6.3.3 Decision tree\\nThe building of the decision tree begins with the root and then moves to the sub-\\nnodes. The nodes represent characteristics features that represent the decision\\npoints, hence the information is classified. The nodes are linked at different levels toeach other by branches that represent different decisions made by testing the statusof the features in the node. It is a type of supervised machine learning algorithmthat uses the if and else statement with a tree data structure for its operation [41].\\nThe decision tree algorithm is based on the use of Shannon Entropy which\\ndetermine the amounts of information of an event. If the probability distribution isgiven P as P = (p1, p2, P3, …, Pn), with a sample data S, the information carried by\\nthis distribution is called the Entropy of P and is given by the following equation,where (Pi) is the probability that the number (i) will appear during the process.\\nP¼p1, p2, P3, …, Pn ðÞ (13)\\nEntropy Pð Þ¼X\\nn\\ni¼1Pi X log Pi ðÞ (14)\\nGain P ,Tð Þ¼ Entropy Pð Þ�Xn\\nj¼1Pj X Entropy Pj ðÞ ðÞ (15)\\nWhere Pj is a set data of all values of (T).\\n3.6.3.4 Artificial neural network\\nNeural networks use set of algorithms to recognize patterns in medical images\\nthrough machine perception, labelling of the raw input. The layers are made ofnodes [42]. loosely patterned. A node combines input from the data with a set of\\ncoefficients, or weights, that either amplify or dampen that input, thereby assigningsignificance to inputs concerning the task the algorithm is trying to learn. These\\nFigure 5.\\nNeural network modeling and output function.\\n72Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='788cc5ec-fa2c-49fa-907a-defad9d4b1ea', embedding=None, metadata={'page_label': '73', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='input-weight products are summed and then the sum is passed through a node ’s\\nso-called activation function, to determine whether and to what extent that signal\\nshould progress further through the network to affect the outcome ( Figure 5 ).\\nThe input layer is denoted by X 1,X2,X3,…Xn, (16)\\nthe first input is X 1and the other several inputs to X n.\\nFigure 6.\\nFlowchart diagram of the classification and prediction.\\n73Ensemble Machine Learning Algorithms for Prediction and Classification of Medical Images\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.1 00602', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c2da7899-51ce-465e-9330-5441a4a5f02d', embedding=None, metadata={'page_label': '74', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The connection weight is also denoted by W 1,W 2,W 3,…Wn: (17)\\nThe weight signifies the strength of the node.\\na¼Xn\\nj¼1wθxjþb (18)\\nWhere a is the output generated from multiple input. The output is a weighted\\ncombination of all the inputs. This output a is fed into a transfer function f to produce y.\\n3.7 The system flowchart\\nImage Pre-processing: The aim of this process is to improve the image data\\n(features) by suppressing unwanted distortions and enhancement of some impor-\\ntant image features so that our Computer Vision models can benefit from thisimproved data to work on. Detection of an object: Detection refers to the localiza-tion of an object which means the segmentation of the image and identifying the\\nposition of the object of interest. Feature extraction and Training: This is a crucial\\nstep wherein statistical or deep learning methods are used to identify the mostinteresting patterns of the image, features that might be unique to a particular class,and that will, later on, help the model to differentiate between different classes.This process where the model learns the features from the dataset is called modeltraining. Classification of the object: This step categorizes detected objects intopredefined classes by using a suitable classification technique that compares theimage patterns with the target patterns ( Figure 6 ).\\n4. Discussion\\nEnsemble machine learning application method for the classification and pre-\\ndiction of medical images is proposed in this study. The study focuses on the use ofdifferent machine learning algorithm as a combined model to get better result as aresult of the aggregation of the models. The images will be first pre-processed,augmented, fed into the classifier for training and testing for evaluation and thenthe predicted result.\\n5. Conclusion\\nConclusively, the traditional approach of reading results from medical images by\\nthe care providers cannot be devoid of errors as well as the time take to predict theresult of such images. In case of emergencies, early detection of any ailment willattract prompt, treatment and time management is also a vital aspect of the process.The application of Ensemble machine learning algorithms to medical imaging is ajustifiable approach to obtain a better accuracy compared to the single classifier oreven the traditional reading of results from the radiologist. This paper established a\\nbrief study that enclosed different machine learning algorithms and the combina-\\ntions to make an ensemble learning classifier. More so, it stated the positive effect ofhaving an ensemble approach for the prediction and classification of medical imag-ing. The paper also includes some of the reviews that are relevant to the study area.The explanation of medical images is one of the most demanding aspect of predic-tion and classification of diseases that occurs daily in medical diagnosis. The appli-cation of machine learning in the classification and prediction of medical images is\\n74Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='acc1590c-6f70-48b7-b50f-819cf73dc758', embedding=None, metadata={'page_label': '75', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='growing at a geometric rate. A high level of precision and knowledge in the specific\\nfield may be required for accurate inference. The effectiveness and the efficiency of\\nthe combinations of different machine learning algorithm will enable better under-\\nstanding of biological integration and analysis of knowledge as it improves accessand transition in healthcare. The impact will reduce cost, earlier detection of dis-eases and accurate interpretation of results than using the single model. Theresearch has the potential to cause a major shift in the field of medicine.\\nAcknowledgements\\nThe authors are grateful to the participants who contributed to this research\\nespecially Mr. Gowin Akinbo for his immense contribution in proof reading thispaper for publication.\\nConflict of interest\\nThe authors declare no conflicts of interest for this publication.\\nAuthor details\\nRacheal S. Akinbo* and Oladunni A. DaramolaFederal University of Technology, Akure, Nigeria\\n*Address all correspondence to: rachea.akinbo@gmail.com\\n© 2021 The Author(s). Licensee IntechOpen. T his chapter is distributed under the terms\\nof the Creative Commons Attribution License ( http://creativecommons.org/licenses/\\nby/3.0), which permits unrestricted use, distribution, and reproduction in any medium,\\nprovided the original work is properly cited.\\n75Ensemble Machine Learning Algorithms for Prediction and Classification of Medical Images\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.1 00602', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='b5737b37-f7cd-4a9f-b061-1ae989ecf413', embedding=None, metadata={'page_label': '76', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='References\\n[1]Suetens P. (2017). “Fundamentals of\\nMedical Imaging ”, Cambridge\\nUniversity Press, ISBN:9781316671849.\\nDOI: doi:10.1017/9781316671849\\n[2]Gerasymov O. (2020). “Medical\\nImage Analysis and Processing ”,\\nAvailable from: https://codeit.us/blog/\\nmedical-image-analysis-processing-\\nsoftware [Accessed: 2021-06-25]\\n[3]MedlinePlus (2021). “Imaging and\\nradiology ”Available at: https://medline\\nplus.gov/ency/article/007451.htm\\n[4]Wang X (2020). “Future of medical\\nimaging, imaging trends 2020,MailChimp, medical imaging 2020,medical imaging trends ”Available from:\\nhttps://www.carestream.com/blog/2020/01/14/medical-imaging-trends-in-2020/ [Accessed: 2021-06-25]\\n[5]U.S. Food & Drug Administration\\n2020a, Ultrasound Imaging, FDA,viewed 18 2021-9-2021, Available at:https://www.fda.gov/radiation-emitting-products/medical-imaging/ultrasound-imaging\\n[6]History.com (2020). “German\\nScientist Discovers X-rays, A&E\\nTelevision Networks ”Accessed\\n2021-09-18, Available at: https://www.\\nhistory.com/this-day-in-history/german-scientist-discovers-x-rays\\n[7]U.S. Food & Drug\\nAdministration 2019, ComputedTomography (CT), FDA, Accessed\\n2021-09-18. Available at: https://www.fda.\\ngov/radiation-emitting-products/medical-x-ray-imaging/computed-tomography-ct\\n[8]NPS MedicineWise (2019). “Imaging\\nExplained ”, Accessed 2021-09-18\\nAvailable at: https://www.nps.org.au/consumers/imaging-explained\\n[9]Healthdirect (2019). “PET Scan ”,\\nAccessed 2021-09-20, available only at:https://www.healthdirect.gov.au/pet-scan\\n[10]Jürgen W, Lorenz C. Four\\nchallenges in medical image analysisfrom an industrial perspective. EditorialMed Image Anal. 2016; 33:44-49. DOI:\\n10.1016/j.media.2016.06.023\\n[11]Wiggins Walter (2021). “Top\\nChallenges of Applying ArtificialIntelligence to Medical Imaging ”.\\nAccessed 2021-09-19, Available at:https://healthitanalytics.com/features/top-challenges-of-applying-artificial-intelligence-to-medical-imagin\\n[12]Mohammed M, Khan MB, Bashier\\nMohammed BE. Machine learning:algorithms and applications. CRC Press.2016; 2016\\n[13]Iqbal H. Sarker (2021), “Machine\\nLearning: Algorithms, Real-WorldApplications and Research ”Springer\\nNature Singapore Pte Ltd Computer\\nScience. https://doi.org/10.1007/\\ns42979-021-00592-x SN Computer\\n[14]Stuart R.J, and Peter N. (2010).\\nArtificial Intelligence: A ModernApproach (Third ed.). Prentice Hall.ISBN 9780136042594.\\n[15]Mehryar M, Afshin R, and Ameet T.\\n(2012). “Foundations of Machine\\nLearning ”. The MIT Press. ISBN\\n9780262018258.\\n[16]Han J, Pei J, Kamber M. Data\\nmining: concepts and techniques.\\nAmsterdam: Elsevier; 2011. p. 2011\\n[17]Jordan M. I, and Christopher B. M.\\n(2004). “Neural Networks ”. In Allen B.\\nTucker (ed.). Computer Science\\nHandbook, Second Edition (Section VII:Intelligent Systems). Boca Raton,Florida: Chapman & Hall/CRCPress LLC. ISBN 978-1-58488-360-9.\\n76Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='168df5a6-b822-4714-b5e8-e2572a0efbf0', embedding=None, metadata={'page_label': '77', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='[18]Sarker IH, Kayes ASM, Badsha S,\\nAlqahtani H, Watters P, Ng A. (2020).\\n“Cybersecurity data science: an\\noverview from machine learningperspective ”. J Big Data. 2020; 7(1):1-29\\n[19]Vaishya, R, Javaid M, Khan,\\nIbrahim H. Haleem A. (2020).“Artificial Intelligence (AI) applications\\nfor COVID-19 pandemic ”. Diabetes &\\nMetabolic Syndrome: Clinical Research& Reviews. 14 (4): 337-339. DOI:10.1016/j.dsx.2020.04.012. PMC7195043. PMID 32305024.\\n[20]Hamed R, Arash A, Haywantee R.\\n“Application of machine learning to\\npredict visitors ’green behavior in\\nmarine protected areas: evidence fromCyprus ”. Journal of Sustainable\\nTourism. 125. 2021. DOI: 10.1080/09669582.2021.1887878\\n[21]Rhiannon W. (2020). “Future\\nsmartphones ‘will prolong their own\\nbattery life by monitoring owners ’\\nbehaviour ’”. i (newspaper) [Accessed:\\n2021-06-17]\\n[22]KDnuggets: Mayo M. (2021). “Top\\nData Science, Machine Learning\\nMethods Used in2018/2019 ”. Available\\nfrom: https://www.kdnuggets.com/\\n2019/04/top-data-science-machine-learning-methods-2018-2019.html[Accessed: 2021-07-08]\\n[23]Ame W. Deep learning vs. machine\\nlearning –What ’s the difference?\\nAccessed. 2021;(2021-09-18) Available:https://levity.ai/blog/difference-machine-learning-deep-learning\\n[24]Dickson B. (2020). “What is\\nensemble learning? ”Available from:\\nhttps://bdtechtalks.com/2020/11/12/what-is-ensemble-learning/ [Accessed:\\n2021-07-08]\\n[25]Deepa J, Singh Thipendra P. A\\nsurvey of fracture detection techniques\\nin bone X-ray images. ResearchGatepublication on Artificial IntelligenceReview. 2020; 53:4475-4517 https://doi.\\norg/10.1007/s10462-019-09799-\\n[26]Cha D, Pae C, Seong S-B, Choi JY,\\nPark H-J. Automated diagnosis of eardisease using ensemble deep learningwith a big otoendoscopy image\\ndatabase. eBioMedicine. 2019; 2019 (45):\\n606-614\\n[27]Ryoya Shiode, Mototaka Kabashima,\\nYuta Hiasa, Kunihiro Oka, Tsuyoshi\\nMurase, Yoshinobu Sato, Yoshito Otake(2021). “2D-3D reconstruction of distal\\nforearm bone from actual X-ray images\\nof the wrist using convolutional neural\\nnetworks ”. Sci Rep. 2021 Jul 27;11(1):\\n15249. DOI: 10.1038/s41598-021-94634-2.\\n[28]IBM Cloud Education (2020).\\n“Convolutional Neural Networks ”\\nhttps://www.ibm.com/cloud/learn/\\nconvolutional-neural-networks\\n[29]Fengping A, Xiaowei L. and\\nXingmin M. (2021). “Medical Image\\nClassification Algorithm Based on\\nVisual Attention Mechanism ”, Hindawi\\nOxidative Medicine and CellularLongevity Volume 2021, Article ID\\n6280690, 12 pages https://doi.org/\\n10.1155/2021/6280690\\n[30]Sah (2021). “Machine Learning: A\\nReview of Learning Types ”,\\npreprints202007.0230.v1.pdf doi:10.20944/preprints202007. 0230.v\\n[31]Puttagunta M, Ravi S. Medical\\nimage analysis based on deep learningapproach. Springer Nature MultimediaTools and Applications. 2021. DOI:https://doi.org/10.1007/s11042-021-10707-4\\n[32]Battineni, Getu Gamo Sagaro B,\\nNalini Chinatalapudi and FrancescoAmenta (2020). “Applications of\\nMachine Learning Predictive Models inthe Chronic Disease Diagnosis ”Gopi\\nJournal of Personalized MedicineReview.\\n77Ensemble Machine Learning Algorithms for Prediction and Classification of Medical Images\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.1 00602', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c69f9bc3-26a3-4dc1-acdf-cb7aa4745f57', embedding=None, metadata={'page_label': '78', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='[33]Kandel I, Castelli M, Popovi č, A.\\nComparing Stacking Ensemble\\nTechniques to Improve MusculoskeletalFracture Image Classification. J.Imaging. 2021; 2021 (7):100 https://doi.\\norg/10.3390/jimaging7060100\\n[34]Uysal F, Hardalaç F, Peker O,\\nTolunay T, Tokgöz N. Classification ofShoulder X-ray Images with DeepLearning Ensemble Models. AppliedSciences. 2021; 2021 (11):2723\\n[35]Kitamura G, Chung CY, Moore BE.\\n“Ankle Fracture Detection Utilizing a\\nConvolutional Neural NetworkEnsemble Implemented with a SmallSample ”, De Novo Training, and\\nMultiview Incorporation. Journal ofDigital Imaging. 2019; 2019 (32):672-677\\n[36]Muhammad Ayaz,1 Furqan\\nShaukat,2 and Gulistan Raja (2021).\\n“Ensemble learning based automatic\\ndetection of tuberculosis in chest X-ray\\nimages using hybrid featuredescriptors ”. Phys Eng Sci Med. 2021\\nJan 18: 1-12. DOI: 10.1007/s13246-020-00966-0\\n[37]Rajaraman Sivaramakrishnan,\\nSiegelman Jenifer, Philip O. Alderson,Lucas S. Folio, Les R. Folio, AndSameer K. Antani (2020). “Iteratively\\nPruned Deep Learning Ensembles forCOVID-19 Detection in Chest X-Rays ”\\n(Senior Member, IEEE) ReceivedMay 13, 2020, Digital ObjectIdentifier 10.1109/ACCESS.2020.\\n300381. IEEE Access.\\n[38]Pedamkar P (2020). “Ensemble\\nMethods in Machine Learning ”\\nAvailable from: https://www.educba.\\ncom/ensemble-methods-in-machine-learning/ [Accessed: 2021-07-10]\\n[39]Pandey P.K, Yaduvir S., Sweta T.\\n(2011). “Image Processing Using\\nPrincipal Component Analysis ”\\nInternational Journal of ComputerApplication 15(4). DOI: 10.5120/1935-2582[40]Brownlee J. (2016). “Logistic\\nRegression for Machine Learning ”\\nAvailable from: https://machinelearningmastery.com/logistic-regression-for-machine-learning/ [Accessed:2021-07-11]\\n[41]Nicholson C. (2021). “Decision\\nTree ”Available from: https://wiki.path\\nmind.com/decision-tree [Accessed:2021-07-11]\\n[42]Gill N. S. (2021). “Artificial Neural\\nNetworks Applications and Algorithms ”\\nAvailable from https://www.xenonstack.\\ncom/blog/artificial-neural-network-\\napplications [Accessed: 2021-07-11]\\n78Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='20e1b6a9-0468-4cc5-b034-68691be5c4dd', embedding=None, metadata={'page_label': '79', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 5\\nDelivering Precision Medicine\\nto Patients with Spinal Cord\\nDisorders; Insights into\\nApplications of Bioinformatics and\\nMachine Learning from Studies of\\nDegenerative Cervical Myelopathy\\nKalum J. Ost, David W. Anderson and David W. Cadotte\\nAbstract\\nWith the common adoption of electronic health records and new technologies\\ncapable of producing an unprecedented scale of data, a shift must occur in how we\\npractice medicine in order to utilize these resources. We are entering an era inwhich the capacity of even the most clever human doctor simply is insufficient. Assuch, realizing “personalized ”or“precision ”medicine requires new methods that\\ncan leverage the massive amounts of data now available. Machine learning tech-niques provide one important toolkit in this venture, as they are fundamentallydesigned to deal with (and, in fact, benefit from) massive datasets. The clinicalapplications for such machine learning systems are still in their infancy, however,and the field of medicine presents a unique set of design considerations. In thischapter, we will walk through how we selected and adjusted the “Progressive\\nLearning framework ”to account for these considerations in the case of Degenera-\\ntive Cervical Myeolopathy. We additionally compare a model designed with these\\ntechniques to similar static models run in “perfect world ”scenarios (free of the\\nclinical issues address), and we use simulated clinical data acquisition scenarios to\\ndemonstrate the advantages of our machine learning approach in providingpersonalized diagnoses.\\nKeywords: Precision Medicine, Personalized Medicine, Neural Networks,\\nDegenerative Cervical Myelopathy, Spinal Cord Injury, Continual Learning,\\nBioinformatics\\n1. Introduction\\nThe classical practice of medical is undergoing a transition as new scales of data\\nproduction become increasingly common. This transition presents the field with\\nmajor analytical challenges that necessitate new and creative ways of engaging. The\\nuse of machine learning is one of the most important developments supporting this\\n79', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='8eb166d7-384c-4439-ad7e-4909cce8cf46', embedding=None, metadata={'page_label': '80', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='transition, as its methods are ideally suited (and in fact benefit from) the massive\\nscale of data collection that is increasingly becoming the norm. With the rapid\\ngrowth in high-throughput technologies for genetics, proteomics, and other biolog-\\nical metrics, alongside the recent wide-spread adaptation of electronic healthrecords [1, 2], more data than ever has become available to feed into a machinelearning system. The classical practice of medicine is typified by giants such as Dr.William Osler [3] whose diagnostic acumen improved the lives of many. In the verynear future (and, in many cases, the present), physicians and diagnosticians willwork with more data than they could possibly interpret. Machine learning is one ofmany tools which will help alleviate this, helping to guide many diagnostic and\\ntherapeutic decisions made by the clinical team, and if implemented well, should\\nsupport patients ’overall health. This potential realization of “precision medicine ”is\\nbased on the belief that each patient has unique characteristics which should beaccounted for when treating them [4].\\nWhile precision medicine has already demonstrated major benefits in fields like\\npharmacology [5] and oncology [6 –8], a number of potential applications remain in\\nother medical fields. In this chapter, we will demonstrate this using spinal corddisease, specifically by examining its application to Degenerative Cervical Myelop-\\nathy (DCM). DCM is a condition when the bones and joints of the human neck\\n(cervical spine) degenerate with age, causing a slow progressive ‘squeeze ’of the\\nspinal cord. This progressive condition has a significant effect on patient quality oflife. Symptoms include pain, numbness, dexterity loss, gait imbalance, and sphinc-ter dysfunction [9, 10], with symptoms often not appearing until permanent dam-age has already occurred [11]. MRI scans are typically used as part of the diagnosticprocess, and demographic factors have also been shown to be effective in predictingDCM severity [12]. An additional challenge is that patients can exhibit the hall-\\nmarks of DCM without developing symptoms [13], suggesting that a wide range of\\nfactors may be contributing to the illness ’s severity. Despite all of this, research into\\nprecision medical approaches and diagnostics have been sorely lacking; to the bestof our knowledge, only 4 published studies involving DCM (also referred to asCervical Spondylotic Myelopathy) exist which utilize machine learning [7, 14 –16],\\ncoming from only three different groups (including our own), and with only oneutilizing MRI data [16].\\nIn this chapter, we will discuss how we went about designing a machine learning\\nprocess, focusing on considerations required for clinical data specifically. We firstexplore how data should be managed and stored, before moving into data prepara-tion procedures. Finally, we move onto the design considerations for the machinelearning model. We will focus on models made for diagnostic prediction, ratherthan outcome prediction; however, we intend this only as a first step in usingmachine learning to support patient care, with future work moving toward modelsthat provide personalized therapeutic recommendations as well. Throughout thischapter we will apply the techniques being discussed to DCM to help contextualize\\nthem. Some preliminary results for the final resulting system will also be shown, as\\na‘proof-of-concept ’, using the CIFAR-10 dataset modified to replicate clinical cir-\\ncumstances. We hope that this will provide a road-map for future machine learningdriven precision medicine projects to follow.\\n2. Precision medicine machine learning system design\\nWe have previously published work using spinal cord metrics generated by the\\nSpinal Cord Toolbox [17] alongside simple linear and logistic regression models[16]. While it found moderate success, our results suggested that complex aspects of\\n80Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='32edb690-6699-4dae-a6fa-9050d70d0c4e', embedding=None, metadata={'page_label': '81', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='the spinal cord morphology are likely the key to an accurate model, with simple\\nregression analyses alone appearing to be insufficient. Said study also only used\\nMRI-derived metrics, resulting in our model being unable to use non-imaging\\nattributes to support its diagnostic conclusions, something which has been shown toaid model accuracy in other studies [18]. Finally, our prior models were static innature, and thus had to be rebuilt each time new data became available. While thismay be tractable for simple models (which can be rebuilt very quickly), morecomplex models require more computational investment, and as such wouldbecome far too difficult to manage as the dataset grows. As an additional concern,there is reason to believe that the trends in our collected metrics are likely to change\\nover time as societal, behavioral, and environmental changes occur, influencing\\nDCM epidemiology [19], resulting in prior trends becoming obsolete or less signif-icant. As such, an ideal model would be able to adapt to these changes as they arise,without the need of manual correction.\\n2.1 Data management\\nAs previously mentioned, a key consideration in the clinical use of machine\\nlearning is that clinical data does not remain fixed. As new patients arrive and have\\ntheir data collected and current patients see their disease state change, the relevantdata that can be leveraged will change and expand over time. One possible approachis to retrain our machine learning model from scratch each time we update ourdataset; this would become incredibly time and resource consuming as the datasetgrows, however. Thankfully, advancements in continual learning in the last 5 years\\nprovide an elegant solution [20] (which we discuss in Section 3). To use thesetechniques effectively, we will need to consider the best way of optimizing howdata is collected, stored, accessed, processed, and reported. Ideally, these datamanagement systems should be malleable, extendable, and easy to use, so they mayremain useful long-term in a ever-changing clinical environment. This section willfocus on detailing methodologies for achieving this, accounting for the challengespresented by ongoing clinical data collection in the process.\\n2.1.1 Acquisition and storage\\nIdeally, our clinical dataset would include any and all relevant features that can\\nbe reliably and cost-effectively obtained. In reality, the specific data elements (or\\n“features ”) will vary both across patients and over time (as new diagnostic tests\\ncome available or as ethical rules/constraints are updated). As such, an ideal data\\nmanagement approach should be capable of adapting to variable data feature col-\\nlection over time, while still allowing new patients to be included. For ethicalreasons, the storage system also needs to be set up so that data can be easilyremoved, should patients request their data be purged or if privacy rules require it.\\nIn our facility, we addressed these considerations by creating a non-relational\\ndocument database system using MongoDB. This allows for new features to beadded and removed on-the-fly via a modular framework of ‘forms ’, which specify\\nsets of related features that should exist inside a single document ‘type ’. These\\ndocuments can then be stored within a larger super-document (which we will referto as a ‘record ’) for each specific patient. This results in a large dataset containing all\\nrelevant features organized in an individual-specific manner. Each form acts as a‘schema ’, specifying what features can be expected to exist within each patient ’s\\nrecord. With MongoDB, this allows features to be added and removed as neededwithout restructuring the entire database [21], which would risk data loss. If newfeatures are desired, one can simply write a new form containing said features and\\n81Delivering Precision Medicine to Patients with Spinal Cord Disorders; Insights …\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 8713', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='b4804f4c-f50d-4f44-93e1-937ae85d913c', embedding=None, metadata={'page_label': '82', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='add it to the system; previous entries without these new features can then be treated\\nas containing “null”values in their place, thereby enabling them to still be included\\nin any analyses performed on the data. Should features need to be removed, theform containing them can either be revised or deleted entirely. This results in thefeatures effectively being masked from analysis access without deleting them fromthe database itself, allowing for their recovery in the future.\\nOur system also has the added benefit of allowing for the creation of ‘output ’\\nforms, which capture and store metrics generated from data analyses. This enablesthe same system that collects the data to also report these analytical results back tothe original submitter via the same interface. These output forms can also be stored\\nalongside forms containing the original values that were provided to the analysis,\\nmaking both easily accessible when calculating error/loss.\\nIn our DCM dataset, all features (including MRI sequences) were collected at the\\ntime of diagnosis and consent to participate in our longitudinal registry associatedwith the Canadian Spine Outcomes and Research Network [22]. This registry col-lects hundreds of metrics on each patient, including a number of common diagnos-tic tests, with each being stored in the database as a single form. Most notably, thisincludes the modified Japanese Orthopedic Association (mJOA) scale form [23].\\nThis is important for our study as we used this diagnostic assessment of DCM\\nseverity as the target metric for model training purposes. The MRI sequence form(which contains our MRI sequences alongside metadata associated with how theywere obtained) and demographic information about the patient (including metricssuch as name, age, and sex, among others) are also represented by one form eachwithin our system. A simplified visualization of this structure can be seen inFigure 1 .\\nThis system can also allow pre-built structures to be re-created within it. For\\nexample, our MRI data is currently stored using the Brain Imaging Data Structure(BIDS) format [24]. This standardized data structure has directory hierarchiesaccording to the contents of the file, with metadata describing the contents of thedirectory “falling through ”to sub-directories and documents nested within it.\\nThese nested directories can then contain new metadata which overrides some or allof the previously set values, allowing for more granular metadata specification.Such a structure is conducive to our system, with said “nested ”directories acting as\\nfeatures within forms, or forms within records; features could even consist of sets of\\nsub-features (such as our MRI feature, which contains the MRI image andits\\nassociated metadata bundled together). Such nested structure can then specify\\n“override ”values, as they become needed.\\n2.2 Cleaning and preparation\\nThe raw data collected in a clinical setting is almost never “analysis ready ”, as\\nfactors like human error and/or missing data fields must be contended with. Strat-egies for “cleaning ”data can vary from dataset to dataset, but for precision medi-\\ncine models there are some common standards. First, such protocols should workon a per-record basis, not a full-data basis. This is to avoid the circumstance whereadding entries with extreme values would skew the dataset ’s distribution,\\ncompromising the model ’s prior training (as the input metrics are, in effect, re-\\nscaled), resulting in an unrealistic drop in model accuracy. Per-record internalnormalization, however, typically works well, so long as it remains consistent overthe period of the model ’s use. Some exceptions to this exist; for example, exclusion\\nmethods may need to be aware of the entire dataset to identify erroneous records.Likewise, imputation methods will need to “tap into ”other available data to fill in\\nmissing or incorrect data points within each record.\\n82Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c4cb75bc-bc44-4d39-b5c5-0653e7aa3fa4', embedding=None, metadata={'page_label': '83', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='It is often the case that data is obtained from multiple different sources (e.g.\\ndifferent clinics, practitioners, hospitals, labs, databases, etc.), which may have\\nvarying protocols and/or environmental differences that can structurally influencethe resulting measurements. If the model could be retrained from scratch everytime new data was obtained, these batch effects could be easily removed [25]. Initeratively trained systems, however, this would result in the same issue as full-data\\nnormalization; new entries causing fall-through changes in the entire dataset.\\nHowever, under the assumption that batch effects have less influence on the datathan ‘true ’contributing effects, it has been shown that systems which learn itera-\\ntively can integrate batch effect compensation directly into their training for bothnumeric [26] and imaging [27] metrics, thereby resolving the issue.\\nComing back to our DCM example, our data consists of demographic informa-\\ntion (which included a mix of numerical and categorical data), diagnostic data (alsonumerical and categorical), and 3-dimensional MRI sequences data (which also\\ncontains meta-data describing its acquisition method). For numerical and categori-\\ncal data, our processing procedures are minimal, consisting of a quick manualreview to confirm that all required features were present. As our dataset wasrelatively large, we opted to simply drop entries which contained malformed ormissing data. New patient entries with errors were either met with a request to thesupplier for corrected data, or had true values imputed for prediction purposes [28].Categorical data is then one-hot encoded, while numerical data is scaled between 0and 1 for values with know minimums and maximums. We had access to multiple\\ndifferent MRI sequencing methodologies as well, but focus on T2w sagittal oriented\\nsequences based on our prior tests with the data [16]. MRI sequences are then\\nresampled to a voxel size of 1 mm\\n3and the signal values normalized to a 0 to 1 range.\\nFigure 1.\\nA simplified example of how data is stored and managed in our theoretical system. Each feature tracked is firstbundled into a ‘model ’, which groups related features together alongside a descriptive label. These models act as\\na schema for any data analysis procedures to hook into, and can be modified, removed, and created as needed.\\nModel instances are then stored in ‘records ’, which represent one entry for any analysis system which requires it\\n(in our case, that of one patient enrolled in our DCM study). A data structure like this can be easily achieved\\nwith any non-relational database system; in our case, we opted to use MongoDB.\\n83Delivering Precision Medicine to Patients with Spinal Cord Disorders; Insights …\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 8713', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='afdb609c-7c4e-46bc-826b-a68092aa6626', embedding=None, metadata={'page_label': '84', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Unlike our numerical results, this was done based on per-image signal minimum\\nand maximum, in an attempt to account for variations in signal intensity variation,\\naiding in batch effect removal in the process.\\n3. Machine learning model design\\nLike the data management system, machine learning models designed for preci-\\nsion medicine need to be able to accept new data on an ongoing basis. The data\\ncontents may change over time as new discoveries about the illness are made,though it can be safely assumed that new data will be related to old data in someway. Contents of new data cannot be expected to be well distributed across target alltarget metrics. All of these requirements make precision medicinal systems a perfectuse-case for continual learning systems.\\nContinual learning systems are characterized by their iterative training, as well\\nas the ability to ‘recall ’what they learn from prior tasks to help solve new ones. Each\\nof these tasks are assumed to be related, but contain non-trivial variation. Thismeans the model must be flexible to change, while avoiding completelyreconstructing itself after each new task, which could result in it ‘forgetting ’useful\\nprior learning. These capabilities are referred to, respectively, as forward transfer(the ability to leverage prior learning to improve future analyses) and backwardtransfer (the ability leverage new knowledge to help with prior tasks).\\nPromising progress has been made in designing continual learning systems [20],\\nto the point of a preliminary frameworks being devised to develop them. For this\\nchapter, we will be using Fayek et. al ’sProgressive Learning framework [29] as a\\nbaseline reference, though some changes were made to account for precision med-\\nicine applications.\\n3.1 Initial network structure\\nAll networks need to start somewhere, which for all intents and purposes acts\\nlike a classical static machine learning system. Neural networks are the system of\\nchoice for these processes, as they allow for multiple data types to be analyzedsimultaneously, being able to be constructed in a modular fashion to match up withour data storage structure detailed prior. Depending on the data, what this entailswill differ. For data with implicit relations between features (such as MRI imageswith their spatial relations), Convolutional Neural Network (CNN) systems havebeen shown to be extremely effective [30]. CNNs are also among the most compu-\\ntational efficient neural networks to train and run [31, 32], making them ideal for\\nlow resource systems. For other data, a Densely Connected Learning Networks(DCLNs) may be more appropriate. The complexity of these networks can be tunedto fit the problem. These models tend to be over-parameterized, however, poten-tially causing them to “stick ”in one place or over-fit to training data; this is\\nmediated somewhat via model pruning, discussed later in this section. The choice ofavailable models is ever-changing, however, so one should find the model structurewhich best fits their specific case.\\nFor progressively learning models, one further constraint exists; it must be able\\nto be cleanly divide its layers into ‘blocks ’. As discussed in Fayek et. al ’s framework\\n[29], this is necessary to allow for the model to progress over time. How theseblocks are formed can be arbitrary, so long as each block is capable of beinggeneralized to accept data containing the same features, but of different shape (asthe size of the input data grows resulting from the concatenation operationdiscussed later in this section). One should also keep in mind that the block\\n84Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='82141d36-a62b-406e-a8c0-47b5d8ac6aa9', embedding=None, metadata={'page_label': '85', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='containing the output layer will be reset every progressive iteration, and should be\\nkept as lightweight as possible.\\nFor DCM, this would be accomplished via multiple layers running in parallel. For\\nMRI inputs, being 3D spatial sequences, something like a 3D DenseNet similar to thatemployed by Ke et al. [33] could be used. The DenseNet could be run alongsideDCLN blocks in parallel to read and interpret our linear data (demographics, forexample), grouped with the DenseNet blocks to form the initial progressive learningmodel. A diagram of this structure, using the same structure mentioned prior(Figure 1 ), with a simplified “MRI ”model present, is shown in Figure 2 .\\nFor the purposes of comparison with the original Progressive Learning frame-\\nwork, however, our testing system will instead use their initial model structure [29].\\n3.2 Iterative training data considerations\\nOnce this initial framework is in place, it then needs to prove capable of\\naccepting new patient data, updating itself as it does so. Given that the measure-\\nments of patients enrolling in clinical illness studies can be sporadic in terms of\\nwhen and how often they are made, data for this system will need to be collectedover time until a sufficiently large ‘batch ’of new records is acquired. Ideally large\\nFigure 2.\\nAn example of the initial neural network structure for use in precision medicinal systems. Note that each formreceives its own “branch” block (presented within the model block column) which is used to interpret the form ’s\\ncontents. As a result, each branch’ s structure can be tailored to suit the form’ s contents, allowing for modular\\naddition or removal of model ’s feeding into the network ’s design as needed. The results of each of these branches’\\ninterpretations are then submitted to a set of “merging ”blocks, which attempts to combine these results together\\nin a sensible manner, before a final “output ”layer reports the model ’s predictions for the input. The output layer\\nis also modular, allowing for extension and/or revision as desired.\\n85Delivering Precision Medicine to Patients with Spinal Cord Disorders; Insights …\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 8713', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='636c0195-073c-46eb-a6f4-036b01d561d7', embedding=None, metadata={'page_label': '86', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='batches would be collected which are sizable enough to be split into multiple smaller\\nbatches, allowing for curriculum formation as detailed in the subsequent section. In\\nmany cases this is simply not feasible due to the time required to obtain such large\\nbatches. In this circumstance, each batch acts as a single ‘curriculum ’provided to\\nour network in effectively random order. Thankfully, the curriculum stage appearsto be the least significant stage of the Progressive Learning framework [29]. Thesize of these batches will depend heavily on how much data one expects to be able tocollect in a given period of time and how regularly one wishes to update the model.For categorical data, each batch should include at least two of every category (onefor testing, one for validation), which may influence how many samples one needs\\nto acquire. We recommend a slightly larger batch sizes when linear data is brought\\ninto the fold, to account for the increased variety. With our DCM dataset, with acategorical output metric (the mJOA-derived DCM severity class, consisting of 4classes), a batch of 20 patient records was selected. Data augmentation of this new\\ndata can also be utilized to increase the number of effective records being submit-ted. However, one should avoid using data from records in previous training cycles,as it can lead to a the model failing to adopt novel data trends in newer results.\\n3.3 Continual learning\\nHere, we will focus on detailing a framework based on Fayek et. al ’s Progressive\\nLearning Framework [29], which consistes of three stages; curriculum ,progression\\nandpruning .\\n3.3.1 Curriculum\\nGiven sufficiently large batches of new data can be collected in a timely manner,\\none can utilize the curriculum stage; at least three times the number of records per\\nbatch being collected in a 6 month period seems to be a good cutoff for this, thoughthis can differ depending how rapidly one expects disease trends to change. This\\nstage, as described in Fayek et. al ’s framework [29], is composed of two steps;\\ncurricula creation and task ordering. In the creation step, the batch is split into sub-\\nbatches, with each being known as a ‘curriculum ’. How this is done depends on the\\ndata at hand (i.e. categorical data requires that each curriculum contains data fromeach category), but can otherwise be performed arbitrarily. Once these curricula areformed they are sorted based on an estimate of how “difficult ”they are, from least\\nto most. Difficulty estimation can be as simple as running a regression on the dataand using the resulting loss metric. The sorted set of curricula are then submitted to\\nthe network for the progression and pruning stages, one at a time. This allows for\\nthe network to learn incrementally, picking up the “easier ”trends from earlier\\ncurricula before being tasked with learning more “difficult ”trends in later ones.\\nIn precision medicine, however, collecting sufficient data in a useful time span is\\noften not possible. In this case, this stage can be safely skipped; the smaller batches willsimply act as randomly sampled, unordered curricula. How “large ”this is depends on\\nthe batch size selected earlier; one should collect at least three batches worth towarrant the additional complexity of the curriculum stage. For our DCM setup, we fell\\nbelow this level, as we intend on updating as often as possible, and as such intended on\\nutilizing new batches as soon as they were collected. We believe that in most precisionmedicine examples this is likely to be the case, though in some situations (such as theongoing COVID-19 pandemic), the scale of patient data collection may make thecurriculum stage worth considering. Employing few-shot learning techniques may alsoallow for smaller subsets of data to form multiple batches as well, though the efficacyof such procedures has yet to be tested in this context.\\n86Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='8e66b1e4-649f-4a08-b3f5-332d791dcf11', embedding=None, metadata={'page_label': '87', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.3.2 Progression\\nIn this stage, new blocks of layers are generated and concatenated to previously\\ngenerated blocks in the model. The new input-accepting block is simply stacked\\nadjacent to the prior input blocks in the model, ready to receive input from recordsin our dataset. Each subsequent new block, however, receives the concatenatedoutputs of allblocks from the prior layer, allowing it to include features learned in\\nprevious training cycles. The final block, which contains the output layer, is thenregenerated entirely, resulting in some lost training progress that is, thankfully,\\nusually quickly resolved as the model begins re-training.\\nThe contents of these added blocks depends on the desired task and computa-\\ntional resources available. Large, more complex blocks require more computational\\nresources and are more likely to result in over-fitting, but can enable rapid adaptionof the network and better forward transfer. In the original framework [29], theseblocks were simply copies of the original block ’s architecture, but reduced to\\napproximately half the parameters. However, one could instead cycle through a setof varying block-types, based on how well the model performed and whether new\\ndata trends are expected to have appeared. They could also be changed as the model\\nevolves and new effective model designs are discovered, though how effective thisis in practice has yet to be seen.\\nOnce these blocks are added, the network is then retrained on the new batch of\\ndata, generally with the same training setup used for the original set of blocks. Duringthis retraining, prior block ’s parameters can be frozen, locking in what they had\\nlearned prior while still allowing them to contribute to the model ’s overall prediction.\\nThis prevents catastrophic forgetting of previously learned tasks, should they need to\\nbe recalled, though this usually comes at the cost of reduced overall training effec-\\ntiveness. However, if one does not expect to need to re-evaluate records which havealready been tested before, one can deviate from Fayek ’s original design and instead\\nallow prior blocks to change along with the rest of the model. An example of pro-gression (with two simple DCLN blocks being added) is shown in Figure 3 .\\nFor our DCM data, this is a pretty straightforward decision. New blocks would\\nsimply consist of new 3D DenseNet blocks run in parallel to simple DCLN layers,both containing approximately half the parameters as the original block set. The\\noutput block is then simply a linear layer which is fed into a SoftMax function for\\nfinal categorical prediction. As we do not expect prior records to need to bere-tested, we also allow prior blocks to be updated during each training cycle.\\n3.3.3 Pruning\\nIn this stage, a portion of parameters in the new blocks are dropped from the\\nnetwork. What parts of the model are allowed to be pruned depends on how the\\nprior progression stage was accomplished; if previously trained blocks have beenfrozen, then only newly added elements should be allowed to be pruned to avoidcatastrophic loss of prior training. Otherwise, the entire model can be pruned, justas it has been allowed to be trained and updated. The pruning system can also varyin how it determines which parameters are to be pruned, though dropping param-\\neters with the lowest absolute value weights is the most straightforward. These can\\nalso be grouped as well, with Fayek et al. choosing to prune greedily layer-by-layer.However, we have found that considering all parameters at once is also effective.The proportion qdropped per cycle will depend on the computational resources and\\ntime available. Smaller increments will take longer to run, whereas larger values willtend to land further away from the “optimal ”state of the network. An example of\\nthe pruning stage is shown in Figure 4 .\\n87Delivering Precision Medicine to Patients with Spinal Cord Disorders; Insights …\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 8713', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='226656c3-2389-4aab-862e-dbdf50ef8a19', embedding=None, metadata={'page_label': '88', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The network, now lacking the pruned parameters, is then retrained for a (much\\nshorter) duration to account for their loss. In Fayek et al ’s example, this process is\\nthen repeated with progressively larger qproportions until a loss in performance is\\nobserved. Alternatively, one can instead repeatedly drop the same percentile of\\nparameters each cycle from the previously pruned network. This has the benefit of\\nreducing the time taken per cycle slightly (the same weights do not need to bepruned every cycle), while also leading to the total proportion of the pruned modelincreasing more gradually per cycle, improving the odds that the model lands closerto the true optimal size for the system. This pruning system has the potential to be\\nmuch slower, however (should the rare circumstance occur where all the new\\nparameters are useless, requiring more iterations overall). As such, in time-limitedsystems, Fayek ’s approach remains more effective.\\nThis stage also allows for, in theory, dynamic feature removal. Should a model (or\\nfeature within said model) cease to be available, one can simply explicitly prune theparameters associated with that feature, in effect performing a targeted pruningcycle. One would need to re-enable training of previously trained nodes to account\\nFigure 3.\\nAn example of the progression stage, building off of the initial model shown in Figure 2. New nodes are\\ncontained within the gray boxes, with hashed lines indicating the new connections formed as a result. Note thatinput connections are specific to each form, only connecting to one’ s inputs (in this case, only the Demographic ’s\\ninput), and not to those in the other branches (such as the MRI branch); this allows for shortcomings inparticular model ’s contributions to be accounting for independently, without an extreme growth in network\\ncomplexity. Note as well that the merging layer (representing all non-input receiving blocks) forms connectionswith all prior block outputs, however, regardless of which forms have received a new connected block. The entireoutput block is also regenerated at this stage, providing some learning plasticity at the expense of initial learning.\\n88Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='83866823-91aa-41d3-9751-a6776305c4a2', embedding=None, metadata={'page_label': '89', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='for this, however, leading to the possibility of reduced backward transfer. Depending\\non how significant the to-be-removed features have become in the network, this mayneed to be done over multiple pruning cycles; this should allow the network to adaptto changes over time, reducing the risk of it getting ‘stuck ’in a sub-optimal state.\\nFor our DCM data, the complexity of the illness and scope of the data makes it\\nextremely unlikely for a worst-case pruning issue to occur. As such, a 10% lowestabsolute weight pruning system, applied globally, is selected as our starting point,iteratively applied until a loss of mean accuracy over 10 post-prune correctionepochs is observed.\\n4. Protocol assessment\\n4.1 Progressive learning ConvNet\\n4.1.1 Methodology\\nTo confirm our protocol functions effectively in practice, we replicated the\\nCIFAR-100 analysis used in the original Progressive Learning paper [29], with a few\\nmajor changes to replicate a precision medicine environment (i.e. the kind of\\nFigure 4.\\nAn example of the pruning stage, building off of the progression network shown in Figure 3. Note that only\\nnewly formed connections are targeted for pruning by default, with pre-existing connections remaining safe.Parameters themselves can also be effectively lost entirely (shown as nodes with no fill and a dashed outline)should all connections leading into them get removed. This results in all connections leading out of them alsogetting pruned by proxy.\\n89Delivering Precision Medicine to Patients with Spinal Cord Disorders; Insights …\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 8713', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='99eb1539-2204-4cf4-abf2-6cfb3e628a8d', embedding=None, metadata={'page_label': '90', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='clinical context in which data is typically collected). First, only the CIFAR-10\\ndataset was used [34], rather than it being used as the model initialization dataset.\\nThis was done to better reflect the clinical environment, where we are unlikely to\\nhave a pre-established dataset which is known to be effective at preparing ourmodel for the task. The 10 categories of the CIFAR-10 dataset also represent theaverage granularity usually used to assess many illnesses. Second, our datasets wererandomly split into 10 subsets of 6000 random images, with 5000 used for trainingand the remaining 1000 used for validation. The contents of these subsets wascompletely random, allowing for imbalance in the number of elements from each ofthe 10 categories, reflecting how data collected in a clinical setting could occur.\\nThird, we skipped the curriculum stage, again to reflect the circumstances of clini-\\ncal data collection (wherein the scale of collection is insufficient). Fourth, ourframework was implemented in PyTorch [35] rather than TensorFlow [36] due toits more robust network pruning support. Finally, data augmentation wasperformed on each image to both discourage the model from memorizing data andto simulate human error/variation in clinically acquired data. This results in aproblem which is slightly more difficult than the original setup devised by Fayeket al., though for parity sake, we continued to use the same Convolution Network\\ndesign.\\nWe tested 6 procedures, representing combinations of two different variations.\\nThe first variation was whether the learning model trained as an independent\\nlearning model, a progressive learning model with prior blocks frozen, or a pro-gressive learning model with prior blocks being freely pruned and updated. Forindependent learning procedures, the model was completely reset after each train-ing cycle, whereas for progressive learning procedures the model persisted acrosscycles (allowing for it to “apply ”prior knowledge to new data). The second was\\nwhether data was provided in batches (similar to a clinical setting), or submitted allat once (the “ideal” for machine learning analyses). In batched procedures, data was\\nsubmitted one subset at a time, as described prior. A strict max wall time of 8 hourswas put in place for all protocols to simulate the limited resources (in both time andhardware) that clinical settings often have. All protocols were run on a single TeslaV100-PCIE-16GB GPU with 16GB of RAM and two Intel(R) Xeon(R) Gold 6148CPUs run at 2.40GHz (speeding up initial protocol setup).\\nThe initial architecture for all procedures is shown in Table 1 . For progressive\\nlearning procedures, new blocks were added which were half the size of the originalblocks, set to receive the the concatenated outputs of all blocks in the prior layer ofeach set of blocks. All parameters were initialized randomly using PyTorch version1.8.1 default settings. We used an ADAM optimizer with a learning rate of 0.001,first moment β\\n1of 0.99, second moment β2of 0.999, and weight decay λof 0.001\\nduring training. For progressive learning models, an identical optimizer with onetenth the learning rate was used for post-pruning model optimization. Each cycleconsisted of 90 epochs of training. Progressive procedures were given 10 epochs per\\npruning cycle, with pruning being repeated until the mean accuracy of the prior set\\nof epochs was greater than that of the new set of epochs, with the model ’s state\\nbeing restored to the prior before continuing. The model ’s training and validation\\naccuracy was evaluated and reported once per epoch. Protocol efficacy was mea-sured via the max validation accuracy of the model over all cycles and epochs andmean best-accuracy-per-cycle (BAPC) for all cycles.\\n4.1.2 Results\\nFor our full datasets, the model achieved diagnostic classification accuracy\\nvalues of 80-85% for most of the results. The simple model, without progression\\n90Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='21eb281f-5580-4248-9407-9b1b6dc7d9b7', embedding=None, metadata={'page_label': '91', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='and with full access to the entire dataset, reached a max accuracy of 81.13%, with a\\nmean BAPC of 80.71%. Adding progression to the process further improved this,primarily though the pruning stage, with a max accuracy of of 84.80%. However,the mean BAPC dropped to 77.44%, as prior frozen parameters in the modelappeared to make the model “stagnate ”. Allowing the model to update and prune\\nthese carried-over parameters improves things substantially, leading to a maxaccuracy of 90.66% and a mean BAPC of 84.83%.\\nWhen data was batched, a noticeable drop in accuracy was observed, as\\nexpected. Without progressive learning, our model ’s max observed accuracy was\\nonly 73.7% (a drop of 7.37%), with a mean BAPC of 71.75%. The progressive modelBlock Number Type Size Other\\n1 2DConvolution 32, 3x3 Stride = 1\\n2DBatchNorm\\nReLU\\n[Concatenation ]\\n2 2DConvolution 32, 3x3 Stride = 1\\n2DBatchNorm\\nReLU\\n2DMaxPooling 2x2 Stride = 2\\nDropout r = 0.25\\n[Concatenation ]\\n3 2DConvolution 64, 3x3 Stride = 1\\n2DBatchNorm\\nReLU\\n[Concatenation ]\\n4 2DConvolution 64, 3x3 Stride = 1\\n2DBatchNorm\\nReLU\\n2DMaxPooling 2x2 Stride = 2\\nDropout r = 0.25\\n[Concatenation ]\\n5 Flatten\\nLinear 512\\n1DBatchNorm 512\\nReLU\\nDropout r = 0.5\\n6[ Concatenation ]\\nLinear 20\\nSoftmax\\nTable 1.\\nThe basic structure of the convolutional neural network being tested on the CIFAR-10 dataset. Based on themodel used by Fayek et al. [29]. [Concatenation] indicates where the output of one set of blocks would beconcatenated together before being fed into new blocks in the following layer, and can be ignored forindependent learning tasks.\\n91Delivering Precision Medicine to Patients with Spinal Cord Disorders; Insights …\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 8713', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='1bf1ec4c-138d-4bba-b645-91167ea32849', embedding=None, metadata={'page_label': '92', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='with frozen priors initially performed better, reaching its maximum accuracy of\\n75.9% in its first cycle, but rapidly fell off, having a mean BAPC of 66.0%. Allowing\\nthe model to update its priors greatly improve the results, however, leading to a\\nmaximum accuracy of 82.4% and a mean BAPC of 79.02%, competing with thestatic model trained on all data at once.\\nA plot of each model ’s accuracy for each model setup, taken over the entire\\nduration (all cycles and epochs) for both the training and validation assessments, isshown in Figure 5 .\\n4.2 DenseNet\\n4.2.1 Methodology\\nTo confirm that the success of the setup suggested by Fayek et al. was not due to\\nrandom chance, we also applied the technique to another model which is effective\\nat predicting the CIFAR-10 dataset; the DenseNet architecture [37]. DenseNets arecharacterized by their “blocks ”of densely connected convolution layer chains,\\nleading to a model which can utilize simpler features identified in early convolu-tions to inform later layers that would, in a more linear setup, not be connectedtogether at all. These blocks are a perfect fit for our method, as they can be\\nFigure 5.\\nThe training progression of the ConvNet model replicated from Fayek et. al ’s study [29] in various forms. From\\nleft to right, the model on its own, reset after every cycle (static), a progressively learning model, with prior traitsfrozen (progressive, frozen), and a progressively learning model, with all traits open to training and pruningeach cycle (progressive, free). Training accuracy is shown in blue, with validation accuracy shown in orange.The maximum observed accuracy for each is indicated via a horizontal dotted (training) or dashed(validation) line. The dotted horizontal lines indicate where the training of the model for a given cycle wascomplete (not including the pruning of progressive models). Note that the total number of epochs taken betweenthese cycles differs from cycle to cycle in progressive models, as a result of the pruning stage cycling until a\\nvalidation accuracy loss was observed.\\n92Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c94c6bdd-5e41-484b-a9d2-79eeb4e86511', embedding=None, metadata={'page_label': '93', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='generated and added to our progressive learning network just like any other set of\\nlayers. DenseNets have also been shown to have better accuracy than classical\\nconvolution nets within the CIFAR-10 dataset, reaching error rates of less than 10%\\nin many cases [37]. However, the dense connections make the networks extremelycomplex, and they are generally highly over-parameterized as well, making themprone to over-fitting in some cases.\\nOur testing methodology was largely identical to that of the Convolutional\\nnetwork tested in the previous section. One change was to use a Stochastic GradientDescent (SGD) optimizer with an initial learning rate of 0.1. Training was done inbatches of 64, for a total of 300 epochs per cycle. The learning rate is reduced by a\\nfactor of 10 when 50% and 75% of the epochs for each cycle has passed. The SGD\\noptimizer was set with a weight decay of 0.0001 and a momentum of 0.9. Dropoutlayers with a drop rate of 0.2 were added after each block as well. The initialarchitecture for the network was based on the ‘densenet-169 ’architecture, and is\\nshown in Table 2 , having a growth rate of 32, an initial feature count of 64, and\\nBlock Number Type Size Other\\n1 2DConvolution 64, 7x7 Stride = 2, Padding = 3\\n2DBatchNorm\\nReLU\\n2DMaxPooling 3x3 Stride = 2, Padding = 1\\n[Concatenation ]\\n2 Dense Block Layers = 6 Bottleneck = 4, r = 0.2\\nTransition Block\\n[Concatenation ]\\n3 Dense Block Layers = 12 Bottleneck = 4, r = 0.2\\nTransition Block\\n[Concatenation ]\\n4 Dense Block Layers = 32 Bottleneck = 4, r = 0.2\\nTransition Block\\n[Concatenation ]\\n5 Dense Block Layers = 32 Bottleneck = 4, r = 0.2\\nTransition Block\\n[Concatenation ]\\n6 2DBatchNorm 1664\\n[Concatenation ]\\n7 ReLU\\n2DAdaptiveAveragePool 1x1\\nFlatten\\nLinear 1664\\nTable 2.\\nThe structure of the DenseNet mdoel being tested on the CIFAR-10 dataset. Based on the model used by Huanget al. [37]. Dense block indicates a densely connected convolution block, with transition block indicating atransition layer, both being detailed in Huang et. al’ s original paper. [Concatenation] indicates where the\\noutput of one set of blocks would be concatenated together before being fed into new blocks in the followinglayer, and can be ignored for independent learning tasks. Where it appears, r indicates dropout rate for the\\nassociated block.\\n93Delivering Precision Medicine to Patients with Spinal Cord Disorders; Insights …\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 8713', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='70502a0d-df07-487a-b9f1-181d5ad01c34', embedding=None, metadata={'page_label': '94', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='consisting of 4 blocks of densely connected convolution layers, each with 6, 12, 32,\\nand 32 convolution layers respectively. For progressive learning systems, new\\nblocks followed the same architecture with half the growth rate (16) and initial\\nfeatures (32). These changes were made to maintain parity with the originalDenseNet CIFAR-10 test [37].\\n4.2.2 Results\\nFor our full datasets, we saw an accuracy values of around 90%. The simple\\nmodel, without progression, reached a max accuracy of exactly 90%, but was only\\nable to run one cycle to completion before the 8 hour time limit was reached.\\nAdding progression to the process improved this slightly, resulting in a max accu-\\nracy of of 90.66%, but only barely completed its first pruning cycle before the timelimit was reached. As a result, the same accuracy was observed for both progressivemodels with and without priors being trainable, as no new prior blocks were added.Slight variations were still observed, however, due to how the model ’s initialization\\nprocess differs.\\nWhen data was batched, a much more significant drop in accuracy occured as\\ncompared to the Convolutional network. Without progressive learning, our model ’s\\nmax observed accuracy was only 69.9% (a drop of more than 30%), with a meanBAPC of 65.87%. However, it was able to run for all 10 cycles within the allotted\\nFigure 6.\\nThe training progression of the DeepNet model replicated from Huang et. al’ s original ‘densenet-169 ’model\\n[37] in various forms. From left to right, the model on its own, reset after every cycle (static), a progressivelylearning model, with prior traits frozen (progressive, frozen), and a progressively learning model, with all traitsopen to training and pruning each cycle (progressive, free). Training accuracy is shown in blue, with validationaccuracy shown in orange. The maximum observed accuracy for each is indicated via a horizontal dotted(training) or dashed (validation) line. The dotted horizontal lines indicate where the training of the model for agiven cycle was complete (not including the pruning of progressive models). Note that the total number of epochstaken between these cycles differs from cycle to cycle in progressive models, as a result of the pruning stage cycling\\nuntil a validation accuracy loss was observed.\\n94Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='02a4b72a-0993-435d-abc8-d837b8ec91f6', embedding=None, metadata={'page_label': '95', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='8 hour time span. The progressive model with frozen priors performed even worse,\\nreaching a maximum accuracy of 67.1% in its first cycle, and only completing\\n5 cycles before the time limit, only reaching a mean BAPC of 64.28%. Allowing the\\nmodel to update its priors somewhat improved the results, leading to a maximumaccuracy of 71.7% and a mean BAPC of 68.28%, showing some slight recovery overthe static model in a batch scenario. However, it also only managed to run through5 cycles before the time limit was reached.\\nA plot of each model ’s accuracy for each model setup, taken over the entire\\nduration (all cycles and epochs) for both the training and validation assessments, issummarized in Figure 6 .\\n5. Discussion and conclusions\\nThe results of our tests show great promise for how these approaches to machine\\nlearning use in precision medicine can be used, while nonetheless highlighting somesignificant shortcomings which will need to be considered should this frameworkbecome common practice. Most notably, we see that model ’s which over-fit the\\navailable data are extremely detrimental to the system, even if the underlyingmodel would be better with all data immediately available to it. This is shown veryclearly with the effectiveness of pruning in all our models, with clear gains inaccuracy observed, likely as a result of the process helping counteract over-fitting\\nresulting from over-parameterized models. Finding an “ideal ”model for a given\\ntask is already a difficult task, and our results show that this is only exacerbated by\\nthe conditions of a clinical environment. Nevertheless, there is clearly potential inthis framework, with the Convolutional network tested on clinical-like batch databeing near identical in effectiveness to its static counterpart trained on the fulldataset.\\nWe are also optimistic that many opportunities remain for improvement in\\nprogressive learning implementations. Our current implementation of the progres-\\nsive learning framework is locked to a specific set of initial data inputs, being unable\\nto add new ones should they become available. In theory, this could be as simple asadding a new set of initial blocks to the existing network, in effect acting like a“progression ”stage with custom new blocks (as well as an update to existing new\\nblock generation procedures to match). However, this has a number of issues thatwe have not, at present, found a way to resolve. First, each branch is likely to“learn ”at different rates, resulting in one set of blocks associated with a given set of\\ninput data containing more redundant features per-progression stage than the rest.\\nThis proves problematic during pruning, however; we either over-prune blocks\\nwith important features within them, or under-prune those which contain anabundance of redundant and/or noise-contributing features. We believe this can beresolved, but were simply unable to do so by the time of this publication.\\nAnother potential improvement would be to “carry-over ”output layers weights\\nbetween progression stages. This would allow for the network to have better for-ward transfer, so long as the task ’s end goal (categorical prediction, single metric\\nestimation etc.) remains the same. In our implementation, this is currently not the\\ncase, with the output layer being regenerated every cycle, keeping it in line with the\\noriginal Progressive Learning framework ’s design [29]. The difficulty of\\nimplementing such as system, as well as its effectiveness in improving model out-comes, has yet to be tested.\\nOne other major hurdle is that of long term memory cost. As currently\\nimplemented, pruning does not actually remove parameters from the model; itsimply masks them out during training and evaluation, preventing them from\\n95Delivering Precision Medicine to Patients with Spinal Cord Disorders; Insights …\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 8713', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='e33633fb-5aa5-42cb-a2ca-9a1b5de08546', embedding=None, metadata={'page_label': '96', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='contributing to the models predictions. While this improves the speed and accuracy\\nof the model being generated, its memory footprint expands infinitely as more\\ncycles are run. Resolving this issue is difficult, however, requiring the model to\\neffectively fully re-construct itself to account for any now-removed parameters.Doing so would allow the model to come to a “static ”memory cost, as the number\\nof pruned parameters approaches the number of new ones added every cycle. Inturn, this would enable applications where the model is expected to existing forvery long duration in limited resource systems. Such compression techniques are anongoing field of research at time of writing; as such, we believe such a implemen-tation will be possible in the near future.\\nFinally, testing our methodology on a real-world clinical dataset is needed before\\nwe can be sure it is truly effective. While the CIFAR-10 dataset [34] has been shownto work effectively for machine learning testing purposes, our assumptions aboutclinical data still need to be confirmed. We intend to put our framework to the testsoon, assessing its effectiveness at predicting DCM severity using the DCM datamentioned throughout this chapter; nevertheless, this framework should be con-sidered experimental until such results (from ourselves or others) are acquired.Continual learning systems trained for clinical data also retain the limitations of\\ncontinual learning, such as increased potential to over-fit and the inability to trans-\\nfer new knowledge obtained to help with the understanding of prior knowledge.Modifications to the progression procedure have been proposed to amend this [29],though these have not been tested at time of writing.\\nOverall, however, we believe our framework for machine learning system design\\nin precision medicine should work well as a road-map for future research, eventhough refinements remain to be made. With systems such as the ProgressiveLearning framework available, these new systems can adapt to changes in data\\ntrends while accepting new data in effectively random batches, both important\\nrequirements for a clinical environment. Well designed data storage and manage-ment also allows such systems to easily access, update, and report important metricsto all necessary parties, while remaining open to changes as new research is com-pleted. Through the application of these techniques, modern medicine should beable to not only adapt to the age of information, but to benefit immensely from it.\\nAbbreviations\\nDCM Degenerative Cervical MyeolopathyCIFAR Canadian Institute for Advanced Research\\nmJOA Modified Japanese Orthopedic Association\\nBIDS Brain Imaging Data StructureCNN Convolutional Neural NetworkDCLN Deeply Connected Learning NetworkBAPC Best Accuracy Per CycleSGD Stochastic Gradient Descent\\n96Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='196cf36d-5d7c-4e41-8008-1f07925ebda8', embedding=None, metadata={'page_label': '97', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Author details\\nKalum J. Ost1,2, David W. Anderson2†and David W. Cadotte1,2,3,4*†\\n1 Hotchkiss Brain Institute, Calgary, Alberta, Canada\\n2 Cumming School of Medicine, Calgary, Alberta, Canada\\n3 Division of Neurosurgery, Departments of Clinical Neurosciences and Radiology,\\nUniversity of Calgary, Alberta, Canada\\n4 Combined Orthopedic and Neurosurgery Spine Program, University of Calgary,\\nAlberta, Canada\\n*Address all correspondence to: david.cadotte@ucalgary.ca\\n†These authors contributed equally.\\n© 2021 The Author(s). Licensee IntechOpen. T his chapter is distributed under the terms\\nof the Creative Commons Attribution License ( http://creativecommons.org/licenses/\\nby/3.0), which permits unrestricted use, distribution, and reproduction in any medium,\\nprovided the original work is properly cited.\\n97Delivering Precision Medicine to Patients with Spinal Cord Disorders; Insights …\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 8713', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='ea345d42-46a3-4a0b-83c7-3f7294f01a60', embedding=None, metadata={'page_label': '98', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='References\\n[1]Julia Adler-Milstein and Ashish K Jha.\\nHitech act drove large gains in hospital\\nelectronic health record adoption.Health Affairs , 36(8): 1416 –1422, 2017.\\ndoi:10.1016/j.cell.2019.02.039.\\n[2]R Scott Evans. Electronic health\\nrecords: then, now, and in the future.\\nYearbook of medical informatics , (Suppl\\n1):S48, 2016.\\n[3]Michael Bliss. William Osler: A life in\\nmedicine . Oxford University Press,\\n1999.\\n[4]Zheng-Guo Wang, Liang Zhang, and\\nWen-Jun Zhao. Definition and\\napplication of precision medicine.Chinese Journal of Traumatology , 19(5):\\n249–250, 2016.\\n[5]Christina L Aquilante, David P Kao,\\nKaty E Trinkley, Chen-Tan Lin, Kristy RCrooks, Emily C Hearst, Steven J Hess,Elizabeth L Kudron, Yee Ming Lee, InaLiko, et al. Clinical implementation ofpharmacogenomics via a health system-wide research biobank: the university ofcolorado experience, 2020.\\n[6]Jessica R Williams, Dalia Lorenzo,\\nJohn Salerno, Vivian M Yeh, Victoria BMitrani, and Sunil Kripalani. Currentapplications of precision medicine: abibliometric analysis. Personalized\\nmedicine , 16(4):351 –359, 2019. doi:\\n10.2217/pme-2018-0089.\\n[7]Omar Khan, Jetan H Badhiwala,\\nGiovanni Grasso, and Michael GFehlings. Use of machine learning andartificial intelligence to drivepersonalized medicine approaches forspine care. World Neurosurgery , 140:\\n512–518, 2020. doi: 10.1016/j.\\nwneu.2020.04.022.\\n[8]Renato Cuocolo, Martina Caruso,\\nTeresa Perillo, Lorenzo Ugga, and MarioPetretta. Machine learning in oncology:A clinical appraisal. Cancer letters , 481:55–62, 2020. doi: 10.1016/j.\\ncanlet.2020.03.032.\\n[9]Aria Nouri, Lindsay Tetreault,\\nAnoushka Singh, Spyridon KKaradimas, and Michael G Fehlings.Degenerative cervical myelopathy:epidemiology, genetics, andpathogenesis. Spine , 40(12):E675– E693,\\n2015. doi: 10.1097/BRS.0000000000000913.\\n[10]Benjamin M Davies, Oliver D\\nMowforth, Emma K Smith, and MarkRN Kotter. Degenerative cervical\\nmyelopathy. Bmj, 360, 2018. doi:\\n10.1136/bmj.k186.\\n[11]Ivana Kovalova, Milos Kerkovsky,\\nZdenek Kadanka, Zdenek Kadanka Jr,\\nMartin Nemec, Barbora Jurova, LadislavDusek, Jiri Jarkovsky, and JosefBednarik. Prevalence and imagingcharacteristics of nonmyelopathic andmyelopathic spondylotic cervical cordcompression. Spine , 41(24):1908 –1916,\\n2016. doi: 10.1097/\\nBRS.0000000000001842.\\n[12]Lindsay A Tetreault, Branko\\nKopjar, Alexander Vaccaro, SangwookTim Yoon, Paul M Arnold, Eric M\\nMassicotte, and Michael G Fehlings. Aclinical prediction model to determineoutcomes in patients with cervicalspondylotic myelopathy undergoingsurgical treatment: data from theprospective, multi-center aospinenorth america study. JBJS, 95 (18):\\n1659– 1666, 2013. doi: 10.2106/JBJS.\\nL.01323.\\n[13]Josef Bednarik, Zdenek Kadanka,\\nLadislav Dusek, Milos Kerkovsky,Stanislav Vohanka, Oldrich Novotny,Igor Urbanek, and DagmarKratochvilova. Presymptomaticspondylotic cervical myelopathy: anupdated predictive model. European\\nSpine Journal , 17(3):421 –431, 2008. doi:\\n10.1007/s00586-008-0585-1.\\n98Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='5dc2309a-cf2b-4354-b12f-f952827c6712', embedding=None, metadata={'page_label': '99', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='[14]Benjamin S Hopkins, Kenneth A\\nWeber II, Kartik Kesavabhotla, Monica\\nPaliwal, Donald R Cantrell, and ZacharyA Smith. Machine learning for theprediction of cervical spondyloticmyelopathy: a post hoc pilot study of 28participants. World neurosurgery , 127:\\ne436 –e442, 2019. doi: 10.1016/j.\\nwneu.2019.03.165.\\n[15]Omar Khan, Jetan H Badhiwala,\\nMuhammad A Akbar, and Michael GFehlings. Prediction of worse functionalstatus after surgery for degenerativecervical myelopathy: A machine\\nlearning approach. Neurosurgery , 2020.\\ndoi: 10.1093/neuros/nyaa477.\\n[16]Kalum Ost, W Bradley Jacobs,\\nNathan Evaniew, Julien Cohen-Adad,\\nDavid Anderson, and David W Cadotte.Spinal cord morphology in degenerativecervical myelopathy patients; assessing\\nkey morphological characteristics using\\nmachine vision tools. Journal of Clinical\\nMedicine , 10(4): 892, 2021. doi: 10.3390/\\njcm10040892.\\n[17]Benjamin De Leener, Simon Lévy,\\nSara M Dupont, Vladimir S Fonov,Nikola Stikov, D Louis Collins, Virginie\\nCallot, and Julien Cohen-Adad. Sct:\\nSpinal cord toolbox, an open-sourcesoftware for processing spinal cord mridata. Neuroimage , 145:24– 43, 2017. doi:\\n10.1016/j.neuroimage.2016.10.009.\\n[18]Takashi Kameyama, Yoshio\\nHashizume, Tetsuo Ando, and Akira\\nTakahashi. Morphometry of the normal\\ncadaveric cervical spinal cord. Spine , 19\\n(18):2077 –2081, 1994. doi: 10.1097/\\n00007632-199409150-00013.\\n[19]Nitin B Jain, Gregory D Ayers,\\nEmily N Peterson, Mitchel B Harris,Leslie Morse, Kevin C O ’Connor, and\\nEric Garshick. Traumatic spinal cordinjury in the united states, 1993-2012.Jama , 313(22):2236 –2243, 2015.\\n[20]Raia Hadsell, Dushyant Rao, Andrei\\nA Rusu, and Razvan Pascanu.Embracing change: Continual learningin deep neural networks. Trends in\\nCognitive Sciences , 2020. doi: 10.1016/j.\\ntics.2020.09.004.\\n[21]Mongodb. https://github.com/mong\\nodb/mongo, 2013.\\n[22]Nathan Evaniew, David W Cadotte,\\nNicolas Dea, Christopher S Bailey, SeanD Christie, Charles G Fisher, JeromePaquet, Alex Soroceanu, Kenneth CThomas, Y Raja Rampersaud, et al.Clinical predictors of achieving theminimal clinically important difference\\nafter surgery for cervical spondylotic\\nmyelopathy: an external validationstudy from the canadian spine outcomesand research network. Journal of\\nNeurosurgery: Spine , 33(2):129– 137,\\n2020. doi: 10.3171/2020.2.spine191495.\\n[23]Lindsay Tetreault, Branko Kopjar,\\nAria Nouri, Paul Arnold, GiuseppeBarbagallo, Ronald Bartels, ZhouQiang, Anoushka Singh, MehmetZileli, Alexander Vaccaro, et al. Themodified japanese orthopaedicassociation scale: establishing criteriafor mild, moderate and severeimpairment in patients with\\ndegenerative cervical myelopathy.\\nEuropean Spine Journal , 26(1):78 –84,\\n2017. doi: 10.1007/s00586-016-4660-8.\\n[24]Krzyszt of J Gorgolewski, Tibor\\nAuer, Vince D Calhoun, R CameronCraddock, Samir Das, Eugene P Duff,\\nGuillaume Flandin, Satrajit S Ghosh,\\nTristan Glatard, Yaroslav O Halchenko,et al. The brain imaging data structure, aformat for organizing and describingoutputs of neuroimaging experiments.Scientific data , 3(1):1 –9, 2016. doi:\\n10.1038/sdata.2016.44.\\n[25]A. Chen, J. Beer, N. Tustison, P.\\nCook, R. Shinohara, and H. Shou.Removal of scanner effects incovariance improves multivariatepattern analysis in neuroimaging data.bioRxiv p, 2019.\\n99Delivering Precision Medicine to Patients with Spinal Cord Disorders; Insights …\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 8713', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='d50dfb8a-e8ff-4dea-8305-e486ebf0b93c', embedding=None, metadata={'page_label': '100', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='[26]Xiangjie Li, Kui Wang, Yafei Lyu,\\nHuize Pan, Jingxiao Zhang, Dwight\\nStambolian, Katalin Susztak, MuredachP Reilly, Gang Hu, and Mingyao Li.Deep learning enables accurateclustering with batch effect removal insingle-cell rna-seq analysis. Nature\\ncommunications , 11(1):1 –14, 2020. doi:\\n10.1038/s41467-020-15851-3.\\n[27]Samuel J Yang, Scott L Lipnick, Nina\\nR Makhortova, SubhashiniVenugopalan, Minjie Fan, ZanArmstrong, Thorsten M Schlaeger,Liyong Deng, Wendy K Chung, Liadan\\nO’Callaghan, et al. Applying deep neural\\nnetwork analysis to high-content image-\\nbased assays. SLAS DISCOVERY:\\nAdvancing Life Sciences R&D , 24(8):829 –\\n841, 2019. doi: 10.1177/2472555219857715.\\n[28]Jake Turicchi, Ruairi O ’Driscoll,\\nGraham Finlayson, Cristiana Duarte,Antonio L Palmeira, Sofus C Larsen,Berit L Heitmann, and R James Stubbs.Data imputation and body weightvariability calculation using linear andnonlinear methods in data collectedfrom digital smart scales: simulation andvalidation study. JMIR mHealth and\\nuHealth , 8(9):e17977, 2020.\\n[29]Haytham M Fayek, Lawrence\\nCavedon, and Hong Ren Wu.Progressive learning: A deep learningframework for continual learning.Neural Networks, 128:345 –357, 2020. doi:\\n10.1016/j.neunet.2020.05.011.\\n[30]Olaf Ronneberger, Philipp Fischer,\\nand Thomas Brox. U-net: Convolutionalnetworks for biomedical imagesegmentation. In International\\nConference on Medical image computingand computer-assisted intervention , pages\\n234–241. Springer, 2015.\\n[31]Alex Krizhevsky, Ilya Sutskever,\\nand Geoffrey E Hinton. Imagenetclassification with deep convolutionalneural networks. Advances in neuralinformation processing systems , 25: 1097 –\\n1105, 2012.\\n[32]Ting Zhang, Guo-Jun Qi, Bin Xiao,\\nand Jingdong Wang. Interleaved groupconvolutions. In Proceedings of the IEEE\\ninternational conference on computervision, pages 4373 –4382, 2017.\\n[33]Liangru Ke, Yishu Deng, Weixiong\\nXia, Mengyun Qiang, Xi Chen, KuiyuanLiu, Bingzhong Jing, Caisheng He,Chuanmiao Xie, Xiang Guo, et al.Development of a self-constrained 3ddensenet model in automatic detectionand segmentation of nasopharyngealcarcinoma using magnetic resonanceimages. Oral Oncology , 110:104862,\\n2020. doi: 10.1016/j.oraloncology.2020.104862.\\n[34]Alex Krizhevsky, Geoffrey Hinton,\\net al. Learning multiple layers offeatures from tiny images. 2009.\\n[35]Adam Paszke, Sam Gross, Soumith\\nChintala, Gregory Chanan, EdwardYang, Zachary DeVito, Zeming Lin,Alban Desmaison, Luca Antiga, andAdam Lerer. Automatic differentiation\\nin pytorch. 2017.\\n[36]Martín Abadi, Ashish Agarwal, Paul\\nBarham, Eugene Brevdo, Zhifeng Chen,\\nCraig Citro, Greg S. Corrado, AndyDavis, Jeffrey Dean, Matthieu Devin,Sanjay Ghemawat, Ian Goodfellow,Andrew Harp, Geoffrey Irving, Michael\\nIsard, Yangqing Jia, Rafal Jozefowicz,\\nLukasz Kaiser, Manjunath Kudlur, JoshLevenberg, Dandelion Man ’e, Rajat\\nMonga, Sherry Moore, Derek Murray,Chris Olah, Mike Schuster, JonathonShlens, Benoit Steiner, Ilya Sutskever,Kunal Talwar, Paul Tucker, VincentVanhoucke, Vijay Vasudevan, Fernanda\\nViégas, Oriol Vinyals, Pete Warden,\\nMartin Wattenberg, Martin Wicke,Yuan Yu, and Xiaoqiang Zheng.TensorFlow: Large-scale machinelearning on heterogeneous systems,\\n100Machine Learning - Algorithms, Models and Applications', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='5b8ef07a-39f6-427b-aa89-3e44bb3cb5c9', embedding=None, metadata={'page_label': '101', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='2015. URL https://www.tensorflow.org/.\\nSoftware available from tensorflow.org.\\n[37]Gao Huang, Zhuang Liu, Laurens\\nVan Der Maaten, and Kilian QWeinberger. Densely connectedconvolutional networks. In Proceedings\\nof the IEEE conference on computer visionand pattern recognition , pages 4700 –\\n4708, 2017.\\n101Delivering Precision Medicine to Patients with Spinal Cord Disorders; Insights …\\nDOI: http:/ /dx.doi.org/10. 5772/intechopen.9 8713', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='336abe6d-8b95-4e7e-9aee-71803835b48a', embedding=None, metadata={'page_label': '102', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='670a3f10-21a2-48d2-9118-fcda27b28060', embedding=None, metadata={'page_label': '103', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='103Chapter 6\\nEnhancing Program Management \\nwith Predictive Analytics Algorithms (PAAs)\\nBongs\\xa0Lainjo\\nAbstract\\nThe increase in the amount of big data and the emergence of analytics technologies \\nhas created the opportunity for applying algorithm development techniques using \\nmachine learning (ML) languages to predict future events. To conduct inclusive analyses of contemporary literature of existing relevant narratives with a focus on program management themes, including state-of-the art methodologies on current plausible predictive analytics models. The methodology used is the review and applications of relevant programming platforms available. Program management requires the utilization of the existing ML languages in understanding future events. Enabling decision makers to make strategic - goals, objectives, and mis-sions. The use of PAAs has gained thematic significance in automotive industries, energy sector, financial organizations, industrial operations, medical services, governments, and more. PAAs are important in promoting the management of future events such as workflow or operational activities in a way that institu-tions can schedule their activities in order to optimize performance. It enables organizations to use existing big data to predict future performance and mitigate risks. The improvements in information technology and data analytics procedures have resulted in the ability of businesses to make effective use of historical data in making predictions. This enables evidence-based planning, mitigating risks, and optimizing production.\\nKeywords: program-management, algorithm-development,  \\npredictive-analytics-models, machine-learning, evidence-based-planning, \\noptimizing\\n1. Introduction\\nThis chapter examines the current knowledge and scholarly information about \\npredictive analytics algorithms (PAAs) by focusing on the concept of working principles on which they are used to predict future events and the procedures fol-lowed in creating them. The PAAs have been used extensively in predicting future events in healthcare practice, manufacturing companies, businesses, education, sports, and agriculture. The main programming languages used to create PAAs are Java, C, and Python amongst others. The forms of algorithms that are commonly used are brute force algorithm, simple recursive algorithm, backtracking algorithm, randomized algorithm, and dynamic programming algorithms.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='f93e6329-24e6-4328-a200-85f1e79c6f40', embedding=None, metadata={'page_label': '104', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n1042. Background\\nOver the years, the concept and principles of data management have remained \\nmostly unchanged. What has changed, however, includes the introduction of a \\ncomplex, state-of-the-art, sophisticated, and integrated technological ecosystem: big data, cloud computing, and analytics [1]. The dynamics of this system have moved the way data are managed to a higher level, and institutions (public, private, sports, healthcare, and more) have capitalized on this! They have maximized their respective productivity levels using these systems with no reservations. As expected, these inno-vative developments come with significant risks from reliability to privacy and secu-rity concerns. Data are only as good and useful as their level of validity and reliability. Analytics, mentioned earlier, is one of the major components of the ecosystem that is used in transforming data into information. It is a sub-system that is also as useful as the reliability of the data used in performing different analytical interventions. At the conceptual level, analytics is an algorithm-driven strategy [2]. It facilitates the trans-formation of complex (generally) historical data sets into meaningful outcomes used for predicting future events. Its effectiveness has transformed and refined different sets of intended results. Institutions have used its predictive capabilities to optimize resources, streamline activities and increase productivity—ultimately becoming more competitive. The key players involved in the management and utilization of these ecosystems are the service providers (SPs) and their clients (users) [3].\\nIt has been difficult for equipment manufacturers to develop innovative prod-\\nucts using hardware alone. Those involved in product development have been able to add capabilities by applying solutions that improve customer satisfaction and value creation. Predictive analytics programs and equipment have been effective in promoting the anticipation of failures and provide forecasts for energy require-ments while reducing the cost of operations. Predictive analytic models are used by companies in developing forecasts and creating plans for better utilization of resources. Before PAAs are used, the developer must review the available data and create/test mathematical models that incorporate computational processes in predicting future outcomes. The models provide forecasts of future outcomes based on a particular metric such as the associated parameter changes.\\nThis chapter looks at the scope, thematic applicability, challenges, and progno-\\nses of predictive analytics with life case studies from different institutions. It also highlights limitations, implications, and potential vulnerabilities. In this study, a select number of key institutions are included. These serve as examples of classical life case studies meant to help readers resonate with their own different and unique challenges. The various organizations are reviewed and analyzed on multi-dimen-sional thematic platforms. These include problem statements, strategic approaches, relevant processes, algorithmic layouts, programming descriptions, pilot testing, process reviews, initial implementation, and challenges and lessons learned. The relevant contents of these themes are only limited by the inability to access reli-able, valid, evidence-based, useful, and compelling sources of information. Every attempt is made to address these limitations, and at the same time, prioritize avail-able sources based on their pragmatic perspectives, simplicity, and authenticity. The select institutions include business (e-commerce, banking, finance, marketing, and more), health, education, government, sports, agriculture, social media, and so on. One invaluable approach applied in developing this narrative is an extensive review of available and contemporary literature. While the topic remains new and evolving, available documentation does indicate an inclusive degree of participa -\\ntion by different stakeholders. Key limitations like technical inability to develop and implement the various models have not been a significant deterrent. Readers need to consider this chapter as an evidence-based, knowledge-sharing cursory or ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='44077bae-8bb9-4483-a97b-c21e11753472', embedding=None, metadata={'page_label': '105', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='105Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\nsoft-core and easy to understand demonstration of the strength, scope, and applica -\\ntion of PAAs in optimizing program management challenges.\\n3. Quality of data (QOD)\\nMy experience dealing with data of different types and categories spans over \\nfour decades. From attending a survey technician-training program after high \\nschool to studying in an engineering school, data management has played and continues to play a very significant role in my professional life. As well, the chal-lenges encountered over this period of time continue to evolve exponentially! The most recent paradigm transformation in data management is in the proliferation of analytics — a domain that has enabled businesses, industry, academia, banks, etc. to exhale and address competing forces with might and vitality.\\nOne adage that strongly and appropriately describes different forms of data \\nis “garbage in garbage out” (GIGO). Interestingly, this adage is not just limited to conventional data as described in the previous paragraph—it also includes a human dimension. For example, healthy eating habits correlate positively with an improved quality of life and health.\\nThe importance and significance of good data cannot be adequately emphasized \\nin general, and more specifically and critically in data-intensive methodologies like analytics.\\nHere is a personal and professional life case study example. In 1992, Columbia \\nUniversity (CU) recruited me as a Senior Data Management Advisor. My very first assignment was to recalculate the incidence rate of HIV/AIDS. Four years earlier, CU had launched a project that was primarily managing an open HIV/AIDS cohort. That is a population of interest that recruited new members as the study progressed.\\nThe project’ s focus was to manage a cohort of over 13,000 participants and \\nproduce periodic reports (in this case every six months) on the dynamics of the epidemic. The milestones were morbidity rates — incidence and prevalence.\\nThe week when my assignment began coincided with a scientific conference in \\nHolland where Dr. Maria Wawer (my boss) and other colleagues were presenting papers on the project findings. During that first week of the conference, Dr. Wawer contacted me to inquire about what incidence rates I had come up with. In the meantime, because of my limited knowledge of the data set, I recruited two experts who had been with the project as consultants during and since its interception. I identified what I believed were the most critical issues to be addressed before start -\\ning the computations and subsequent analysis.\\nThe team was then assigned specific tasks. These included cleaning the relevant \\ndata set: generating frequency tables; identifying outliers; triangulating with both source data (original questionnaires), laboratory technicians (serology test results), and survey team members. After completing this cleaning and validation process (including correcting the numerous inconsistencies), we proceeded to perform the calculations using the statistical package — Statistical Package for Social Sciences (SPSS). This phase of the assignment went very well. After compiling the results, I then submitted the findings (as earlier agreed) to Dr. Wawer who was still at the conference in Holland. The recalculated rates this time were one infected case lower than what was being presented at the conference. And that, as it turned out, was a big deal! I received immediate feedback as anticipated, highlighting the fact that I was new to the project team with a limited understanding of the data sets.\\nDuring one of our weekly team meetings (post-conference), primarily to \\nreview what had gone wrong with our incidence rate, one of my colleagues was so embarrassed and distraught that he started shedding tears. Since no amount ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='de900490-c433-4c8c-927e-964515a020d3', embedding=None, metadata={'page_label': '106', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n106of consolation could calm him the meeting was immediately adjourned. In the \\nmeantime, members of a similar and “competing” project were constantly and consistently asking us what the real incidence rate was. What should they quote in their papers? As the message continued to spread, our team agreed on a consensus response, which was that the team was still in the review and validation process after which the final and latest incidence rates would be disclosed. This resolution served very well in mitigating further concerns.\\nDuring this process, our team went back to the drawing board to confirm what \\nthe real rates were. After our earlier computations and part of the triangulation process, we had actually conducted a recount of the new infections. The numbers were consistent with our findings. This recounting exercise was again conducted in addition to further calculations. And this time every degree of verification con-firmed our results: there was one infected case too many!\\nAnd what is the message? PAAs and other quantitative methods are only as valid, \\nreliable, and useful as the quality of data used.\\n3.1 Objectives\\nThe objectives of this chapter are to examine:\\n• the current literature on PAAs with the focus on methods in which they are \\nused to enable prediction of future events.\\n• case studies of the use of PAAs in industrial applications\\n• the conceptual framework on which PAAs are used to develop a machine language that enables prediction of future outcomes.\\n3.2 Theoretical frameworks\\nDescriptive highlights on which this framework’ s algorithm is based are as \\nfollows:\\n• A collection of literature materials explaining the concept of PAAs\\n• Relevant and applicable models used are reviewed;\\n• And simultaneously analyzing available literature material;\\nFigure 1. \\nTheoretical framework [3].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='0127d84e-948a-483a-921a-e2118d046893', embedding=None, metadata={'page_label': '107', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='107Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\n• An outcome report is compiled and;\\n• Findings are presented to relevant parties\\n• The required theoretical framework is as illustrated in Figure 1.\\n4. Scorecard\\n4.1 Description of the conceptual framework\\nA scorecard is a technique of measuring the performance of an organization in \\nits entirety rather than focusing on a particular process or component of activities, \\ntasks, and operations [4]. A balanced scorecard can be used to test the effectiveness of a program such as the ability of the program to be achieved at a reduced cost, increased efficiency, reduced efforts, and a high accuracy in producing the required outcomes. Previously, a balanced scorecard was designed to enable the assessment of the performance of companies and the extent to which its strategic decisions can be made to achieve the desired operational outcomes. It has been a relevant tool for companies in the assessment of the performance of internal processes and providing opportunities for learning and growth [5]. In spite of the perception that a balanced scorecard is used as a tool for measuring performance, it can be used in the measure-ment of other activities such as operational efficiency, effective time utilization, and the level of competitiveness of an organization in a particular industry.\\n4.2 How it works\\nA balanced scorecard (BSC) is used in deciding what a business is trying to \\nachieve, to align resources in a manner that the regular activities of a business \\nare achieved, and to create priorities for the provision of products and services to customers. It is composed of small boxes containing elements of mission, vision, core values of an organization, strategic areas of focus, and the activities in which a business will undertake to achieve continuous improvement [6].\\nBSC is primarily used by businesses, government agencies, and non-profit \\ninstitutions. The working principle of a BSC is that an organization can be viewed from a number of perspectives, which can be used to create objectives, targets, and actions in relation to various points of views. The main perspectives of a BSC are listed below .\\n• Financial performance: The performance of an organization is viewed in terms of the effectiveness of its use of financial services.\\n• Customers/stakeholder needs: The BSC measures performance in terms of the ability to meet customer expectations.\\n• Internal procedures: The performance of an organization is viewed based on the quality and efficiency of production of a particular product, service, or major business processes.\\n• Capacity of an organization: From this perspective, an organizational perfor-mance is viewed based on its ability to utilize resources, technology, human capital, and other capabilities that create an environment for the achievement of a high performance.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='ecbd264f-d770-42ed-93f0-dedcb04e85eb', embedding=None, metadata={'page_label': '108', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n1084.3 When it is used to create PAAs\\nBSC can be used during the creation of PAAs by enabling the formulation of the \\nperformance features of the algorithms. The algorithms for analyzing an organiza -\\ntion’ s performance can be analyzed using a BSC composed of capacity components \\nsuch as the ability to be produced at low cost, ease of operation by the users, reduced likelihood of breakdown, and the ability to provide accurate forecast of an organization’ s performance (Figure 2) [7].\\n4.4 Strengths and weaknesses of the model\\nThe strength of a balanced scorecard is that it provides the opportunity for \\nputting all the operations of a business into consideration. It also accounts for the \\nimpacts of different components on each other rather than examining the manner in which a particular component operates or achieves its intended goals [8]. When a BSC has been integrated into the functions of an organization, it can be used as a tool for monitoring the achievement of goals and objectives.\\nThe disadvantage of a BSC is that it focuses on the impacts in general, which \\nneglects the performance of an individual or a particular process within a set of processes. There is the possibility of perverting a scorecard by using it as a tool for monitoring employees rather than the performance of a business [9]. It also takes into account a large number of variables to constitute a practicable scorecard, mak-ing it challenging to manage.\\nIn Louisiana University College (LCU) of Engineering, a ClearPoint Strategic \\nbalanced scorecard software is used to align the activities such as enrollment, \\nFigure 2. \\nBalanced scorecard for the implementation of PAAs [7].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='e034a364-7e64-45be-8d27-8a2116073626', embedding=None, metadata={'page_label': '109', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='109Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\nassessment of students, and improvement of the infrastructure of the department \\naccording to its vision, mission, and goals. The outcomes of the balanced scorecard enabled members of the institution to understand their performances in relation to the target outcomes that need to be achieved [10]. Due to this strategic plan, there has been increased enrollment in the college and it is considered to be the fifth fast -\\nest growing college of engineering in the U.S.\\n5. Current models of designing PAAs\\n5.1 Forecasting and PAAs\\nForecasting and analytics algorithms are used to create a model of a future \\nevent. An example of a common future event forecasted in many businesses is sales volumes. PAAs are used by sales managers to compare the outputs of the algorithms with achieved results, and to discuss the variations with their representatives who examine them and make estimates [11]. Forecasting algorithms also provide sales-people with the opportunities to know when they need to communicate prospects based on changes in algorithms, which have an impact on the buying decisions of customers.\\n5.2 Statistical models\\nTime series algorithm is a common statistical model of PAAs and is categorized \\ninto frequency-based algorithms and time-domain algorithms. Frequency-domain \\nalgorithms consist of spectral and wavelength analyses, while time-domain meth-ods include algorithms used during auto-correlation and cross-correlation analyses [12]. Another commonly used statistical algorithm is the market segmentation algorithm that is extensively used in customer profiling depending on particular characteristics or priorities of a business.\\n5.3 Linear regression models\\nIn simplistic terms, linear regression algorithms are used in modeling relation-\\nships between observed (dependent) and design (independent) variables. It is \\nbased on the least squares method that fits the best line and results into the minimal sum of squared errors between the expected and actual data points. Linear regres-sion algorithms are used to make decisions such as the most suitable marketing mix to achieve optimized sales when particular investment channels are used. An example of a case where linear regression is used is at Cable Company X in the United States, where a program is used to determine the effect of variables that predict truck rolls within seven days. The variables used are downstream power, upstream power, and downstream signal-to-noise ratio [13]. The results that are statistically significant provide an insight on the interventions that need to be made to prevent truck roll.\\n5.4 Multiple regression models\\nMultiple regression analyses are used when product pricing is required across \\nan industry such as real estate pricing and marketing organizations in order to \\nestablish the impact of a campaign. It is a broader category of regressions that incorporates both linear and nonlinear regressions and uses explanatory variables to perform an analysis [14]. The main application of multiple regression algorithms ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c9f982d8-77fe-4200-8493-db8dd20e9465', embedding=None, metadata={'page_label': '110', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n110in practical situations is social science research, the analysis of the behavior of a \\ndevice, or in the insurance industry to estimate the worthiness of a claim. Multiple regression analysis was used to examine the factors that affected the outcome of a referendum in which the United Kingdom opted to leave the European Union. The research involved the application of multivariate regression analysis in which the Logistic (Logit) Model was combined with real data to determine the statistically significant factors that have an impact on the voting preference in a simultane-ous manner, in addition to the odds ratio that supports Leave or Remain [15]. The results of the multiple regressions showed that the gender of voters, age, and level of education were statistically significant factors, while country of birth was a statistically insignificant factor.\\n5.5 Multivariate regression model\\nIn multivariate regression models, the value of a single variable is predicted \\nusing a number of independent variables. It is also used in the estimation of the \\nrelationship between predictors and responses. Predictors constitute continuous, categorical, or a combination of both. Multivariate analysis measures multivariate probability distributions in the context of their impacts on the observed data [10]. An example of such a model is multivariate analysis of covariance (MANOV A), which performs the analysis of variance that covers instances where more than one variable is analyzed simultaneously. Principal component analysis (PCA) is a multivariate analysis that enables the creation of a new set of orthogonal variables containing similar data as the original set. Multivariate regression analysis has been used by DHL, a global delivery company to predict future status of global trade, in its Global Trade Barometer program. A machine-learning language is used to input collected data related to different intermediate commodities that range from clothes, bumpers, or mobile devices [16]. The program leverages artificial intel-ligence and multivariate analysis PAAs to create a single data that enables under-standing of the effects of a number of variables on a single variable. The output can be used by stakeholders to make decisions such as planning the capacity for future demands of their services and benchmarking on the forecasts to understand the industry’ s competitiveness.\\n5.6 Decision tree\\nDecision-tree algorithms are classified into supervised learning algorithms. They \\nare used to create models for solving regression and classification problems. The \\ngoal of creating a decision tree is to generate values that can be used to predict the outcomes of a particular class or target variables by applying learning decision rules derived from past data [17]. The concept of tree representation of algorithms is used to solve a problem. Corresponding attributes are used in various internal nodes of the decision tree while class label is made at the leaf node. Pouch, a British plugin company developed an artificial intelligence (AI) chatbot, which informs customers of Black Friday discounts. The bot is available to users on Facebook Messenger and uses decision-tree logic to understand people’ s preferences [18]. The decision tree enables users to search the directory according to codes such as departments and their products, brands, and voucher codes of their preferences.\\nMilwaukee-based Aurora Health Care uses the technique of decision tree in the \\ndesign of a “digital concierge, ” which operates on the principle of AI. The organiza -\\ntion has cooperated with developers from Microsoft’ s arm of healthcare innovation in the development of a tool that simplifies decision-making in relation to patient care. The concept of decision tree is applied through a chatbot program, which can ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='b9af1c46-5499-4b7c-8d95-d03db2d97bba', embedding=None, metadata={'page_label': '111', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='111Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\nbe accessed via a web browser [19]. This computer code enables mapping out symp-\\ntoms and the common descriptions used by people to describe their health issues.\\nThe input is provided through answers to a set of questions regarding the \\nsymptoms presented. The bot adapts to the answers and outputs possible causes and treatment plan suggestions. The algorithm enables the creation of a command for making a decision on whether the patient may need further clinical care by the patient clicking a section that reserves his or her place in a line at an Aurora urgent care center. The conceptual framework of the chatbot is illustrated in Figure 3.\\n6. Data management\\nTesting data quality using predictive analytics algorithm takes place through the \\ncreation of a computer model for validity and reliability of data. The resulting com-puter model is usually a Pearson correlation that explains the relationship between response and design variables [20]. In measurement of reliability, the objective is to measure the extent to which the measured value is likely to change when the research is replicated. Some computer algorithms measure reliability by performing random and systematic error analyses. Eco-Absorber is a panel acoustics com-mercializing company that uses reliability and validity algorithms to get accurate outcomes of its surveys [21]. The outcomes are used to determine the suitability of the survey findings to recommend a change in practice that addresses the 4Ps of marketing in an effective manner.\\n7. Program management implications of PAAs\\nA number of considerations must be made when applying PAAs in program \\nmanagement. Good prediction can be achieved only if there are good data such as past records, which can be used to predict future outcomes of a process or an activity. For instance, prediction of sales of an organization in the next six months is subject to the availability of historical data that, when analyzed, provide a better understanding of the trend of changes in sales [22]. Before data analysis is conducted, they must be organized to reduce redundancy and unnecessary fields must be discarded. In order to deploy the insights from predictive analysis into the systems, it is recommended that software applications should be used to integrate \\nFigure 3. \\nFramework of decision tree used by Aurora Health Care [19].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='092644b6-730b-4f38-95a3-410960e790e8', embedding=None, metadata={'page_label': '112', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n112them into predicting performances of businesses [23]. Some of the software that \\ncan be used includes API calls, predictive markup language, and web services. The reliability of PAAs algorithms is subject to the use of original data that have been prepared effectively through calculation of aggregate fields, identifying missing data, and merging a number of sources. Each component of data analysis should be analyzed independently. In case of advanced requirements, more advanced algo-rithms may be required [24].\\n8. Stages of PAA development\\nThis section explains a more streamlined and contextual version of cross indus-\\ntry standard process for data mining (CRISP-DM). It is a neutral framework that addresses data analytics from two perspectives: application and technical. It is com-monly used in predictive data analytics. As we focus on these details, it needs to be pointed out here that conducting (PDA) should never be diploid simply for the sake of expressing curiosity or flaunting one’ s knowledge of an existing problem-solving strategy. PDA is meant to solve problems. And in order to solve these problems, significant efforts are required to justify its application. One important component of such an exercise is the identification of a relevant management challenge. Hard questions need to be asked. What specifically is the issue? What are some of the interventions that have been made? How have the intervention outcomes improved or addressed the problem? And how have these interventions contributed in mitigating these problems. A combination of these questions will help significantly in redirecting and focusing intervention strategies.\\n8.1 Problem statement\\nIn this stage, the business problem that needs to be addressed should be identi-\\nfied. The objective can be to perform a forecast of the future needs or to establish \\nthe likelihood of occurrence of a particular defect. The resulting predictive algorithm should be one that promotes the attainment of the goals and objectives that have been identified [13]. Problem statement identification also involves the definition of performance metrics that a business needs to achieve. A plan should be devised that enables the measurement of the metrics when data are input into the algorithm.\\n8.2 Intervention strategies\\nThe intervention strategy involves making a decision about the right software \\nor application to use in creating algorithms for resolving a particular operational \\nprocedure in a business. The intervention strategy may be to design an algorithm that enables understanding of the breakage of devices being manufactured, the likelihood of reduction in the number of purchases, or overall change in customer satisfaction.\\n8.3 Processes\\nThe process of algorithm development will be determined by the goals to be \\nachieved and the data to be analyzed. Algorithm development is achieved by the \\nuse of machine learning and data mining methods composed of relevant analytic platforms. The process of developing an algorithm can take different shapes accord-ing to the purpose to be achieved [25] of the commonly used methods in creating ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='3b37f2e6-bc09-4468-a968-499b9bba5236', embedding=None, metadata={'page_label': '113', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='113Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\nalgorithms are the creation of computer programs that enable processing of data \\ninput to perform a number of tasks such as regression analyses or estimation of variances. The relationships between an organization’ s data sets can be amassed by the use of unsupervised clustering algorithms. The processes to be followed during the design of algorithms can be illustrated using flow charts [26]. These are charts composed of activities to be performed, decisions to be made, the arrows which show the direction of a program, and conditions that must be satisfied before a program progresses to the next stage.\\n8.4 Algorithm design\\nDuring algorithm design, the designer creates mathematical processes that \\ncan be used to solve problems. The concept used to develop algorithms is coding \\nengineering. Algorithm design and implementation are achieved by the use of design patterns or template patterns and involve the use of data structures to create programs and subprograms that can be used to derive the mathematical output from a particular data input [27]. In order to develop an algorithm, mainframe programming languages that are recommended include ALGOL, FORTRAN, PL/I, and SNOBOL. The developer of an algorithm can create hand-written processes and a set of mechanical activities to be performed by hand before creating a correspond-ing algorithm using a computer program.\\n8.5 Program development\\nDuring the program development stage, a code is written in the form of pseudo-\\ncode and logic requirements to be followed in a particular programming language. \\nVarious coding language choices can be made in relation to a programming task depending on its characteristics and usability [18]. A relevant coding language is selected and syntax rules are followed with little deviation to improve the accuracy of the program.\\n8.6 Pilot testing\\nIn this stage, the written program undergoes a debugging stage in which the \\nprogrammer identifies errors in the program. The identified errors can be syntactic \\nor logic. In addition, the programmer explores other areas that are likely to make the program not run in a proper manner or not run completely [21]. The pilot test -\\ning stage is usually lengthy and tedious and often constitutes more than 50% of the program development process. However, when there is greater attention to program design and coding, it is possible to reduce the amount of time spent in the debug -\\nging stage. Syntax errors result in difficulty of executing a program and constitute simple errors such as misspelling or failure to comply with the syntax rules to be followed in a particular programming language [12].\\n8.7 Pre-implementation testing\\nIn this testing, test data is added to the program to determine its usability in \\nproviding the required outputs. Agile testing can also be performed by following \\nthe principle of testing from the customer’ s perspectives [23]. This testing should be performed by the quality assurance (QA) team. User acceptance testing (UAT) is performed on the program to determine whether it is usable in the intended system when released. This is due to the fact that changes in software characteristics undergo changes as it is developed. The resulting changes can be misunderstood in ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='01027463-6ac2-421e-bff8-aa8f420c2901', embedding=None, metadata={'page_label': '114', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n114a fashion that is not according to the objectives of users. When UAT is completed, if \\nall requirements are met, the program is moved to production and made available to the users.\\n8.8 Final implementation\\nThe final implementation stage is where a program is used to conduct an analysis \\nof a particular data to provide an output that can be used to predict future activi-\\nties of an organization [14]. In the implementation stage, the data mined from an organization’ s database are input into the written computer program, processed (machine learning) and the resulting output is recorded and analyzed to enable prediction of a future characteristic of a program.\\n8.9 Lessons learned\\nThe programmer conducts an assessment of a written program to establish \\nwhether the expected output has been achieved. A program that results in a desired \\noutput such as the number of customers who purchase products in a particular time period and considered useful should be retained by the organization.\\n8.10 Challenges\\nA major challenge that is likely to be encountered during any programming \\nactivity is that some programmers may not use algorithms that produce the \\nexpected output. Some problems are difficult to solve because they do not have parallel codes that can be used to write their corresponding programs. Some paral-lel algorithms have complex features that make execution of programs difficult. Debugging is an important skill but most people do not have the ability to identify and correct errors due to the frustrations and difficulties encountered during this process. The design phase of a computer program can be challenging in terms of the need to think about the program requirements that need to be put together in a manner that would facilitate future updates. When program design is not effective, the resulting program can be difficult to modify in the future.\\n9. Life case studies of the use of PAAs in institutions\\nIn an attempt to simplify the conceptual complexities of PAAs, a select number \\nof themes are included with life case studies. It is my hope that such an approach will enable readers to better internalize some of what has been accomplished and relate these accomplishments to their respective and unique themes.\\n9.1 Health\\nData analytics are used extensively to predict the resource requirements for \\nhospitals. At Texas Hospital, predictive analytics algorithms have been used to \\nenable reduction of its 30-day rate of readmission due to heart failure [25]. The data used to conduct the analysis are the admission number of patients who are readmitted and those having heart failure in the past months. The most commonly used method is a computer program that can be written using Java, JavaScript, or C in which an algorithm is created to establish a regression equation that can be used to predict future readmission rates. The independent variable is the number of patients with heart failures while the dependent variable is the number of ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='5f127bb5-b950-4a55-8842-c5caad10ee8d', embedding=None, metadata={'page_label': '115', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='115Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\nreadmissions in the past months. The resulting output provides a value of regression \\nequation that can be used in combination with the current number of heart failure patients to predict future readmission rates.\\nAt the Harris Methodist Hospital outside Dallas, predictive analytics algo-\\nrithms are used to conduct scans on medical records to establish the most suit -\\nable care that can result in an improvement in patient outcomes. The algorithm accounts for a number of data characteristics such as blood pressure and the amount of glucose in blood to act as an identifier of patients who are at risk of experiencing heart failure [28]. The algorithm creates a 30-day risk score representing the likely heart failure incidence. This enables physicians to focus on patients who need to be provided with intensive care. The commonly used programming languages are Python and PHP . The risk score is determined by creating an algorithm that measures the p-value using a computer program. A particular level of significance is used to determine whether there is a likelihood of heart failure. The input variables are the amount of glucose in blood and blood pressure. The output of the analytic program is the level of significance, which may be 0.05 or any set value by the hospital. Patients whose values fall within the significance value are at risk of heart failure and effectiveness of treatment mea -\\nsures should be improved in promoting their health [29]. An algorithm is created that measures multiple regressions in which two independent variables are used; amount of glucose in blood and blood pressure. The resulting regression equation in a computer program contains the sections for input of the independent vari-ables. The program is run and a regression value provided is used to predict the possibility of heart failure in a patient.\\n9.2 Problem statement\\nIt has been necessary to determine methods of identifying patients who are \\nat risk of heart failure with less human involvement. The existence of machine \\nlanguages such as Java, Javascript, and Python has provided the opportunity for practitioners at Harris Methodist Hospital in Dallas to develop a machine learning algorithm that enables distinction of patients at risk of heart failure in order to provide them with more intensive treatment.\\n9.3 Intervention strategy\\nThe intervention includes the creation of a computer program based on machine \\nlearning languages in which the practitioners record patients’ data and calculate the \\nrelationship between the values of blood glucose level and blood pressure to heart failure. This is where a notification is provided to the practitioners when blood pres-sure or blood glucose levels reaches a particular value.\\n9.4 Process\\nThe process involved the installation of the machine learning languages into the \\nsystems at Harris Methodist Hospital, coding and testing of programs using sample \\npatient values, training the employees to use the program, and its commission for use in identifying patients at risk of heart failure.\\n9.5 Algorithm design\\nThe design of the algorithm was achieved by complying with the framework \\nshown in Figure 4.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='8194ab07-0835-4751-9392-769df03aa61c', embedding=None, metadata={'page_label': '116', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n1169.6 Pre-implementation testing\\nBefore the actual implementation of the algorithm, it is tested by adding the \\nvalue of blood pressures and blood glucose levels of patients to determine whether \\nit is able to sound an alarm when the values are higher than the maximum amounts. \\nFigure 4. \\nAlgorithm framework for testing patients at risk of heart failure [21].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='254c3fe9-5ed8-44fb-965f-fbd5a3e9327b', embedding=None, metadata={'page_label': '117', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='117Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\nThe program is also debugged by removing syntax errors and misspelled words in \\norder to improve its readability.\\n9.7 Final implementation\\nThe final implementation is the integration of the machine learning language \\nin the diagnosis of patients who are at risk of heart failure. The implementation \\ninvolves authorizing the use of the software in the organization as well as training the personnel involved in patient care to examine patients who are at risk of heart failure.\\n9.8 Lessons learned\\nMachine learning algorithms can be created to enable healthcare professionals to \\nmake accurate decisions during the diagnosis of patients such as identifying those \\nwho are at risk of heart failure. The effectiveness of the program is determined by the nature of the machine language used, the competence of the personnel, and the dedication of the staff involved in monitoring blood sugar levels and blood pressure as determinants of heart failure.\\n9.9 Challenges\\nThe major challenges that are likely to be encountered in the use of the program \\nare the lack of staff motivation, difficulty in debugging due to failure to locate errors \\nin coding, failure of organizations to allocate enough resources, and the practice of using machine learning language to diagnose patients for risks of heart failure.\\n9.10 Education\\nMany learning institutions have used predictive analytics to predict future per-\\nformances by applying past performance scores of students in their institutions. At \\nSouthern Methodist University, an associate provost has contributed to student data management practices by applying predictive analytics algorithms that combine the grades attained by students in the past years to predict their performances in the future [11].\\nThe analysis performed involves entering the raw data into the package and \\nfollowing the procedure of regression analysis. The preliminary result of the regres-sion is a regression value that is related to the current performance of the student and is a factor that enables prediction of future performance. The final outcome is a standardized coefficient that acts as a predictor of the performance of a student in future tests based on the present performance.\\n9.11 Problem statement\\nThe need to achieve an accurate prediction of the future performance of stu-\\ndents at the Southern Methodist University (based on their present performances) \\nis unquestionable. The use of a machine learning (ML) program is regarded as the most suitable approach for achieving this objective.\\n9.12 Intervention strategy\\nThe intervention strategy that has been recommended is the use of an ML \\nalgorithm that calculates the regression value for the students’ scores, which can ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='2940dc11-176d-43c8-883f-8f198486d00c', embedding=None, metadata={'page_label': '118', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n118be used to predict their performances in the next academic periods. The recom-\\nmended statistical package is GNU PSPP , which has features that enable calculation of statistical measures such as simple linear regression, multiple linear regression, cluster analysis, and reliability analysis [30].\\n9.13 Process\\nThe process involved was the installation of the GNU PSP application into the \\ncomputer system followed by the design of the machine codes that return particular \\nvalues of performance when information is input. The computer program will \\nFigure 5. \\nDesign of the algorithm for prediction of future student’s performances [10].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c3728fbb-c916-4233-9f08-e449e429fee7', embedding=None, metadata={'page_label': '119', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='119Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\nbe composed of input points and the points of making decisions regarding the \\nrequired outputs.\\n9.14 Algorithm design\\nThe design of the algorithm will take place immediately after the installation of \\nthe GNU PSP computer application. The design involves the use of computer deci-\\nsion frameworks such as the flowchart shown in Figure 5.\\n9.15 Pre-implementation testing\\nDuring the pre-implementation stage, the program is tested to determine \\nwhether there are any errors. Debugging is done to correct syntax errors and factors \\ncontributing to the failure of the program are examined. The ability of the program to be used in a particular system is tested.\\n9.16 Final implementation\\nThe program is authorized for use in predicting the future academic perfor-\\nmance of students in an institution, in which it is destined to be used [31]. The \\nstaff is trained to apply the program during the entry of students’ previous perfor-mances. They also trained on the skills of interpreting the results of the program.\\n9.17 Lessons learned\\nThe lessons learned from the program are that it is possible to design an effective \\nprogram if the desired outcome is established. The programmer also needs to have \\nthe relevant knowledge including the steps for writing a machine code containing greater details. When a program for predicting future performances is created, it provides an approximate future performance of a student so that potential low performances can be mitigated.\\n9.18 Challenges\\nThe challenges that are likely to be encountered during the design of the com-\\nputer program are the omission of particular procedures that enable analysis of \\nthe inputs to provide the accurate prediction of future outcomes. A challenge is also likely to occur in the debugging stage when the source of the error cannot be located.\\n9.19 Agriculture\\nAgDNA intends to solve the issue of excess nitrogen by implementing the PAAs \\nconcept, in which nitrogen requirements are optimally matched with site-specific \\nconditions in the field, thus reducing the likelihood of the occurrence of high amounts of nitrogen in the atmosphere. The company has integrated next-genera -\\ntion cloud computing technology and techniques for big data analysis, soil charac -\\nteristics analysis, and climate data as information that enables understanding the nature of a farming field and its suitability for crop production [32]. These inputs are then combined using the most recent precision nitrogen management (PNM) frameworks to provide a prediction of the required amounts of nitrogen. The meth-odology used is the creation of a computer program in which the characteristics of the soil are compared to the amount of nitrogen in order to determine whether ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='bec3a5ab-7f2a-4d6f-9c23-2a290c8131e0', embedding=None, metadata={'page_label': '120', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n120there is significance in the relationship. The statistical measure used in the analysis \\nis the p-value, which measures the level of significance of the relationship between various soil characteristics and the amount of nitrogen. The software used in the computation of the relationship is JavasScript, which is cloud-computing software that enables the creation of programs for regression analyses. The analysis involves the input of the amount of nitrogen and the corresponding soil characteristics such as soil type, color, moisture content, and soil texture. The preliminary results are the p-values in which the values greater than the set significance value are soil types that have higher amounts of nitrogen that need to be regulated [33].\\n9.20 Business: marketing\\nBusiness application of PAAs occurs at the New Y ork Times (NYT) as a means \\nof improving its business and operational model. Predictive analytics models have \\nbeen created that enable subscription to the organization’ s social media sites and other business decisions. According to a report by Chris Wilgins in a Predictive Analytics conference, predictive analytics is used to influence customers [10]. The NYT uses natural language processing as a means of increasing reader engagement so that the most beneficial types of articles can be sold. The software used is C program, in which an algorithm is developed that enables recognition of words such as adjectives used by customers to demonstrate their satisfaction. The software also has a subprogram, which enables the creation of a decision tree that matches the natural languages used by customers to make a particular decision. The preliminary result of the program is a tree diagram, which matches the natural language used by customers and the decisions that need to be taken to promote the sales of the NYT products.\\n9.21 Business: transportation\\nVirgin Atlantic uses predictive analytics algorithms to determine the prices of \\ntickets according to the likelihood of travel demands by customers [6]. The statisti-\\ncal packages used are either MATLAB or SPSS, which have features that enable the calculation of statistical measures such as regression analysis, multiple regression analyses, correlation analyses, and the T-test. The methodology used is the input of the raw data such as prices of tickets and the corresponding number of customers who board flights in a specified period such as a month or a year. The statistical measures conducted include regression analysis and significance analyses. The preliminary regression value is used as a measure of the relationship between independent variables (price) and the dependent variable (number of customers). A final prediction of future demand in ticket sales is established by the use of the regression coefficient to predict the likely number of customers.\\n9.22 Sports\\nA commonly used predictive analytic model in sports is Sports Performance \\nPlatform (SPP) from Microsoft, which incorporates an ML and AI in the creation \\nof algorithms used to make decisions regarding the performance of athletes. This application provides solutions for the locker room, performance lab, and has an algorithm that enables prevention of injuries, making decisions pertaining to games, and changing training schemes to improve the performances of athletes [15]. An example of a sports club that uses PAAs is Midtjylland, a Danish club that was on the brink of bankruptcy but improved to nearly winning a championship title. The club made changes to the steering approach by implementing analytical ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='f439408d-2999-4f38-a225-f06e475979f4', embedding=None, metadata={'page_label': '121', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='121Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\nprocedures in which experts conducted an analysis of each player twice a month \\nto obtain information that addressed the player’ s training needs. The experts also provided the coach with information such as when to change the game plan in accordance with the in-game statistics. Information from analytical models was used to recommend new players [34]. The programming software used for the analysis of the players was SPP . The methodology used was the creation of an algorithm that enabled input of player behaviors such as the number of passes, distances covered, number of touches of the ball, and the resulting team perfor-mance such as the number of wins, draws, and losses. The algorithm creation methodology also involved the creation of a code that measured the regression between the variables. The preliminary results were the raw player data in the computer program and the team’ s performance in the past matches. The final outcome was the regression value, which showed the relationship between each player’ s characteristics and the team’ s performance. This value is important in making decisions such as whether to substitute a player in order to improve the performance of the club.\\n9.23 Social media\\nSocial networking companies such as Facebook have been using predictive \\nanalytics algorithms that enable updates regarding a brand to be available to the \\nuser after a product has been “liked” . Therefore, users are able to see posts, which improve their engagement rates with their individual networks such as posts that their friends have engaged with [16]. The programming language used is JavaScript due to its cloud computing feature and the ability to make changes to an already existing algorithm. The methodology used is the creation of an algorithm that enables the site to link a liked product to a user’ s page. The process includes the sta -\\ntistical analysis of a decision tree in which the website is automatically coded to link a “liked” product to the user’ s page. The final outcome is a user experience in which when a person likes a product, the updates regarding the product appear on their page in the future. This implies that Facebook will promote the ability of marketers to promote social engagement with customers.\\n9.24 Manufacturing\\nIn manufacturing companies, machine-learning algorithms have been used to \\nunderstand the machine problems that are likely to be encountered in order to apply \\npreventive practices to keep the supply chain operational. At Georgia Institute of Technology, machine-learning algorithms provide the opportunity to promote forecasting the likelihood of machine failures, thus, enabling the technicians to perform maintenance practices [3]. The machine learning language used is a C program with capabilities for creating codes that enable calculation of statistical tests such as regression analyses, linear regression, and multiple regressions. The methodology used is the creation of a computer algorithm in which past intervals of failures is added. The data are the failure times (the dependent variable) and the time interval (independent variable). A sub-program is created that enables the calculation of simple regression analysis, which establishes the relationship between machine failure times and the time interval. The preliminary results are the input values of failures of the machines against time interval. The outcome of the analysis is a regression coefficient, which can be multiplied by the current failure frequency to determine the next likelihood of the machine’ s failure. This ML algorithm has been applied in the performance of regular maintenance tasks on lathes, grinders, saws, and gears (Figure 6).', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='4addbfd4-c344-4d4a-b7fd-586d9685b65e', embedding=None, metadata={'page_label': '122', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n1229.25 Government institutions\\nIn the United Kingdom (UK), the Ministry of Defense uses machine learning \\nalgorithms to explore and organize public documents. This is achieved by creating \\nalgorithms that enable the identification of documents depending on their subjects and conducts the analysis of information for the purpose of finding patterns and anomalies in data systems [25]. The algorithms are also implemented in the detec -\\ntion of fraudulent activities, transactions, or activities of any public official for personal gain. The algorithms have been effective in the detection of activities such as money laundering, the creation of counterfeit trade items or the duplication of business documents. The processes include the installation of machine learning languages into the systems of the organizations, the creation of computer programs, testing, and implementation [35]. The inputs are information regarding future activities such as the attempt to change the content of documents in order to achieve personal objectives or defraud the government. The program is capable of providing information about the perpetrators of the acts and insights on characteristics that can be used to trace them.\\n9.26 Crowdsourcing\\nBugcrowd Inc. uses crowdsourcing, in cooperation with Fortune 500 companies \\nsuch as MasterCard Incorporation, to identify vulnerabilities that may be used by \\nhackers to infringe on their infrastructure. This is achieved by the use of a machine learning language called a bug bounty program, which enables the engagement of the cybersecurity community, providing them with monetary rewards for their contribution to the resolution of the vulnerabilities [2]. A major advantage associ-ated with the company is the lack of a requirement for evaluation of claims of cyber threats using the crowd-sourced information to determine the areas of security where greater attention should be placed. Crowdsourcing also involves the use of application programming interfaces (APIs), a tool for software development that \\nFigure 6. \\nSummary of the improvements made at General Electric [3].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='9e2fcd08-e85a-423c-86da-902fe4056992', embedding=None, metadata={'page_label': '123', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='123Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\nintegrates the sourced data into the current workflows or reports of business secu-\\nrity analyses. The process involves the selection of a suitable programming language such as Python and installing it in the organization’ s system [5]. Professionals in machine code development develop machine codes that enable the recording of information from a number of sources. The output is a list of sources of information containing cybersecurity information that is usable for improving the organization’ s databases.\\n10. International development programs that use PAAs\\nFrom a geopolitical perspective, I have also included case studies on themes that \\nare universally applicable with specific emphasis on select themes that significantly contribute in making the world a better place and hence promoting a better quality of life.\\n10.1 Natural disaster programs\\nThe concept of predictive analytic algorithms has been implemented in the \\nanalysis of big data regarding past natural disasters and used to predict future \\nincidences [23]. An example of an incident that provided data for fighting natural disasters is the earthquake that occurred in Haiti in 2010. Crowdsourcing has been used to obtain real-time images of disasters such as earthquakes while big data approaches in artificial intelligence (AI) have been used to determine meanings in messages such as SMS that were generated during the occurrence of natural disasters.\\nThe processes involved the installation of machine learning language followed \\nby the creation of an algorithm that enables the performance of mathemati-cal analyses such as regression analysis and providing the output that can be interpreted to estimate the likelihood of occurrence of a similar incident such as another earthquake in the future [33]. The analytical procedures performed involve the input of information pertaining to disasters such as the magnitude of an earthquake, time of occurrence, and region into the machine language. The machine language performs an analysis of mathematical processes such as linear regression and multiple regressions to provide statistical coefficients that can be used to predict future disasters.\\n10.2 Poverty eradication program\\nPredictive analytics have been used by the World Bank (WB) in poverty eradica -\\ntion initiatives such as the collection of information of affected areas, the analysis \\nof the number of people who need relief services, and the relationship between their status with infectious diseases. This is in accordance with the WB objective of eradicating poverty by the year 2050. Countries conduct household surveys and provide WB with information used to classify the population according to the level of poverty [25].\\nThe processes involve the creation of a machine language that enables input \\nof raw data such as the economic statuses of families. Data from statistical offices in various countries are input into the machine learning language that has been designed in a customized fashion to enable the stratification of families according to their gender, age, income levels, geographical location, race, or culture. The pro-gram has commands that enable the quick calculation of statistical measures such as linear regression or multiple regressions to provide coefficients that enable the ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='d2b632d5-63c6-456b-9240-a8ab6a715f5b', embedding=None, metadata={'page_label': '124', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n124prediction of poverty levels in the future [2]. The machine learning language has \\nalso been designed in a manner that enables the transfer of data from mobile phones to the program for analysis. This program has been implemented to measure the economic status of people in Togo, Tanzania, and Tajikistan to provide outputs that enable prediction of poverty status in the future. A similar program has been used by the WB in the measurement of the movements of nomadic people in Somalia to predict future migration patterns.\\n11. Programming software\\n11.1 Turn-key programming model\\nA turn-key program (TKP) is one that is developed according to specifica -\\ntions because the owner has specified all the functional requirements. A TKP has the primary advantage of enabling the user to establish a program budget, inputs, and outputs in a scheduled manner. Turn-key programs do not provide easy flexibility in the management of changes and other features requested by the programmer.\\n11.2 In house programming model\\nIn in-house programming, a program is developed by the IT department of the \\ncompany rather than an outside company [32]. An example of in-house program-\\nming is Google’ s software development, which is done using its machines that are located in various parts of the computer network system.\\n11.3 Outsourcing programming model\\nOutsourcing programming is the process in which a computer program is writ -\\nten by a third party and generally external institutions on a consulting basis. It is a \\nmore advantageous method of programming because an organization reduces the cost of undertaking a particular project. It is also a means of ensuring time-saving in the development of computer programs because it tends to be less time-consum-ing when a number of experts are assigned to complete program development. The risks and challenges involved in outsourcing are confidentiality, limited supervi-sion, possible tardiness and service-provider loyalty.\\n12.  Programming languages, architecture development, platform, \\ninterfaces\\n12.1 Java\\nJava is a major programming language used in building server-side programs \\nfor video games and apps in mobile phones. It is also popular in the creation of \\nprograms for operation on Android-based platforms. Java incorporates both compilation and interpretation techniques [3]. Java compiler is used to convert a source code into bytes. Java Virtual Machine (JVM) performs an interpretation of the bytecode and the creation of a code that can be executed when the program is run. Java is highly recommended during the creation of web server programs, web commerce applications such as electronic trading systems, scientific applications, and enterprise databases (Figure 7).', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='76d84315-a884-49d9-a18a-ce6d2be4f834', embedding=None, metadata={'page_label': '125', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='125Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\n12.2 Python\\nPython is an object-oriented programming language that is popular due to its \\nsimple and readable syntax. It is easy to learn and uses simple language for program \\ncoding. For instance, if the computer is required to write something, the command “print” is used. Python makes use of the concept of dynamic typing, reference count -\\ning, and detection of garbage in order to facilitate memory management [11]. It uses similar expressions to other programming languages such as C and Java (Figure 8).\\n12.3 C language\\nC is a compiler program that can be used to translate functions, declarations, \\nand definitions into files that are executable. It has a simpler command procedure \\nand performs less programming tasks compared with other languages used in \\nFigure 7. \\nA mapping of Java programming language architecture [3].\\nFigure 8. Architecture of Python programming language [11].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='974f041f-2881-4cb9-9740-849b9e68a92c', embedding=None, metadata={'page_label': '126', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n126programming such as Python or Java. Executable files are created by the compiler \\ntranslating source code into executable codes independently. It does not remember the defined variables while performing file processing [2]. This implies that a vari-able cannot be used if it has undergone previous declaration in the same file. C is similar to Java in functions such as loops and conditionals, but the former is simpler in other aspects, such as the structure of data definitions (Figure 9).\\n13. Algorithm development: examples of algorithms\\n13.1 Brute force algorithms\\nBrute force algorithms enable enumeration of all integers from 1 to n and estab-\\nlish whether each number is divisible by n to obtain a whole number. With this type of algorithm, direct computation is performed based on a problem statement to be resolved and the corresponding concepts [7]. The search phase for the text can be done randomly. It is an algorithm that is commonly used in the solution of problems such as sorting, searching, and binomial expansion.\\n13.2 Simple recursive algorithm\\nA recursive (self-executing) algorithm is one that uses smaller input values \\nand applies simple operations to them in order to obtain the result. It applies the \\nprinciple of solving a problem by dividing it into smaller versions, which can then be solved by the use of recursive algorithms. If a function is represented recursively, the corresponding recursive algorithm for the computation of its members is a mir-ror of the definition.\\nFigure 9. \\nCompiler architecture of a C program [2].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='0e98174b-9d27-4cd5-98d6-59d09c08f8b3', embedding=None, metadata={'page_label': '127', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='127Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\n13.3 Backtracking algorithms\\nA backtracking algorithm is an algorithm that is used to find solutions to compu-\\ntational problems such as conditional problems. The process of programming starts \\nwith a particular move out of a number of alternatives [36]. If it is possible to reach a solution using the selected move, the solution is printed; otherwise, the program backtracks and selects another move to try.\\n13.4 Randomized algorithms\\nRandomized algorithms use the concept of randomness to determine the task \\nto be performed anywhere in the algorithm. Their preferred use is for the analysis \\nof expectation of worst cases, in which all likely values of the random variables are considered and the corresponding time by a possible value is evaluated.\\n13.5 Dynamic programming algorithms\\nDynamic programming is the process where algorithms are created for breaking \\ndown a problem into a number of sub-programs. These problems are solved just \\nonce and the result is stored so that when a similar problem occurs in the future, a solution is looked up amongst the stored solutions [7]. This basically involves creat -\\ning a program that memorizes the results of a particular state and using it to solve a sub-problem.\\n14. Highlights\\nThis chapter has reviewed and analyzed contemporary documentation pertain-\\ning to the use of PAAs, the processes involved in their development, their applica -\\ntion in the computation of mathematical procedures, such as linear regression and multiple regression, and prediction of future outcomes. The stages in which PAAs undergo until the outcome is achieved include problem statement, intervention strategy formulation, processes, algorithm design, program development, pilot testing, pre-implementation testing, the analysis of lessons learned, and examina -\\ntion of the challenges encountered.\\nThe concept of PAAs has been used in most machine-learning languages to \\ndevelop computer programs that provide an output, which enables understanding future events in healthcare, education, manufacturing, governance, and natural calamities such as earthquakes or poverty levels. In healthcare practice, it has been possible to develop a PAA that uses blood sugar levels and blood pressure to predict the patients who are at risk of heart failure so that intervention measures can be implemented. In educational institutions, PAAs have been developed that enable the input of the student’ s performance in the present period to predict future performances in various fields of specialization. In agriculture, big data PAAs have been used to formulate soil characteristics in the future based on the current char-acteristics such as soil moisture content, the amount of nitrogen in the soil, and the amount of salts. The output has been used, for example, as a guide on the measures that can be taken to reduce the amount of nitrogen in the soil. Other areas where PAAs have been used are player performance prediction in sports, sales predictions in businesses, predictions of unauthorized acts in government departments, and crowdsourcing to promote organizational cybersecurity.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='200ef46b-0d6d-4291-aef1-71992900a413', embedding=None, metadata={'page_label': '128', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n12815. Summary\\nThe euphoria created by the advent and exponential evolution of predictive \\nanalytics seems to have left many stakeholders in awe. From every level of business \\nto different institutional categories, the best and optimal performance seems to be in sight with no establishment being left behind.\\nWhile the positive outcomes achieved so far continue to escalate, institutions at \\nlarge need to take one step backwards to do some stocktaking. This process involves asking critical and provocative questions, including: Are we doing the right thing? How evidence-based are our strategies? Are they sustainable? How reliable are our data sets? Is client data adequately protected from potential cybercriminals? Have all the ethical concerns been adequately addressed? What is the gold standard?\\nIf PAAs’ dynamics are any indication, the learning curve is bound to be long, \\nsteep, and daunting. One major reason for this possibility is the growing complexi-ties of managing data and the institutions involved in processing them. There is also the challenge of establishing a diverse team of experts involved in developing problem solutions. Members of such a complementary group serve as an invaluable backbone to any potential success. The problems are complex, ranging from good quality data to the nuances that accompany risks and assumptions of selecting and applying the appropriate algorithms.\\nAs already indicated elsewhere in this chapter, good quality data is sine qua non \\nto any successful analysis (quantitative and qualitative). Mark Twain’ s characteriza -\\ntion of lies, “lies, damned lies and statistics, ” should always serve as a compelling reminder that the information generated from data through the machine learning (ML) process is only as useful as the quality of data used. Having and using the appropriate and reliable piece of information is a catalyst for making informed deci -\\nsions. PAAs are no exception! ML processes continue to gauge significant amounts of data. This data is transformed through the ML process to predictive outcomes (information) used in making informed decisions. ML’ s propensities to process big data sets have made cloud computing an inevitable requirement. The arrival of quantum computers (QC) has made the transformation process faster, reliable, and more efficient. These QCs, which have miniaturized the binary digit (bit), have moved computing to a higher level. According to an IBM definition, “Quantum computers, on the other hand, are based on qubits, which operate according to two key principles of quantum physics: superposition and entanglement. Superposition means that each qubit can represent both a 1 and a 0 at the same time. ” Access to good quality data is one way of optimizing the utilization of these QCs.\\nIn one of my series of lectures given to graduate students at the University of the \\nWest Indies in Kingston, Jamaica, a student wanted to know why program managers firmly believe that in any strategic framework — “logframe” for example — outputs (and their indicators) always contribute to outcomes, especially given the potential for misleading and unreliable results reported at the output level.\\nIn my response, I agreed with the student while elaborating on the data col-\\nlection and reporting vulnerabilities, especially in environments where very little appreciation is given to data that are subsequently converted to information. I explained the trade-offs that managers and other stakeholders are faced with. I described what it takes to address issues like these, including conducting a control study. I further shared an anecdote with the group; an experience I had conducting a program evaluation for a UN agency. In this case, the agency had spent 4.5 million dollars over a three-year period on national capacity strengthening. The partici-pants, who were medical health workers, were trained both nationally and inter-nationally. This was identified as one of the output indicators that contributed to a corresponding relevant indicator — improved quality of health services — at the ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='9306740b-bb89-4eab-a273-d0d16b1bb991', embedding=None, metadata={'page_label': '129', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='129Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\noutcome result level. During the evaluation assignment, I followed up (something \\nthat was never done after training), and as it turned out, most of those who benefit -\\nted from the training had moved on; some changed ministries, others had left the country, and some had even changed professions! Obviously, any planning deci-sions made using that training report would undoubtedly be erroneous, misleading, and deceptive at best.\\nIt is quite conceivable that the evolving, inclusive, and streamlining dynamic \\nof PAAs will continue to have positive and unquestionable consequences on how programs are managed. The myriad implications are unfathomable with synergies that collectively yield both intended and unintended outcomes. If current thematic applications are any indications, introducing analytics in any intervention will continue to be a win-win initiative.\\nWhile different institutions condition their interventions towards their respec -\\ntive strategies, the ultimate outcome is improved productivity and optimization of resource (human, financial, and material) utilization. There is also the human (quality of life) dimension that can revolutionize, reverse, and mitigate certain nuances that affect our wellbeing. For example, academic institutions now apply some models for improving student performance. By using historical data these institutions are able to identify vulnerable students, counsel them on an individual basis, and enable them to set more achievable objectives based on their academic performance with respect to the average group standing. The ultimate outcomes demonstrate counterfactuals that are obvious. And the results have been quite impressive. Some students in some cases have even encouraged themselves to become their own agents of change.\\nThere is also gradually and increasingly, an inclusive element of analytics that \\ncontinues to encourage and involve members of different community popula -\\ntions: crowdsourcing. This strategy has mushroomed and generated an astounding dynamic amongst communities. It remains to be seen to what extent the strategy will contribute to improving people’ s quality of life.\\nIn general, business institutions are ahead of the curve with marketing as one of \\nthe trailblazers. The competition remains extensive and brutal.\\nAbbreviations\\nML Machine learning\\nPAA Predictive analytics algorithms\\nSP Service provider\\nQOD Quality of data\\nGIGO garbage in garbage out\\nCU Columbia University\\nSPSS  Statistical Package for Social Sciences\\nBSC Balanced scorecard\\nLCU  Louisiana University College\\nPCA Principal component analysis\\nAI Artificial intelligence\\nQA Quality assurance\\nUAT User acceptance testing\\nPNM Precision nitrogen management\\nNYT  New Y ork Times\\nSPP Sports Performance Platform\\nUK United Kingdom\\nAPI Application programming interface', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='1246dd5f-7739-4022-9129-be93f1f24109', embedding=None, metadata={'page_label': '130', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n130Author details\\nBongs\\xa0Lainjo\\nCybermatic International, Montréal,\\xa0QC, Canada\\n* Address all correspondence to: bsuiru@icloud.comWB World Bank\\nTKP Turn-key program\\nJVM Java virtual machine\\nQC Quantum computer\\nMANOV A Multivariate analysis of covariance\\nCRISP-DM Cross industry standard process for data mining\\n© 2021 The Author(s). Licensee IntechOpen. This chapter is distributed under the terms \\nof the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='be4c1f9f-f708-4542-9185-c696a1b77146', embedding=None, metadata={'page_label': '131', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='131Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\nReferences\\n[1] Khan N, Yaqoob I, Hashem IAT, \\nInayat Z, Ali M, Kamaleldin W, et al. Big \\ndata: survey, technologies, opportunities, and challenges. The Scientific World Journal, 2014.\\n[2] Purcell BM. Big data using cloud \\ncomputing. Journal of Technology Research, 2014; 5, 1.\\n[3] Bastos P , Lopes I, Pires LCM. \\nApplication of data mining in a maintenance system for failure prediction. Safety, Reliability and Risk Analysis: Beyond the Horizon: 22nd European Safety and Reliability, 1, 2014; pp 933-940.\\n[4] Zizlavsky O. The balanced scorecard: \\nInnovative performance measurement and management control system. Journal of technology management & innovation, 2014; 9(3), pp. 210-222.\\n[5] El Deen MA, Solayman MM. \\nMaximizing Strategic Performance Results: Adopting Balanced Scorecards and BI Tools. International Journal of Computer Applications, 2015; 117(10).\\n[6] Chitra K, Subashini B. Data mining \\ntechniques and its applications in banking sector. International Journal of Emerging Technology and Advanced Engineering, 2013; 3(8), pp. 219-226.\\n[7] Gera M, Goel S. Data mining-\\ntechniques, methods and algorithms: A review on tools and their validity. International Journal of Computer Applications, 2015; 113(18).\\n[8] Awadallah EA, Allam A. A critique of \\nthe balanced scorecard as a performance measurement tool. International Journal of Business and Social Science, 2015; 6(7), pp. 91-99.\\n[9] Stefanovska L, Soklevski T. Benefits \\nof Using Balanced Scorecard in Strategic and Operational Planning. Universal Journal of Management, 2014; 2(4), pp. 165-171.\\n[10] Soumya SB, Deepika N. Data \\nMining With Predictive Analytics for Financial Applications. International Journal of Scientific Engineering and Applied Science, 2016; 1, pp. 310-317.\\n[11] Mishra N, Silakari S. Predictive \\nanalytics: a survey, trends, applications, oppurtunities & challenges. International Journal of Computer Science and Information Technologies, 2012; 3(3), pp. 4434-4438.\\n[12] Padhy N, Panigrahi R. Data Mining: \\nA prediction Technique for the workers in the PR Department of Orissa (Block and Panchayat). arXiv preprint arXiv:1211.5724. 2012\\n[13] Mandal SK. Performance Analysis \\nOf Data Mining Algorithms For Breast Cancer Cell Detection Using Naïve Bayes, Logistic Regression and Decision Tree. International Journal Of Engineering And Computer Science, 2017; 6(2).\\n[14] Hassani H, Silva ES. Forecasting \\nwith big data: A review . Annals of Data Science, 2015; 2(1), pp. 5-19.\\n[15] Razali N, Mustapha A, Yatim FA, Ab \\nAziz R. Predicting Player Position for Talent Identification in Association Football. In IOP Conference Series: Materials Science and Engineering, 2017, IOP Publishing, Vol. 226, No. 1, p. 012087.\\n[16] Pippal S, Batra L, Krishna A, \\nGupta H, Arora K. Data mining in social networking sites: A social media mining approach to generate effective business strategies. International Journal of Innovations & Advancement in Computer Science, 2014; 3(1).\\n[17] Thomas EH, Galambos N. What \\nsatisfies students? Mining ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='cf135870-20a3-4313-956d-e6654660852b', embedding=None, metadata={'page_label': '132', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Machine Learning - Algorithms, Models and Applications\\n132student-opinion data with regression \\nand decision tree analysis. Research in Higher Education, 2004; 45(3), pp. 251-269.\\n[18] Semenov A, Romov P , Korolev S, \\nYashkov D, Neklyudov K. Performance of machine learning algorithms in predicting game outcome from drafts in dota 2. In International Conference on Analysis of Images, Social Networks and Texts 2016; Springer, Cham. pp. 26-37.\\n[19] Anderson. Framework of decision \\ntree used by Aurora Health Care. 2018\\n[20] Bhargava N, Sharma G, Bhargava R, \\nMathuria M. Decision tree analysis on j48 algorithm for data mining. Proceedings of International Journal of Advanced Research in Computer Science and Software Engineering, 2013; 3(6).\\n[21] Obermeyer Z, Emanuel EJ. \\nPredicting the future—big data, machine learning, and clinical medicine. The New England journal of medicine, 2016; 375(13), p.1216.\\n[22] Perry C. Machine learning and \\nconflict prediction: a use case; 2013.\\n[23] Danjuma K, Osofisan AO. \\nEvaluation of predictive data mining algorithms in Erythemato-Squamous disease diagnosis. arXiv preprint arXiv:1501.00607. 2015\\n[24] Ganas S. Data mining and predictive \\nmodeling with Excel 2007. In Casualty Actuarial Society E-Forum, Spring 2010. 2009\\n[25] Vijayan V , Ravikumar A. Study of \\ndata mining algorithms for prediction and diagnosis of diabetes mellitus. International journal of computer applications, 2014; 95(17).\\n[26] Yadav SK, Pal S. Data mining: A \\nprediction for performance improvement of engineering students using classification. arXiv preprint arXiv:1203.3832. 2012\\n[27] Kinkade N, Jolla L, Lim K. Dota 2 \\nwin prediction. Technical Report. tech. rep., University of California San Diego. 2015.\\n[28] Alkhatib M, Talaei-Khoei A, \\nGhapanchi A. Analysis of research in healthcare data analytics. arXiv preprint arXiv:1606.01354. 2016\\n[29] Milovic B, Milovic M. Prediction \\nand decision making in health care using data mining. Kuwait Chapter of the Arabian Journal of Business and Management Review , 2012; 1(12), p. 126.\\n[30] Thakar P . Performance analysis and \\nprediction in educational data mining: A research travelogue. arXiv preprint arXiv:1509.05176. 2015\\n[31] Karkhanis SP , Dumbre SS. A Study \\nof Application of Data Mining and Analytics in Education Domain. International Journal of Computer Applications, 2015; 120(22).\\n[32] Kaur M, Gulati H, Kundra H. Data \\nmining in Agriculture on crop price prediction: Techniques and Applications. International Journal of Computer Applications, 2014; 99(12), pp. 1-2.\\n[33] Arumugam A. A predictive \\nmodeling approach for improving paddy crop productivity using data mining techniques. Turkish Journal of Electrical Engineering & Computer Sciences, 2017; 25(6), pp. 4777-4787.\\n[34] Maszczyk A, Gołaś A, \\nPietraszewski P , Roczniok R, Zając A, Stanula A. Application of neural and regression models in sports results prediction. Procedia-Social and Behavioral Sciences, 117, 482-487. 2014\\n[35] Assunção MD, Calheiros RN, \\nBianchi S, Netto MA, Buyya, R. Big Data ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='16d53c94-2da1-4769-b57c-ced4036f2b78', embedding=None, metadata={'page_label': '133', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='133Enhancing Program Management with Predictive Analytics Algorithms (PAAs)\\nDOI: http://dx.doi.org/10.5772/intechopen.98758\\ncomputing and clouds: Trends and \\nfuture directions. Journal of Parallel and Distributed Computing, 79, 3-15. 2015\\n[36] Suarjaya IMAD. A new algorithm \\nfor data compression optimization. arXiv preprint arXiv:1209.1045. 2012', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='03d15ba5-55e3-4905-ab4e-22c22b19434b', embedding=None, metadata={'page_label': '134', 'file_name': 'Machine Learning Author Jaydip Sen.pdf', 'file_path': '/content/sample_data/test/Machine Learning Author Jaydip Sen.pdf', 'file_type': 'application/pdf', 'file_size': 4225754, 'creation_date': '2024-09-22', 'last_modified_date': '2024-09-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='IntechOpen Series  \\nArtificial Intelligence, Volume 7\\nMachine Learning  \\nAlgorithms, Models and Applications\\nEdited by Jaydip SenEdited by Jaydip Sen\\nRecent times are witnessing rapid development in machine learning algorithm systems, \\nespecially in reinforcement learning, natural language processing, computer and \\nrobot vision, image processing, speech, and emotional processing and understanding. \\nIn tune with the increasing importance and relevance of machine learning models, \\nalgorithms, and their applications, and with the emergence of more innovative \\nuses–cases of deep learning and artificial intelligence, the current volume presents \\na few innovative research works and their applications in real-world, such as stock \\ntrading, medical and healthcare systems, and software automation. The chapters in \\nthe book illustrate how machine learning and deep learning algorithms and models are \\ndesigned, optimized, and deployed. The volume will be useful for advanced graduate \\nand doctoral students, researchers, faculty members of universities, practicing data \\nscientists and data engineers, professionals, and consultants working on the broad \\nareas of machine learning, deep learning, and artificial intelligence.\\nPublished in London, UK  \\n© 2021 IntechOpen \\n© your_photo / iStockISBN 978-1-83969-484-4Andries Engelbrecht, Artificial Intelligence Series Editor\\nISSN  2633-1403Machine Learning - Algorithms, Models and Applications\\nISBN 978-1-83969-486-8', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
          ]
        }
      ],
      "source": [
        "documents=SimpleDirectoryReader(input_dir=\"/content/sample_data/test/\").load_data()\n",
        "print(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2g7M89fKg54H"
      },
      "outputs": [],
      "source": [
        "system_prompt=\"\"\"\n",
        "You are a Q&A assistant. Your goal is to answer questions as\n",
        "accurately as possible based on the instructions and context provided.\n",
        "\"\"\"\n",
        "## Default format supportable by LLama2\n",
        "query_wrapper_prompt=SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5-mOhoIhfo0",
        "outputId": "5f70e70f-27b2-4881-d37a-70911c095762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2pAn8fTySVw",
        "outputId": "78bfc9e8-9cfa-487a-b951-04d631150e97"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z6B3MPMyVR9",
        "outputId": "94b3f644-dcc7-40e4-e8e9-fe5ef1681f9e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFBDQjPSy4Tc",
        "outputId": "9cd35d5d-2774-413e-c78e-e00d3b96af89"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3unpb4oAK3gu",
        "outputId": "10eb1b3c-ae12-4f56-878f-604b48d8020e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", torch_dtype=torch.float16, low_cpu_mem_usage = True).cpu()\n",
        "from accelerate import disk_offload\n",
        "disk_offload(model=model, offload_dir=\"offload\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834,
          "referenced_widgets": [
            "9842b9c33e1448028e8ec4d73401bee8",
            "6397ff0c44e0401ca6441738ee407d32",
            "800c4a0eec50494bacc2d963777fdc65",
            "7ab93d3985a14d73887881346bc3386e",
            "7d92b1fb9552413a93fae58d1f7931b9",
            "a45553f863dd444f8ab14569cef8cbdf",
            "95e35bcd9868488099bafb8a39533573",
            "1c6f9914156246ec85124a9a3237f4d6",
            "74c441f0b9ff43debd000e0a1c367c60",
            "ed9df090981e40f0a549648331a6051f",
            "90396b96abe14664b7301c0ca2750d9c",
            "884c418b1f5f4289a21f5aef2bcfc4f1",
            "8331a117bbe94d18bdc4de761112823b",
            "688d1315750046839026c08292f7eef9",
            "a92c5b70420b4058a35cf99b733c2bcc",
            "e9c6c4a405404d208fb6d6efe1a896f1",
            "16806a6dc7504638a36df5c959fff6df",
            "467aff81f5d4406590d287b0a4b6f050",
            "109e7d267037417eb9d1cd62dc418162",
            "d888adfb18df4f40acf4baa63704793d",
            "970c95bf3245464ea661e1789a3acd9a",
            "fd46cb1bce8f4fd5888af6671d484ec1",
            "ce8f59737b64400bac262c7637111d07",
            "99c226f1b4cd4224b8433a859d35c0c2",
            "90542e7f3e174516bb28e59c80be63f5",
            "9bd3be5c615b4c6eb89b9932469d1598",
            "bfaec5ca65354abf98a3a6692493e5b1",
            "d3c8d8ee16194a5a9f2634a8f5d97924",
            "828baab081394f82b35c0c5dc55f6f04",
            "4f18d88547424b84b98c82dede980a06",
            "09ff3a2f7b2240af8e3c925b45eb1b06",
            "edc0460bfff140b79d50ce5bb9b6c71f",
            "203476089d644161b2015142f3898e32",
            "a10a50e8c47442c3987cbb91341c9968",
            "e08eecd80abd412899cf5647748c6d82",
            "8d3233a1bfaa4160a32597e97b9784b9",
            "663434cd1a1545d4a130de703af4774f",
            "e907881593064dfea93b1c5823da7ec5",
            "1598a645b7f7468699791aaf2769f0a1",
            "3dce50a02d6a453785c419c466587194",
            "7304f69e6b5b40c6804e175399130edd",
            "18ad3f5402f44f12aa42c797e6213472",
            "2466adadccbf4d20844ded8ef4842a8e",
            "efb9f8731f104e34895b24bde3a54bea",
            "8f24a8da04104454975984f8765d2f1e",
            "f197d9c9189d44b78078a3d35d423a01",
            "073870f0a8b542d4b8f31b5aeae96336",
            "d0399eff9eb3406faf7d4ebd9dbbf2ad",
            "9e9a36fda01c46f39620574202041dd9",
            "3ff4a53138844703a13b0f48b6b36279",
            "7c30ddfbd2d9481d9c0cee5776f744cc",
            "498b40401d1843aaa7307f7d20f43303",
            "415e9f4f7f034e0182aaa24f59435a3f",
            "f6e34929d7434f5c89a78c98bd1b4d0a",
            "59c8fbb3f795471cb4030d3590fef96b",
            "d5c1693f52d0439babd57e7220156e39",
            "e8b6e5381cf14f6e9cdc51ca143f52fd",
            "c5632f992f7749b7a16909963c332d2a",
            "eb17c45d03914cc3899417e413bfdd39",
            "024c31a00e7b4504a1e002398d438b2c",
            "681a1311d00f4f6fa92e7758b9588bbc",
            "6f8d42fd698c4fe8ac410287acdd6641",
            "82938928e6734340858f39dbed32e891",
            "47f919b0f3074ab9bc07f2a73070011a",
            "15df4af0ecb04634b188706b6dc523fe",
            "c79a4794502c42c592db53d53a68c09c",
            "3dfeab3553cb4c53aa51395af2522eec",
            "29c7a52f2e1c482da2466c421678429c",
            "cba8c8a3ec724928a5e72f5741a12d34",
            "5c31b969457a48d487da6dbd20bbf863",
            "eb34f0a76413480db2fbd0a3802ae6d9",
            "35da8eb997bc4ed4b2890b5839ed56a3",
            "fc1cbbbda23a4812a986824d1ce509c5",
            "e7d532eae9854024a9fbe90ed1069b39",
            "900fedabe17642b4808fb3a8d95c82de",
            "bfd992fe153444ce899037213cae66a7",
            "e63834ff7c174d8ea3ec3f03973f1aba"
          ]
        },
        "id": "UnFdgA5mKP_q",
        "outputId": "8f4b5e14-bedc-4130-e7c4-576cca87db82"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9842b9c33e1448028e8ec4d73401bee8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "884c418b1f5f4289a21f5aef2bcfc4f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce8f59737b64400bac262c7637111d07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a10a50e8c47442c3987cbb91341c9968"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f24a8da04104454975984f8765d2f1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5c1693f52d0439babd57e7220156e39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dfeab3553cb4c53aa51395af2522eec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(32000, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaSdpaAttention(\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
              "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
              "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jyVOhSuhhqdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "0c2e794b45934209a199d1f378ac9eb1",
            "fce09d5a858b46a7bab699e66a803018",
            "2b7e6cfef2e24d85a085daeaf5604ffe",
            "b067f6e3d6364992a3d7d9760dcada06",
            "ccc2e3984a094137b284a55bf56f4ce1",
            "0c3f54e7d5ff4912b9c2f8a07087ea75",
            "64696a42de4643f483455d79b00d8bdf",
            "3e676c802031469a9442154cd6acaaa0",
            "b472daaf1fa746c8b0e9199eefd2bee5",
            "1232e610564e45f7b9d30cf414c33ab2",
            "120a9410253149c7bbeb8464dba7f003",
            "515ad11f94714b3e81df8cb0a1bdaa1a",
            "02b6287cc03e4142a0a811051200e10a",
            "78ee0190efa74e0aa7ebac154d939b7c",
            "864150aed65c42b3933a0325eb6fcb93",
            "447de69667ed4d3d863d7aabe26dcf55",
            "6ee0422bdc934af39ecb39dad6c3aaed",
            "c74bafd5536b465a823a5b243f0f8713",
            "f652d0b4a47845b5be76c5be9bbff4f4",
            "338e65983bcc463291ace47e5c15b7ee",
            "1611b995012441208c38758faa2bd7ac",
            "96bf49fa7985456aacf716e20ac79ea4",
            "e2ccec81195d48da91026387c25e79ca",
            "e6238eb55d3641eb91796730bef7275a",
            "db7c06046e5c43559df16e4bc7d7480d",
            "4bbdc5fc13204a41bf8c239707443125",
            "e3933e61141e4e5889d4dd6e9fc51022",
            "14a42caa04b04f85a3a749e549124ece",
            "5d7f0e85868840688d2a8e658f32daba",
            "e6dd385e159441d3a1b4de6593ef16a5",
            "c526698c0b4a424497df65f6ce552d42",
            "52011ecef8944d99914eade3f3c65176",
            "369d6c702c194a9ea01fafc410305ba6",
            "504de912655f4c1980fe6325fbd810a1",
            "15ddd4f7b06a44bd9420040133679471",
            "cc4975aca6474a41b16b9beac0ec5a9f",
            "4fb0ee296e3745bc8851ab0334012f80",
            "c492a78e51564be28be245f95f942485",
            "1b15a44c248e464daf09b011ebdd11ab",
            "189791793bd5435ebdc5727c43c52e1c",
            "9501b62a68404eecac2ce40cbea52f46",
            "62b0337162c54b4f9b4a065c93c341b3",
            "1d0e81336b024a1e8b3c8d38e89ce756",
            "409e1e0be17447c78c54504ca7e8a25f",
            "6f037418ba9e49d98e8e06dfc35788e3",
            "7835c6a745f444249075819a7ee3d3a7",
            "95720d9707fb4a5e98546178fa7a0e7b",
            "2b01f1d99b764ab296a2278dff3ca262",
            "9656da5b64094bcd9d3cb0037bd12752",
            "04e2a96b42d64f1490aa3d26138ffe93",
            "bd515d2f01c146cca876add2a73f2a39",
            "2508155d983644b995f66ae761da5291",
            "22a4c8d71ac446859bcea6b7f55102da",
            "14db39b88dc740f9b04cf4ba09893bfa",
            "078db7fbba474c539a82d37383784a96"
          ]
        },
        "outputId": "b6eae8c1-ad03-482b-b5fe-3de72cff3f5c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c2e794b45934209a199d1f378ac9eb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "515ad11f94714b3e81df8cb0a1bdaa1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2ccec81195d48da91026387c25e79ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "504de912655f4c1980fe6325fbd810a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f037418ba9e49d98e8e06dfc35788e3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=256,\n",
        "    generate_kwargs={\"temperature\": 0.1, \"do_sample\": True},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    device_map=\"auto\"\n",
        "    # uncomment this if using CUDA to reduce memory usage\n",
        "   # model_kwargs={\"torch_dtype\": torch.float16 , \"load_in_8bit\":True}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "duqWuWgfcwiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef9a1e1-180d-4a36-b1d4-bbc6b9a69628"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.125)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (3.10.7)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, pydantic-settings, langchain-community\n",
            "Successfully installed langchain-community-0.3.0 pydantic-settings-2.5.2 python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index.embeddings.langchain\n",
        "!pip install llama_index.embeddings.LangchainEmbedding"
      ],
      "metadata": {
        "id": "I53i_0wxdJVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52d79b8-48ef-4fc3-c65d-a37029e942a6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index.embeddings.langchain\n",
            "  Downloading llama_index_embeddings_langchain-0.2.1-py3-none-any.whl.metadata (612 bytes)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.embeddings.langchain) (0.11.11)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (3.3)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (3.1.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (3.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (24.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.embeddings.langchain) (1.2.2)\n",
            "Downloading llama_index_embeddings_langchain-0.2.1-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: llama_index.embeddings.langchain\n",
            "Successfully installed llama_index.embeddings.langchain-0.2.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement llama_index.embeddings.LangchainEmbedding (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for llama_index.embeddings.LangchainEmbedding\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "pr1EN5sViQm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528,
          "referenced_widgets": [
            "8134746eefbb46c9841289fa43546aea",
            "f0e0deae5988490781e43b6c12180b73",
            "ddd44efae5fc4e24b1ea0292d55d7454",
            "2fcf6d5cf39e4fbeae1ac1e8f33a7332",
            "bb9a0123be29488cb09c0340ed7853a6",
            "4a0763bf214841b2a679ce91ebbb91e9",
            "3b6750424e6b41c8ba5325bcd5212bdd",
            "e0111a6caa0f4cedb6f2c2ca3f987d2c",
            "0376391de42d413a93b1a44a439e24ad",
            "17e3823273204930a8205bbfba158851",
            "559de8da3b4945ae8f72f301ae1765c6",
            "c875c41ffaa144e0b8e60ede7cd3e187",
            "7f4cfe319a214c67a48c3357f556d091",
            "ae77088d8c784f6b94d9caee62bb9969",
            "62e2dfdf851c41799e387a0675898fe9",
            "4a7c36d5a76e4f9e955fdf6c6e3ddaf8",
            "5a99d93be8f24206b3c8844a0d57eb4d",
            "cb27002488844527a031cb31977b45b4",
            "abcb921188c448979b70834164a2ad71",
            "8731cce90a694bd3a41383d23324b71f",
            "14c82fb94c8d4b598d6a66cc8da9bc2c",
            "3bc10aab23024cb0b0bc277e09305653",
            "dab6a83cde734e4bb2db4e6f71d12477",
            "9530884bd2d4423a8d5ac6b4b58ca5a0",
            "8472b0a5ca5b42d88dc8512d778db52c",
            "912ccc4945f7404fb3ea1a69ec5f8c48",
            "2a7e4c0b464e4721b9e749498f153364",
            "011c940967c84243b4195a763633b517",
            "a2926427916042ada963719a4e8e2a9d",
            "39dffa6bb6cd4a0686517e8c4571c896",
            "2359099f1cdb424d8d7646cb0a84125b",
            "9b9a6f8a53d34e0889c365ba621b690f",
            "ee59772a83434eb9ab6c99a5c60136c2",
            "9188b3417eb1460ca143601e53e9dbd5",
            "f2853ad7db5d48e18e13130818746330",
            "679fb016bbab438bbe48564c9db87e20",
            "d1c24b7243084b9e8c65e2a48350cd6d",
            "ba5e8817840a4359b4e2663155661d35",
            "22f9ca76c4734f50bf19a265374216db",
            "3b8eb98a942840a98c6667d0bd7fedd3",
            "1f979b7d82b84a3fa6bce3ffc8657cbf",
            "16d1e82f05b9486d83bd30febb401bb6",
            "8918c78e65544ab2a11ef87ac65dca0a",
            "164ff0b527d94f718a271bc735dbd487",
            "c48c32b17d064caaa30c2ab35573d941",
            "855a97c56eee4a25ae3a787871ba70e5",
            "1ef5c57f36514be9bf8d1f16565c692b",
            "1537737bb66848bb9cfcec21d1f09f7c",
            "7fc2759e442c454a8a68064f99223700",
            "b13694a023e845e987cee15e5dd0f052",
            "83fdbc1844564b1f87db7875be67d852",
            "32e870943c314f3d9a8cebee091b8bae",
            "f275e873467a4d90a48f95f761e9072b",
            "cb5c1ede6ab34ea69d439601228ea068",
            "c013d85ff43b4493a7867d80d8e65f18",
            "cc73517ced114fe8b9e7204a1aa7ea19",
            "bf78a8450b134229a200f1ef5e8f7c22",
            "76367abdd53945c0bc083f182b0eff81",
            "c2bc78cc2ae44488bd3d0f444ed857bb",
            "7de971c43a0849eba64234414ecd407e",
            "c47091e512b4447a995ecd7405def4cd",
            "3e1ce740b10e43b9b9f6415ccda3294e",
            "11ab2b86601a40eca23c18d0ab78e664",
            "92a275a0aeac4fbbb147238fc8290648",
            "42578a813366426f9661265312df1f58",
            "8fca9e3bdfa246ddb78042c3bcb93b57",
            "720f106599624d00b958beb2c59501e9",
            "bd3b430db9f44cbba240576c3711c1e7",
            "90dc179a15ca46af9eb66922e9be1bac",
            "1f4e57522f8b402987d63556b1473e77",
            "d42d18a825e440e399526b77d9d9a8ab",
            "7fb551dd08474f6ab3559c4021f96364",
            "a9035280e80540d0b8a285331fbd6d36",
            "5f4ee1e9a56e44ac8a5eb8977c32fb3e",
            "fb42d69bb51a4d41854ec3c49dd3d2ea",
            "2c55ab15ae504ac39f53c934386f9066",
            "7dfad4f78d94428e9501abeedac58979",
            "05da4c1a724c459388a2e66f4c012b88",
            "35901c27604e440fb79fa2e37f15fba9",
            "96fd290abb4f46a1bba7b090dc52fb69",
            "b65e6a0fcf984a1ea76f99b9e14d0229",
            "7f7c7621defa4c579e03b6a8f4046037",
            "3903071f5f9046aeaa6659e6125d51da",
            "7906760bd5f148bda8d1cf8e609657ad",
            "4b0736dfe0d54016830c5af399a52c2e",
            "624459130e944ead92440309b278c3c6",
            "85f33f2a5e1e48a2a44f3a9a3f366029",
            "279e1297859b495baa374c6554ff959f",
            "12d44a39bb7743829e384f6b6c659787",
            "923413ff468e4738bf37d4ca4b5fb025",
            "4e94aecc09564f67b4f2aacb55c0ec9d",
            "0ea0fcab40884005a14ac25aaa866d7f",
            "b29b338ef87a491f85c66fbdc4b0c710",
            "b152aa8abe094f07854ae2f5c1317514",
            "18d29f3d0afb4c6f9cc69d2cb5d054b1",
            "99213e8c91354b13a90c7d028dd49f88",
            "b43bab3f3f264f94b595bba364935d99",
            "1b00873f66b5455eb730de033736a1df",
            "253087b8f0f94f67b84a11a8b64466f2",
            "1d3a3a60904d48c9ac696034ae8da5ae",
            "2d9d1b73f75c4a6e87f56bf4f03db550",
            "299515682ebb4241a62f29adcf86c3df",
            "610b6a26a71145ee81f2dd1452d45be4",
            "93c29339947a4c39b201609c565cd7c8",
            "ae3193c6a6f345a585eeeca5f969e9f3",
            "62b63b7d47fa4ae8857c4d264f225927",
            "29a814dc93d44c68b44b9a42db901aa1",
            "2be15ffac1374b4fbece47501094e4f3",
            "bb9c1e93f17748b48eae0269da06c9be",
            "4a795eb6a5e74308af9d18d0e5be4bf3",
            "43ed7e43eea74a6dbd140bfc7a67c01b",
            "77e925e61596431a9cd4d2459bd5c34c",
            "fa0997cbfd49420391d6c1e796290206",
            "af5f744f47f34a5293de310386ec0dd5",
            "07c21e95961c470cad0448ddbef0b9b4",
            "4ae65f69e73b4418b5fc93cb733547e5",
            "13342a159e204ff2be8c69a6269a58a3",
            "28d003abd3104ff18038915478dac9d9",
            "32683b2ff7544a4ea8e93c81e0f4db33",
            "b52aaef2006240bfa8f8c6e4f07de285",
            "f72c8dc824324ecc9d8a124713a256ac"
          ]
        },
        "outputId": "97edc3bb-bda0-4047-f465-2c2bb5b5b31f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "<ipython-input-36-c8a8502900c9>:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8134746eefbb46c9841289fa43546aea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c875c41ffaa144e0b8e60ede7cd3e187"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dab6a83cde734e4bb2db4e6f71d12477"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9188b3417eb1460ca143601e53e9dbd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c48c32b17d064caaa30c2ab35573d941"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc73517ced114fe8b9e7204a1aa7ea19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "720f106599624d00b958beb2c59501e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05da4c1a724c459388a2e66f4c012b88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12d44a39bb7743829e384f6b6c659787"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d3a3a60904d48c9ac696034ae8da5ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43ed7e43eea74a6dbd140bfc7a67c01b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from llama_index.core import ServiceContext\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "\n",
        "embed_model=LangchainEmbedding(\n",
        "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "LduiJD2ajpy4"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.chunk_size = 512\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "\n",
        "#service_context=ServiceContext.from_defaults(\n",
        " #   chunk_size=1024,\n",
        "  #  llm=llm,\n",
        "   # embed_model=embed_model\n",
        "#)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex"
      ],
      "metadata": {
        "id": "zY1uBxvrNZB6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'secretkey'"
      ],
      "metadata": {
        "id": "Em7Qe01zqS4d"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "31jvrW2BkFEL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "71f99db0fa9e44f783db86e0805544c4",
            "02045d9563b64cc393392d9b6e91ff2e",
            "cc0249ed1b3e49b49d4fe6c1a0d6353b",
            "955f617cd5d74fc0b0d0a25f4ae9b93e",
            "1dec27b1ffda4dcc8e462492fbcd548b",
            "66184610e094425f89ba80372e18fb26",
            "4b6d5d8854ad43fc8b9d7fa826a4d640",
            "833973e3e7dd4ddb93ad53b9ba228999",
            "a6c450f0e0814c19b9edec7c898edc20",
            "e91d8eac9363436092b07b8891439fe9",
            "c5d32d9840904558937630c1d037b26c",
            "acbb2e25e9c34e44be9221972893d3a1",
            "a1b1e23757114f569586b6ed665ecf45",
            "9ac011ce926842638f69658055814808",
            "61e674d92de447bfb4bb1def9ddc5a39",
            "3c434deb432b4ba2ae1f7a1d4545f437",
            "919b0ca2c284491685fed69dd312f975",
            "efad4941b1884730b1a8a6c402d99c32",
            "a2e8cac3557d423ca2480179ebe5ed6e",
            "6bb886e20f2f49488482e44c3abc2c5b",
            "c3a99b6e646842f98631de0489e67445",
            "6c17b84321a14263bb5a7ce9cb078577"
          ]
        },
        "outputId": "f7ea8a32-bce8-4df3-a490-448ca2c80c9c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/154 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71f99db0fa9e44f783db86e0805544c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/162 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acbb2e25e9c34e44be9221972893d3a1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "index=VectorStoreIndex.from_documents(documents,show_progress = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "XmRABVvym2xq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "IM-gNZ0-kRnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "166280b6-4e28-4a2c-d26f-fb47453f28d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x7a6c05b5fca0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "uSJzrMm6kTxf"
      },
      "outputs": [],
      "source": [
        "query_engine=index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "expandable_segments:True"
      ],
      "metadata": {
        "id": "SxKAmId6WsiI"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
      ],
      "metadata": {
        "id": "ewTzpje-YuvL"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "PdhKFWCTkZRx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "db7988be-8746-4783-de96-991259c3dada"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 13.06 MiB is free. Process 10057 has 14.73 GiB memory in use. Of the allocated memory 14.17 GiB is allocated by PyTorch, and 454.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-227a83ede52a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"what is data science?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m             )\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpanDropEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/base/base_query_engine.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mstr_or_query_bundle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueryBundle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         dispatcher.event(\n\u001b[1;32m     54\u001b[0m             \u001b[0mQueryEndEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m             )\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpanDropEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/query_engine/retriever_query_engine.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    176\u001b[0m         ) as query_event:\n\u001b[1;32m    177\u001b[0m             \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             response = self._response_synthesizer.synthesize(\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m             )\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpanDropEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/response_synthesizers/base.py\u001b[0m in \u001b[0;36msynthesize\u001b[0;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mEventPayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUERY_STR\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         ) as event:\n\u001b[0;32m--> 241\u001b[0;31m             response_str = self.get_response(\n\u001b[0m\u001b[1;32m    242\u001b[0m                 \u001b[0mquery_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 text_chunks=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m             )\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpanDropEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/response_synthesizers/compact_and_refine.py\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# the refine template does not account for size of previous answer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mnew_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_compact_text_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         return super().get_response(\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mquery_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mtext_chunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m             )\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpanDropEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/response_synthesizers/refine.py\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# if this is the first chunk, and text chunk already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;31m# is an answer, then return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 response = self._give_response_single(\n\u001b[0m\u001b[1;32m    178\u001b[0m                     \u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mresponse_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/response_synthesizers/refine.py\u001b[0m in \u001b[0;36m_give_response_single\u001b[0;34m(self, query_str, text_chunk, **response_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     structured_response = cast(\n\u001b[1;32m    233\u001b[0m                         \u001b[0mStructuredRefineResponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                         program(\n\u001b[0m\u001b[1;32m    235\u001b[0m                             \u001b[0mcontext_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_text_chunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             \u001b[0;34m**\u001b[0m\u001b[0mresponse_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m             )\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpanDropEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/response_synthesizers/refine.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             answer = self._llm.predict(\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m             )\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpanDropEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/llms/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mformatted_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprompt_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mparsed_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m             )\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpanDropEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/llms/callbacks.py\u001b[0m in \u001b[0;36mwrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                 )\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m                     \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                     callback_manager.on_event_end(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/llms/huggingface/base.py\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(self, prompt, formatted, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         tokens = self._model.generate(\n\u001b[0m\u001b[1;32m    365\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m             \u001b[0;31m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2025\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2982\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynced_gpus\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mreturn_legacy_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2265\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2267\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 13.06 MiB is free. Process 10057 has 14.73 GiB memory in use. Of the allocated memory 14.17 GiB is allocated by PyTorch, and 454.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "response=query_engine.query(\"what is data science?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "XKsLsgWSkfGD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "5029d2a9-13e7-46ef-e6f5-2922a27514c8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'response' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-ef8b248111bc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHLOq8j2kyfF"
      },
      "outputs": [],
      "source": [
        "response=query_engine.query(\"what is machine learning?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmWD4LdFk7zI"
      },
      "outputs": [],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJLTVLkelCRA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9842b9c33e1448028e8ec4d73401bee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6397ff0c44e0401ca6441738ee407d32",
              "IPY_MODEL_800c4a0eec50494bacc2d963777fdc65",
              "IPY_MODEL_7ab93d3985a14d73887881346bc3386e"
            ],
            "layout": "IPY_MODEL_7d92b1fb9552413a93fae58d1f7931b9"
          }
        },
        "6397ff0c44e0401ca6441738ee407d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a45553f863dd444f8ab14569cef8cbdf",
            "placeholder": "​",
            "style": "IPY_MODEL_95e35bcd9868488099bafb8a39533573",
            "value": "config.json: 100%"
          }
        },
        "800c4a0eec50494bacc2d963777fdc65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c6f9914156246ec85124a9a3237f4d6",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74c441f0b9ff43debd000e0a1c367c60",
            "value": 614
          }
        },
        "7ab93d3985a14d73887881346bc3386e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed9df090981e40f0a549648331a6051f",
            "placeholder": "​",
            "style": "IPY_MODEL_90396b96abe14664b7301c0ca2750d9c",
            "value": " 614/614 [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "7d92b1fb9552413a93fae58d1f7931b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a45553f863dd444f8ab14569cef8cbdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e35bcd9868488099bafb8a39533573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c6f9914156246ec85124a9a3237f4d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74c441f0b9ff43debd000e0a1c367c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed9df090981e40f0a549648331a6051f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90396b96abe14664b7301c0ca2750d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "884c418b1f5f4289a21f5aef2bcfc4f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8331a117bbe94d18bdc4de761112823b",
              "IPY_MODEL_688d1315750046839026c08292f7eef9",
              "IPY_MODEL_a92c5b70420b4058a35cf99b733c2bcc"
            ],
            "layout": "IPY_MODEL_e9c6c4a405404d208fb6d6efe1a896f1"
          }
        },
        "8331a117bbe94d18bdc4de761112823b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16806a6dc7504638a36df5c959fff6df",
            "placeholder": "​",
            "style": "IPY_MODEL_467aff81f5d4406590d287b0a4b6f050",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "688d1315750046839026c08292f7eef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_109e7d267037417eb9d1cd62dc418162",
            "max": 26788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d888adfb18df4f40acf4baa63704793d",
            "value": 26788
          }
        },
        "a92c5b70420b4058a35cf99b733c2bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_970c95bf3245464ea661e1789a3acd9a",
            "placeholder": "​",
            "style": "IPY_MODEL_fd46cb1bce8f4fd5888af6671d484ec1",
            "value": " 26.8k/26.8k [00:00&lt;00:00, 718kB/s]"
          }
        },
        "e9c6c4a405404d208fb6d6efe1a896f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16806a6dc7504638a36df5c959fff6df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "467aff81f5d4406590d287b0a4b6f050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "109e7d267037417eb9d1cd62dc418162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d888adfb18df4f40acf4baa63704793d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "970c95bf3245464ea661e1789a3acd9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd46cb1bce8f4fd5888af6671d484ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce8f59737b64400bac262c7637111d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99c226f1b4cd4224b8433a859d35c0c2",
              "IPY_MODEL_90542e7f3e174516bb28e59c80be63f5",
              "IPY_MODEL_9bd3be5c615b4c6eb89b9932469d1598"
            ],
            "layout": "IPY_MODEL_bfaec5ca65354abf98a3a6692493e5b1"
          }
        },
        "99c226f1b4cd4224b8433a859d35c0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3c8d8ee16194a5a9f2634a8f5d97924",
            "placeholder": "​",
            "style": "IPY_MODEL_828baab081394f82b35c0c5dc55f6f04",
            "value": "Downloading shards: 100%"
          }
        },
        "90542e7f3e174516bb28e59c80be63f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f18d88547424b84b98c82dede980a06",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09ff3a2f7b2240af8e3c925b45eb1b06",
            "value": 2
          }
        },
        "9bd3be5c615b4c6eb89b9932469d1598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edc0460bfff140b79d50ce5bb9b6c71f",
            "placeholder": "​",
            "style": "IPY_MODEL_203476089d644161b2015142f3898e32",
            "value": " 2/2 [01:15&lt;00:00, 33.76s/it]"
          }
        },
        "bfaec5ca65354abf98a3a6692493e5b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c8d8ee16194a5a9f2634a8f5d97924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "828baab081394f82b35c0c5dc55f6f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f18d88547424b84b98c82dede980a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09ff3a2f7b2240af8e3c925b45eb1b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edc0460bfff140b79d50ce5bb9b6c71f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "203476089d644161b2015142f3898e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a10a50e8c47442c3987cbb91341c9968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e08eecd80abd412899cf5647748c6d82",
              "IPY_MODEL_8d3233a1bfaa4160a32597e97b9784b9",
              "IPY_MODEL_663434cd1a1545d4a130de703af4774f"
            ],
            "layout": "IPY_MODEL_e907881593064dfea93b1c5823da7ec5"
          }
        },
        "e08eecd80abd412899cf5647748c6d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1598a645b7f7468699791aaf2769f0a1",
            "placeholder": "​",
            "style": "IPY_MODEL_3dce50a02d6a453785c419c466587194",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "8d3233a1bfaa4160a32597e97b9784b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7304f69e6b5b40c6804e175399130edd",
            "max": 9976576152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18ad3f5402f44f12aa42c797e6213472",
            "value": 9976576152
          }
        },
        "663434cd1a1545d4a130de703af4774f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2466adadccbf4d20844ded8ef4842a8e",
            "placeholder": "​",
            "style": "IPY_MODEL_efb9f8731f104e34895b24bde3a54bea",
            "value": " 9.98G/9.98G [01:01&lt;00:00, 140MB/s]"
          }
        },
        "e907881593064dfea93b1c5823da7ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1598a645b7f7468699791aaf2769f0a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dce50a02d6a453785c419c466587194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7304f69e6b5b40c6804e175399130edd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ad3f5402f44f12aa42c797e6213472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2466adadccbf4d20844ded8ef4842a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efb9f8731f104e34895b24bde3a54bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f24a8da04104454975984f8765d2f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f197d9c9189d44b78078a3d35d423a01",
              "IPY_MODEL_073870f0a8b542d4b8f31b5aeae96336",
              "IPY_MODEL_d0399eff9eb3406faf7d4ebd9dbbf2ad"
            ],
            "layout": "IPY_MODEL_9e9a36fda01c46f39620574202041dd9"
          }
        },
        "f197d9c9189d44b78078a3d35d423a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ff4a53138844703a13b0f48b6b36279",
            "placeholder": "​",
            "style": "IPY_MODEL_7c30ddfbd2d9481d9c0cee5776f744cc",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "073870f0a8b542d4b8f31b5aeae96336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_498b40401d1843aaa7307f7d20f43303",
            "max": 3500296424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_415e9f4f7f034e0182aaa24f59435a3f",
            "value": 3500296424
          }
        },
        "d0399eff9eb3406faf7d4ebd9dbbf2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6e34929d7434f5c89a78c98bd1b4d0a",
            "placeholder": "​",
            "style": "IPY_MODEL_59c8fbb3f795471cb4030d3590fef96b",
            "value": " 3.50G/3.50G [00:14&lt;00:00, 249MB/s]"
          }
        },
        "9e9a36fda01c46f39620574202041dd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ff4a53138844703a13b0f48b6b36279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c30ddfbd2d9481d9c0cee5776f744cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "498b40401d1843aaa7307f7d20f43303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "415e9f4f7f034e0182aaa24f59435a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6e34929d7434f5c89a78c98bd1b4d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c8fbb3f795471cb4030d3590fef96b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5c1693f52d0439babd57e7220156e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8b6e5381cf14f6e9cdc51ca143f52fd",
              "IPY_MODEL_c5632f992f7749b7a16909963c332d2a",
              "IPY_MODEL_eb17c45d03914cc3899417e413bfdd39"
            ],
            "layout": "IPY_MODEL_024c31a00e7b4504a1e002398d438b2c"
          }
        },
        "e8b6e5381cf14f6e9cdc51ca143f52fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_681a1311d00f4f6fa92e7758b9588bbc",
            "placeholder": "​",
            "style": "IPY_MODEL_6f8d42fd698c4fe8ac410287acdd6641",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c5632f992f7749b7a16909963c332d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82938928e6734340858f39dbed32e891",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47f919b0f3074ab9bc07f2a73070011a",
            "value": 2
          }
        },
        "eb17c45d03914cc3899417e413bfdd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15df4af0ecb04634b188706b6dc523fe",
            "placeholder": "​",
            "style": "IPY_MODEL_c79a4794502c42c592db53d53a68c09c",
            "value": " 2/2 [00:01&lt;00:00,  1.77it/s]"
          }
        },
        "024c31a00e7b4504a1e002398d438b2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "681a1311d00f4f6fa92e7758b9588bbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f8d42fd698c4fe8ac410287acdd6641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82938928e6734340858f39dbed32e891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47f919b0f3074ab9bc07f2a73070011a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15df4af0ecb04634b188706b6dc523fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c79a4794502c42c592db53d53a68c09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dfeab3553cb4c53aa51395af2522eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29c7a52f2e1c482da2466c421678429c",
              "IPY_MODEL_cba8c8a3ec724928a5e72f5741a12d34",
              "IPY_MODEL_5c31b969457a48d487da6dbd20bbf863"
            ],
            "layout": "IPY_MODEL_eb34f0a76413480db2fbd0a3802ae6d9"
          }
        },
        "29c7a52f2e1c482da2466c421678429c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35da8eb997bc4ed4b2890b5839ed56a3",
            "placeholder": "​",
            "style": "IPY_MODEL_fc1cbbbda23a4812a986824d1ce509c5",
            "value": "generation_config.json: 100%"
          }
        },
        "cba8c8a3ec724928a5e72f5741a12d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7d532eae9854024a9fbe90ed1069b39",
            "max": 188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_900fedabe17642b4808fb3a8d95c82de",
            "value": 188
          }
        },
        "5c31b969457a48d487da6dbd20bbf863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfd992fe153444ce899037213cae66a7",
            "placeholder": "​",
            "style": "IPY_MODEL_e63834ff7c174d8ea3ec3f03973f1aba",
            "value": " 188/188 [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "eb34f0a76413480db2fbd0a3802ae6d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35da8eb997bc4ed4b2890b5839ed56a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc1cbbbda23a4812a986824d1ce509c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7d532eae9854024a9fbe90ed1069b39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "900fedabe17642b4808fb3a8d95c82de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfd992fe153444ce899037213cae66a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e63834ff7c174d8ea3ec3f03973f1aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c2e794b45934209a199d1f378ac9eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fce09d5a858b46a7bab699e66a803018",
              "IPY_MODEL_2b7e6cfef2e24d85a085daeaf5604ffe",
              "IPY_MODEL_b067f6e3d6364992a3d7d9760dcada06"
            ],
            "layout": "IPY_MODEL_ccc2e3984a094137b284a55bf56f4ce1"
          }
        },
        "fce09d5a858b46a7bab699e66a803018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c3f54e7d5ff4912b9c2f8a07087ea75",
            "placeholder": "​",
            "style": "IPY_MODEL_64696a42de4643f483455d79b00d8bdf",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2b7e6cfef2e24d85a085daeaf5604ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e676c802031469a9442154cd6acaaa0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b472daaf1fa746c8b0e9199eefd2bee5",
            "value": 2
          }
        },
        "b067f6e3d6364992a3d7d9760dcada06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1232e610564e45f7b9d30cf414c33ab2",
            "placeholder": "​",
            "style": "IPY_MODEL_120a9410253149c7bbeb8464dba7f003",
            "value": " 2/2 [01:00&lt;00:00, 27.79s/it]"
          }
        },
        "ccc2e3984a094137b284a55bf56f4ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c3f54e7d5ff4912b9c2f8a07087ea75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64696a42de4643f483455d79b00d8bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e676c802031469a9442154cd6acaaa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b472daaf1fa746c8b0e9199eefd2bee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1232e610564e45f7b9d30cf414c33ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "120a9410253149c7bbeb8464dba7f003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "515ad11f94714b3e81df8cb0a1bdaa1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02b6287cc03e4142a0a811051200e10a",
              "IPY_MODEL_78ee0190efa74e0aa7ebac154d939b7c",
              "IPY_MODEL_864150aed65c42b3933a0325eb6fcb93"
            ],
            "layout": "IPY_MODEL_447de69667ed4d3d863d7aabe26dcf55"
          }
        },
        "02b6287cc03e4142a0a811051200e10a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ee0422bdc934af39ecb39dad6c3aaed",
            "placeholder": "​",
            "style": "IPY_MODEL_c74bafd5536b465a823a5b243f0f8713",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "78ee0190efa74e0aa7ebac154d939b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f652d0b4a47845b5be76c5be9bbff4f4",
            "max": 1618,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_338e65983bcc463291ace47e5c15b7ee",
            "value": 1618
          }
        },
        "864150aed65c42b3933a0325eb6fcb93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1611b995012441208c38758faa2bd7ac",
            "placeholder": "​",
            "style": "IPY_MODEL_96bf49fa7985456aacf716e20ac79ea4",
            "value": " 1.62k/1.62k [00:00&lt;00:00, 115kB/s]"
          }
        },
        "447de69667ed4d3d863d7aabe26dcf55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ee0422bdc934af39ecb39dad6c3aaed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c74bafd5536b465a823a5b243f0f8713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f652d0b4a47845b5be76c5be9bbff4f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "338e65983bcc463291ace47e5c15b7ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1611b995012441208c38758faa2bd7ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96bf49fa7985456aacf716e20ac79ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2ccec81195d48da91026387c25e79ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6238eb55d3641eb91796730bef7275a",
              "IPY_MODEL_db7c06046e5c43559df16e4bc7d7480d",
              "IPY_MODEL_4bbdc5fc13204a41bf8c239707443125"
            ],
            "layout": "IPY_MODEL_e3933e61141e4e5889d4dd6e9fc51022"
          }
        },
        "e6238eb55d3641eb91796730bef7275a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14a42caa04b04f85a3a749e549124ece",
            "placeholder": "​",
            "style": "IPY_MODEL_5d7f0e85868840688d2a8e658f32daba",
            "value": "tokenizer.model: 100%"
          }
        },
        "db7c06046e5c43559df16e4bc7d7480d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6dd385e159441d3a1b4de6593ef16a5",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c526698c0b4a424497df65f6ce552d42",
            "value": 499723
          }
        },
        "4bbdc5fc13204a41bf8c239707443125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52011ecef8944d99914eade3f3c65176",
            "placeholder": "​",
            "style": "IPY_MODEL_369d6c702c194a9ea01fafc410305ba6",
            "value": " 500k/500k [00:00&lt;00:00, 26.6MB/s]"
          }
        },
        "e3933e61141e4e5889d4dd6e9fc51022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14a42caa04b04f85a3a749e549124ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d7f0e85868840688d2a8e658f32daba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6dd385e159441d3a1b4de6593ef16a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c526698c0b4a424497df65f6ce552d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52011ecef8944d99914eade3f3c65176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "369d6c702c194a9ea01fafc410305ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "504de912655f4c1980fe6325fbd810a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15ddd4f7b06a44bd9420040133679471",
              "IPY_MODEL_cc4975aca6474a41b16b9beac0ec5a9f",
              "IPY_MODEL_4fb0ee296e3745bc8851ab0334012f80"
            ],
            "layout": "IPY_MODEL_c492a78e51564be28be245f95f942485"
          }
        },
        "15ddd4f7b06a44bd9420040133679471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b15a44c248e464daf09b011ebdd11ab",
            "placeholder": "​",
            "style": "IPY_MODEL_189791793bd5435ebdc5727c43c52e1c",
            "value": "tokenizer.json: 100%"
          }
        },
        "cc4975aca6474a41b16b9beac0ec5a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9501b62a68404eecac2ce40cbea52f46",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62b0337162c54b4f9b4a065c93c341b3",
            "value": 1842767
          }
        },
        "4fb0ee296e3745bc8851ab0334012f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d0e81336b024a1e8b3c8d38e89ce756",
            "placeholder": "​",
            "style": "IPY_MODEL_409e1e0be17447c78c54504ca7e8a25f",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 5.69MB/s]"
          }
        },
        "c492a78e51564be28be245f95f942485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b15a44c248e464daf09b011ebdd11ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "189791793bd5435ebdc5727c43c52e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9501b62a68404eecac2ce40cbea52f46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62b0337162c54b4f9b4a065c93c341b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d0e81336b024a1e8b3c8d38e89ce756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "409e1e0be17447c78c54504ca7e8a25f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f037418ba9e49d98e8e06dfc35788e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7835c6a745f444249075819a7ee3d3a7",
              "IPY_MODEL_95720d9707fb4a5e98546178fa7a0e7b",
              "IPY_MODEL_2b01f1d99b764ab296a2278dff3ca262"
            ],
            "layout": "IPY_MODEL_9656da5b64094bcd9d3cb0037bd12752"
          }
        },
        "7835c6a745f444249075819a7ee3d3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04e2a96b42d64f1490aa3d26138ffe93",
            "placeholder": "​",
            "style": "IPY_MODEL_bd515d2f01c146cca876add2a73f2a39",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "95720d9707fb4a5e98546178fa7a0e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2508155d983644b995f66ae761da5291",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22a4c8d71ac446859bcea6b7f55102da",
            "value": 414
          }
        },
        "2b01f1d99b764ab296a2278dff3ca262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14db39b88dc740f9b04cf4ba09893bfa",
            "placeholder": "​",
            "style": "IPY_MODEL_078db7fbba474c539a82d37383784a96",
            "value": " 414/414 [00:00&lt;00:00, 30.8kB/s]"
          }
        },
        "9656da5b64094bcd9d3cb0037bd12752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04e2a96b42d64f1490aa3d26138ffe93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd515d2f01c146cca876add2a73f2a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2508155d983644b995f66ae761da5291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22a4c8d71ac446859bcea6b7f55102da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14db39b88dc740f9b04cf4ba09893bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "078db7fbba474c539a82d37383784a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8134746eefbb46c9841289fa43546aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0e0deae5988490781e43b6c12180b73",
              "IPY_MODEL_ddd44efae5fc4e24b1ea0292d55d7454",
              "IPY_MODEL_2fcf6d5cf39e4fbeae1ac1e8f33a7332"
            ],
            "layout": "IPY_MODEL_bb9a0123be29488cb09c0340ed7853a6"
          }
        },
        "f0e0deae5988490781e43b6c12180b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a0763bf214841b2a679ce91ebbb91e9",
            "placeholder": "​",
            "style": "IPY_MODEL_3b6750424e6b41c8ba5325bcd5212bdd",
            "value": "modules.json: 100%"
          }
        },
        "ddd44efae5fc4e24b1ea0292d55d7454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0111a6caa0f4cedb6f2c2ca3f987d2c",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0376391de42d413a93b1a44a439e24ad",
            "value": 349
          }
        },
        "2fcf6d5cf39e4fbeae1ac1e8f33a7332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17e3823273204930a8205bbfba158851",
            "placeholder": "​",
            "style": "IPY_MODEL_559de8da3b4945ae8f72f301ae1765c6",
            "value": " 349/349 [00:00&lt;00:00, 9.34kB/s]"
          }
        },
        "bb9a0123be29488cb09c0340ed7853a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a0763bf214841b2a679ce91ebbb91e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b6750424e6b41c8ba5325bcd5212bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0111a6caa0f4cedb6f2c2ca3f987d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0376391de42d413a93b1a44a439e24ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17e3823273204930a8205bbfba158851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "559de8da3b4945ae8f72f301ae1765c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c875c41ffaa144e0b8e60ede7cd3e187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f4cfe319a214c67a48c3357f556d091",
              "IPY_MODEL_ae77088d8c784f6b94d9caee62bb9969",
              "IPY_MODEL_62e2dfdf851c41799e387a0675898fe9"
            ],
            "layout": "IPY_MODEL_4a7c36d5a76e4f9e955fdf6c6e3ddaf8"
          }
        },
        "7f4cfe319a214c67a48c3357f556d091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a99d93be8f24206b3c8844a0d57eb4d",
            "placeholder": "​",
            "style": "IPY_MODEL_cb27002488844527a031cb31977b45b4",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "ae77088d8c784f6b94d9caee62bb9969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abcb921188c448979b70834164a2ad71",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8731cce90a694bd3a41383d23324b71f",
            "value": 116
          }
        },
        "62e2dfdf851c41799e387a0675898fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14c82fb94c8d4b598d6a66cc8da9bc2c",
            "placeholder": "​",
            "style": "IPY_MODEL_3bc10aab23024cb0b0bc277e09305653",
            "value": " 116/116 [00:00&lt;00:00, 4.23kB/s]"
          }
        },
        "4a7c36d5a76e4f9e955fdf6c6e3ddaf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a99d93be8f24206b3c8844a0d57eb4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb27002488844527a031cb31977b45b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abcb921188c448979b70834164a2ad71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8731cce90a694bd3a41383d23324b71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14c82fb94c8d4b598d6a66cc8da9bc2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bc10aab23024cb0b0bc277e09305653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dab6a83cde734e4bb2db4e6f71d12477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9530884bd2d4423a8d5ac6b4b58ca5a0",
              "IPY_MODEL_8472b0a5ca5b42d88dc8512d778db52c",
              "IPY_MODEL_912ccc4945f7404fb3ea1a69ec5f8c48"
            ],
            "layout": "IPY_MODEL_2a7e4c0b464e4721b9e749498f153364"
          }
        },
        "9530884bd2d4423a8d5ac6b4b58ca5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_011c940967c84243b4195a763633b517",
            "placeholder": "​",
            "style": "IPY_MODEL_a2926427916042ada963719a4e8e2a9d",
            "value": "README.md: 100%"
          }
        },
        "8472b0a5ca5b42d88dc8512d778db52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39dffa6bb6cd4a0686517e8c4571c896",
            "max": 10621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2359099f1cdb424d8d7646cb0a84125b",
            "value": 10621
          }
        },
        "912ccc4945f7404fb3ea1a69ec5f8c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b9a6f8a53d34e0889c365ba621b690f",
            "placeholder": "​",
            "style": "IPY_MODEL_ee59772a83434eb9ab6c99a5c60136c2",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 262kB/s]"
          }
        },
        "2a7e4c0b464e4721b9e749498f153364": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "011c940967c84243b4195a763633b517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2926427916042ada963719a4e8e2a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39dffa6bb6cd4a0686517e8c4571c896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2359099f1cdb424d8d7646cb0a84125b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b9a6f8a53d34e0889c365ba621b690f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee59772a83434eb9ab6c99a5c60136c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9188b3417eb1460ca143601e53e9dbd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2853ad7db5d48e18e13130818746330",
              "IPY_MODEL_679fb016bbab438bbe48564c9db87e20",
              "IPY_MODEL_d1c24b7243084b9e8c65e2a48350cd6d"
            ],
            "layout": "IPY_MODEL_ba5e8817840a4359b4e2663155661d35"
          }
        },
        "f2853ad7db5d48e18e13130818746330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22f9ca76c4734f50bf19a265374216db",
            "placeholder": "​",
            "style": "IPY_MODEL_3b8eb98a942840a98c6667d0bd7fedd3",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "679fb016bbab438bbe48564c9db87e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f979b7d82b84a3fa6bce3ffc8657cbf",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16d1e82f05b9486d83bd30febb401bb6",
            "value": 53
          }
        },
        "d1c24b7243084b9e8c65e2a48350cd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8918c78e65544ab2a11ef87ac65dca0a",
            "placeholder": "​",
            "style": "IPY_MODEL_164ff0b527d94f718a271bc735dbd487",
            "value": " 53.0/53.0 [00:00&lt;00:00, 1.10kB/s]"
          }
        },
        "ba5e8817840a4359b4e2663155661d35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f9ca76c4734f50bf19a265374216db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b8eb98a942840a98c6667d0bd7fedd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f979b7d82b84a3fa6bce3ffc8657cbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d1e82f05b9486d83bd30febb401bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8918c78e65544ab2a11ef87ac65dca0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "164ff0b527d94f718a271bc735dbd487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c48c32b17d064caaa30c2ab35573d941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_855a97c56eee4a25ae3a787871ba70e5",
              "IPY_MODEL_1ef5c57f36514be9bf8d1f16565c692b",
              "IPY_MODEL_1537737bb66848bb9cfcec21d1f09f7c"
            ],
            "layout": "IPY_MODEL_7fc2759e442c454a8a68064f99223700"
          }
        },
        "855a97c56eee4a25ae3a787871ba70e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b13694a023e845e987cee15e5dd0f052",
            "placeholder": "​",
            "style": "IPY_MODEL_83fdbc1844564b1f87db7875be67d852",
            "value": "config.json: 100%"
          }
        },
        "1ef5c57f36514be9bf8d1f16565c692b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32e870943c314f3d9a8cebee091b8bae",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f275e873467a4d90a48f95f761e9072b",
            "value": 571
          }
        },
        "1537737bb66848bb9cfcec21d1f09f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb5c1ede6ab34ea69d439601228ea068",
            "placeholder": "​",
            "style": "IPY_MODEL_c013d85ff43b4493a7867d80d8e65f18",
            "value": " 571/571 [00:00&lt;00:00, 14.6kB/s]"
          }
        },
        "7fc2759e442c454a8a68064f99223700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b13694a023e845e987cee15e5dd0f052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83fdbc1844564b1f87db7875be67d852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32e870943c314f3d9a8cebee091b8bae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f275e873467a4d90a48f95f761e9072b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb5c1ede6ab34ea69d439601228ea068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c013d85ff43b4493a7867d80d8e65f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc73517ced114fe8b9e7204a1aa7ea19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf78a8450b134229a200f1ef5e8f7c22",
              "IPY_MODEL_76367abdd53945c0bc083f182b0eff81",
              "IPY_MODEL_c2bc78cc2ae44488bd3d0f444ed857bb"
            ],
            "layout": "IPY_MODEL_7de971c43a0849eba64234414ecd407e"
          }
        },
        "bf78a8450b134229a200f1ef5e8f7c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c47091e512b4447a995ecd7405def4cd",
            "placeholder": "​",
            "style": "IPY_MODEL_3e1ce740b10e43b9b9f6415ccda3294e",
            "value": "model.safetensors: 100%"
          }
        },
        "76367abdd53945c0bc083f182b0eff81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11ab2b86601a40eca23c18d0ab78e664",
            "max": 437971872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92a275a0aeac4fbbb147238fc8290648",
            "value": 437971872
          }
        },
        "c2bc78cc2ae44488bd3d0f444ed857bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42578a813366426f9661265312df1f58",
            "placeholder": "​",
            "style": "IPY_MODEL_8fca9e3bdfa246ddb78042c3bcb93b57",
            "value": " 438M/438M [00:03&lt;00:00, 213MB/s]"
          }
        },
        "7de971c43a0849eba64234414ecd407e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c47091e512b4447a995ecd7405def4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e1ce740b10e43b9b9f6415ccda3294e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11ab2b86601a40eca23c18d0ab78e664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a275a0aeac4fbbb147238fc8290648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42578a813366426f9661265312df1f58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fca9e3bdfa246ddb78042c3bcb93b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "720f106599624d00b958beb2c59501e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd3b430db9f44cbba240576c3711c1e7",
              "IPY_MODEL_90dc179a15ca46af9eb66922e9be1bac",
              "IPY_MODEL_1f4e57522f8b402987d63556b1473e77"
            ],
            "layout": "IPY_MODEL_d42d18a825e440e399526b77d9d9a8ab"
          }
        },
        "bd3b430db9f44cbba240576c3711c1e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fb551dd08474f6ab3559c4021f96364",
            "placeholder": "​",
            "style": "IPY_MODEL_a9035280e80540d0b8a285331fbd6d36",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "90dc179a15ca46af9eb66922e9be1bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f4ee1e9a56e44ac8a5eb8977c32fb3e",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb42d69bb51a4d41854ec3c49dd3d2ea",
            "value": 363
          }
        },
        "1f4e57522f8b402987d63556b1473e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c55ab15ae504ac39f53c934386f9066",
            "placeholder": "​",
            "style": "IPY_MODEL_7dfad4f78d94428e9501abeedac58979",
            "value": " 363/363 [00:00&lt;00:00, 18.4kB/s]"
          }
        },
        "d42d18a825e440e399526b77d9d9a8ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb551dd08474f6ab3559c4021f96364": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9035280e80540d0b8a285331fbd6d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f4ee1e9a56e44ac8a5eb8977c32fb3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb42d69bb51a4d41854ec3c49dd3d2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c55ab15ae504ac39f53c934386f9066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dfad4f78d94428e9501abeedac58979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05da4c1a724c459388a2e66f4c012b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35901c27604e440fb79fa2e37f15fba9",
              "IPY_MODEL_96fd290abb4f46a1bba7b090dc52fb69",
              "IPY_MODEL_b65e6a0fcf984a1ea76f99b9e14d0229"
            ],
            "layout": "IPY_MODEL_7f7c7621defa4c579e03b6a8f4046037"
          }
        },
        "35901c27604e440fb79fa2e37f15fba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3903071f5f9046aeaa6659e6125d51da",
            "placeholder": "​",
            "style": "IPY_MODEL_7906760bd5f148bda8d1cf8e609657ad",
            "value": "vocab.txt: 100%"
          }
        },
        "96fd290abb4f46a1bba7b090dc52fb69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b0736dfe0d54016830c5af399a52c2e",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_624459130e944ead92440309b278c3c6",
            "value": 231536
          }
        },
        "b65e6a0fcf984a1ea76f99b9e14d0229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85f33f2a5e1e48a2a44f3a9a3f366029",
            "placeholder": "​",
            "style": "IPY_MODEL_279e1297859b495baa374c6554ff959f",
            "value": " 232k/232k [00:00&lt;00:00, 1.76MB/s]"
          }
        },
        "7f7c7621defa4c579e03b6a8f4046037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3903071f5f9046aeaa6659e6125d51da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7906760bd5f148bda8d1cf8e609657ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b0736dfe0d54016830c5af399a52c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624459130e944ead92440309b278c3c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85f33f2a5e1e48a2a44f3a9a3f366029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "279e1297859b495baa374c6554ff959f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12d44a39bb7743829e384f6b6c659787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_923413ff468e4738bf37d4ca4b5fb025",
              "IPY_MODEL_4e94aecc09564f67b4f2aacb55c0ec9d",
              "IPY_MODEL_0ea0fcab40884005a14ac25aaa866d7f"
            ],
            "layout": "IPY_MODEL_b29b338ef87a491f85c66fbdc4b0c710"
          }
        },
        "923413ff468e4738bf37d4ca4b5fb025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b152aa8abe094f07854ae2f5c1317514",
            "placeholder": "​",
            "style": "IPY_MODEL_18d29f3d0afb4c6f9cc69d2cb5d054b1",
            "value": "tokenizer.json: 100%"
          }
        },
        "4e94aecc09564f67b4f2aacb55c0ec9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99213e8c91354b13a90c7d028dd49f88",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b43bab3f3f264f94b595bba364935d99",
            "value": 466021
          }
        },
        "0ea0fcab40884005a14ac25aaa866d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b00873f66b5455eb730de033736a1df",
            "placeholder": "​",
            "style": "IPY_MODEL_253087b8f0f94f67b84a11a8b64466f2",
            "value": " 466k/466k [00:00&lt;00:00, 2.38MB/s]"
          }
        },
        "b29b338ef87a491f85c66fbdc4b0c710": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b152aa8abe094f07854ae2f5c1317514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18d29f3d0afb4c6f9cc69d2cb5d054b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99213e8c91354b13a90c7d028dd49f88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b43bab3f3f264f94b595bba364935d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b00873f66b5455eb730de033736a1df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253087b8f0f94f67b84a11a8b64466f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d3a3a60904d48c9ac696034ae8da5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d9d1b73f75c4a6e87f56bf4f03db550",
              "IPY_MODEL_299515682ebb4241a62f29adcf86c3df",
              "IPY_MODEL_610b6a26a71145ee81f2dd1452d45be4"
            ],
            "layout": "IPY_MODEL_93c29339947a4c39b201609c565cd7c8"
          }
        },
        "2d9d1b73f75c4a6e87f56bf4f03db550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae3193c6a6f345a585eeeca5f969e9f3",
            "placeholder": "​",
            "style": "IPY_MODEL_62b63b7d47fa4ae8857c4d264f225927",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "299515682ebb4241a62f29adcf86c3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29a814dc93d44c68b44b9a42db901aa1",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2be15ffac1374b4fbece47501094e4f3",
            "value": 239
          }
        },
        "610b6a26a71145ee81f2dd1452d45be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb9c1e93f17748b48eae0269da06c9be",
            "placeholder": "​",
            "style": "IPY_MODEL_4a795eb6a5e74308af9d18d0e5be4bf3",
            "value": " 239/239 [00:00&lt;00:00, 18.2kB/s]"
          }
        },
        "93c29339947a4c39b201609c565cd7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae3193c6a6f345a585eeeca5f969e9f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62b63b7d47fa4ae8857c4d264f225927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29a814dc93d44c68b44b9a42db901aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2be15ffac1374b4fbece47501094e4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb9c1e93f17748b48eae0269da06c9be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a795eb6a5e74308af9d18d0e5be4bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43ed7e43eea74a6dbd140bfc7a67c01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77e925e61596431a9cd4d2459bd5c34c",
              "IPY_MODEL_fa0997cbfd49420391d6c1e796290206",
              "IPY_MODEL_af5f744f47f34a5293de310386ec0dd5"
            ],
            "layout": "IPY_MODEL_07c21e95961c470cad0448ddbef0b9b4"
          }
        },
        "77e925e61596431a9cd4d2459bd5c34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ae65f69e73b4418b5fc93cb733547e5",
            "placeholder": "​",
            "style": "IPY_MODEL_13342a159e204ff2be8c69a6269a58a3",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "fa0997cbfd49420391d6c1e796290206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28d003abd3104ff18038915478dac9d9",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32683b2ff7544a4ea8e93c81e0f4db33",
            "value": 190
          }
        },
        "af5f744f47f34a5293de310386ec0dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b52aaef2006240bfa8f8c6e4f07de285",
            "placeholder": "​",
            "style": "IPY_MODEL_f72c8dc824324ecc9d8a124713a256ac",
            "value": " 190/190 [00:00&lt;00:00, 3.61kB/s]"
          }
        },
        "07c21e95961c470cad0448ddbef0b9b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ae65f69e73b4418b5fc93cb733547e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13342a159e204ff2be8c69a6269a58a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28d003abd3104ff18038915478dac9d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32683b2ff7544a4ea8e93c81e0f4db33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b52aaef2006240bfa8f8c6e4f07de285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f72c8dc824324ecc9d8a124713a256ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71f99db0fa9e44f783db86e0805544c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02045d9563b64cc393392d9b6e91ff2e",
              "IPY_MODEL_cc0249ed1b3e49b49d4fe6c1a0d6353b",
              "IPY_MODEL_955f617cd5d74fc0b0d0a25f4ae9b93e"
            ],
            "layout": "IPY_MODEL_1dec27b1ffda4dcc8e462492fbcd548b"
          }
        },
        "02045d9563b64cc393392d9b6e91ff2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66184610e094425f89ba80372e18fb26",
            "placeholder": "​",
            "style": "IPY_MODEL_4b6d5d8854ad43fc8b9d7fa826a4d640",
            "value": "Parsing nodes: 100%"
          }
        },
        "cc0249ed1b3e49b49d4fe6c1a0d6353b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_833973e3e7dd4ddb93ad53b9ba228999",
            "max": 154,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6c450f0e0814c19b9edec7c898edc20",
            "value": 154
          }
        },
        "955f617cd5d74fc0b0d0a25f4ae9b93e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e91d8eac9363436092b07b8891439fe9",
            "placeholder": "​",
            "style": "IPY_MODEL_c5d32d9840904558937630c1d037b26c",
            "value": " 154/154 [00:00&lt;00:00, 587.22it/s]"
          }
        },
        "1dec27b1ffda4dcc8e462492fbcd548b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66184610e094425f89ba80372e18fb26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b6d5d8854ad43fc8b9d7fa826a4d640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "833973e3e7dd4ddb93ad53b9ba228999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c450f0e0814c19b9edec7c898edc20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e91d8eac9363436092b07b8891439fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5d32d9840904558937630c1d037b26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acbb2e25e9c34e44be9221972893d3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1b1e23757114f569586b6ed665ecf45",
              "IPY_MODEL_9ac011ce926842638f69658055814808",
              "IPY_MODEL_61e674d92de447bfb4bb1def9ddc5a39"
            ],
            "layout": "IPY_MODEL_3c434deb432b4ba2ae1f7a1d4545f437"
          }
        },
        "a1b1e23757114f569586b6ed665ecf45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_919b0ca2c284491685fed69dd312f975",
            "placeholder": "​",
            "style": "IPY_MODEL_efad4941b1884730b1a8a6c402d99c32",
            "value": "Generating embeddings: 100%"
          }
        },
        "9ac011ce926842638f69658055814808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2e8cac3557d423ca2480179ebe5ed6e",
            "max": 162,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bb886e20f2f49488482e44c3abc2c5b",
            "value": 162
          }
        },
        "61e674d92de447bfb4bb1def9ddc5a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3a99b6e646842f98631de0489e67445",
            "placeholder": "​",
            "style": "IPY_MODEL_6c17b84321a14263bb5a7ce9cb078577",
            "value": " 162/162 [00:05&lt;00:00, 40.92it/s]"
          }
        },
        "3c434deb432b4ba2ae1f7a1d4545f437": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "919b0ca2c284491685fed69dd312f975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efad4941b1884730b1a8a6c402d99c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2e8cac3557d423ca2480179ebe5ed6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb886e20f2f49488482e44c3abc2c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3a99b6e646842f98631de0489e67445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c17b84321a14263bb5a7ce9cb078577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}